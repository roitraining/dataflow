{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b359750-81d1-48c1-a863-296635114ec2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 1. Initialization Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2036352e-57d4-4ff7-8155-60fb26e67a19",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Beam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d80bb6-e798-4a2c-8e19-bce24f87d212",
   "metadata": {},
   "source": [
    "### Install java by opening the git repository in terminal. Then <font color='blue' face=\"Fixedsys, monospace\" size=\"+2\"><br><br>cd /home/jupyter/dataflow<br><br>sudo ./install-java.sh</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbca6a8-f8cc-45ac-8a62-0d14bfb665d7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Initialize helper functions to run Java inside cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d334c3-e064-4241-aa70-26d939b3e166",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://colab.research.google.com/github/apache/beam/blob/master/examples/notebooks/get-started/try-apache-beam-java.ipynb#scrollTo=CgTXBdTsBn1F\n",
    "# Run and print a shell command.\n",
    "def run(cmd, progress = True, verbose = False):\n",
    "  if progress:\n",
    "      print('>> {}'.format(cmd))\n",
    "    \n",
    "  if verbose:\n",
    "      !{cmd}  # This is magic to run 'cmd' in the shell.\n",
    "      print('')\n",
    "  else:\n",
    "      ! {cmd} > /dev/null 2>&1\n",
    "\n",
    "import os\n",
    "\n",
    "# Download the gradle source.\n",
    "gradle_version = 'gradle-5.0'\n",
    "gradle_path = f\"/opt/{gradle_version}\"\n",
    "if not os.path.exists(gradle_path):\n",
    "  run(f\"wget -q -nc -O gradle.zip https://services.gradle.org/distributions/{gradle_version}-bin.zip\")\n",
    "  run('unzip -q -d /opt gradle.zip')\n",
    "  run('rm -f gradle.zip')\n",
    "\n",
    "# We're choosing to use the absolute path instead of adding it to the $PATH environment variable.\n",
    "def gradle(args):\n",
    "  run(f\"{gradle_path}/bin/gradle --console=plain {args}\")\n",
    "\n",
    "gradle('-v')\n",
    "\n",
    "! mkdir -p src/main/java/samples/quickstart/\n",
    "print('Done')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a716a7d4-28ea-40e7-90db-3e762b7dbcf9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Definition for <font color='blue' face=\"Fixedsys, monospace\" size=\"+2\">%%java</font> Python magic cell function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a97925b-df54-4700-bb8b-d4a3e2305b99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.core.magic import register_line_magic, register_cell_magic, register_line_cell_magic\n",
    "@register_cell_magic\n",
    "def java(line, cell):\n",
    "    \"\"\"\n",
    "    Written by Joseph Gagliardo Jr.\n",
    "    joegagliardo@gmail.com\n",
    "    2021-12-22\n",
    "    \"\"\"\n",
    "    gradle_text = \"\"\"\n",
    "plugins {\n",
    "  // id 'idea'     // Uncomment for IntelliJ IDE\n",
    "  // id 'eclipse'  // Uncomment for Eclipse IDE\n",
    "\n",
    "  // Apply java plugin and make it a runnable application.\n",
    "  id 'java'\n",
    "  id 'application'\n",
    "\n",
    "  // 'shadow' allows us to embed all the dependencies into a fat jar.\n",
    "  id 'com.github.johnrengelman.shadow' version '4.0.3'\n",
    "}\n",
    "\n",
    "// This is the path of the main class, stored within ./src/main/java/\n",
    "mainClassName = 'samples.quickstart.{class_name}'\n",
    "\n",
    "// Declare the sources from which to fetch dependencies.\n",
    "repositories {\n",
    "  mavenCentral()\n",
    "}\n",
    "\n",
    "// Java version compatibility.\n",
    "sourceCompatibility = 1.8\n",
    "targetCompatibility = 1.8\n",
    "\n",
    "// Use the latest Apache Beam major version 2.\n",
    "// You can also lock into a minor version like '2.9.+'.\n",
    "ext.apacheBeamVersion = '2.+'\n",
    "\n",
    "// Declare the dependencies of the project.\n",
    "dependencies {\n",
    "  shadow \"org.apache.beam:beam-sdks-java-core:$apacheBeamVersion\"\n",
    "\n",
    "  runtime \"org.apache.beam:beam-runners-direct-java:$apacheBeamVersion\"\n",
    "  runtime \"org.apache.beam:beam-sdks-java-extensions-sql:$apacheBeamVersion\"\n",
    "  runtime \"com.google.auto.value:auto-value-annotations:1.6\"\n",
    "  runtime \"com.google.code.gson:gson:2.8.8\"\n",
    "  compile \"org.apache.beam:beam-sdks-java-extensions-join-library:$apacheBeamVersion\"\n",
    "  runtime \"org.slf4j:slf4j-api:1.+\"\n",
    "  runtime \"org.slf4j:slf4j-jdk14:1.+\"\n",
    "\n",
    "  annotationProcessor \"com.google.auto.value:auto-value:1.6\"\n",
    "\n",
    "  testCompile \"junit:junit:4.+\"\n",
    "}\n",
    "\n",
    "// Configure 'shadowJar' instead of 'jar' to set up the fat jar.\n",
    "shadowJar {\n",
    "  zip64 true\n",
    "  baseName = '{class_name}' // Name of the fat jar file.\n",
    "  classifier = null       // Set to null, otherwise 'shadow' appends a '-all' to the jar file name.\n",
    "  manifest {\n",
    "    attributes('Main-Class': mainClassName)  // Specify where the main class resides.\n",
    "  }\n",
    "}\n",
    "\"\"\"   \n",
    "    start = cell.find('class ')\n",
    "    end = cell.find(' {')\n",
    "    class_name = cell[start+6:end]\n",
    "    progress = 'noprogress' not in line.lower()\n",
    "    verbose = 'verbose' in line.lower()\n",
    "    output = 'nooutput' not in line.lower()\n",
    "\n",
    "        \n",
    "    # if len(line) == 0:\n",
    "    #     start = cell.find('class ')\n",
    "    #     end = cell.find(' {')\n",
    "    #     class_name = cell[start+6:end]\n",
    "    # else:\n",
    "    #     class_name = line\n",
    "        \n",
    "    \n",
    "    run('rm src/main/java/samples/quickstart/*.java')\n",
    "    run('rm build/libs/*.jar')\n",
    "    run('rm -rf /tmp/outputs*', progress = progress, verbose = verbose)\n",
    "\n",
    "    with open('build.gradle', 'w') as f:\n",
    "        f.write(gradle_text.replace('{class_name}', class_name))\n",
    "\n",
    "    with open(f'src/main/java/samples/quickstart/{class_name}.java', 'w') as f:\n",
    "        f.write(cell)\n",
    "        \n",
    "    # Build the project.\n",
    "    run(f\"{gradle_path}/bin/gradle --console=plain build\", progress = progress, verbose = verbose)\n",
    "    run('ls -lh build/libs/', progress = progress, verbose = verbose)\n",
    "    run(f\"{gradle_path}/bin/gradle --console=plain runShadow\", progress = progress, verbose = verbose)\n",
    "    # run('head -n 20 /tmp/outputs*')\n",
    "    if output:\n",
    "        run('cat /tmp/outputs*', progress = False, verbose = True)\n",
    "\n",
    "    print('Done')\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec95a59-a834-4ee9-9aa6-7e4266367382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional dependencies sometimes needed\n",
    "  compile \"org.apache.beam:beam-sdks-java-extensions-google-cloud-platform-core:2.22.0\"\n",
    "  compile \"org.apache.beam:beam-runners-google-cloud-dataflow-java:2.22.0\"\n",
    "  compile \"org.apache.beam:beam-sdks-java-io-google-cloud-platform:2.22.0\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3957ba-068f-4325-827a-3b21aafeb702",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b5ce6c-55cb-45b7-9ad1-370ee54bf5c1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Install a Spark docker using the following commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3835ac48-b14e-4e01-8290-b9799ba6e97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "! docker pull bitnami/spark && \\\n",
    "docker network create spark_network && \\\n",
    "docker run -d --name spark --network=spark_network -e SPARK_MODE=master bitnami/spark\n",
    "! ln -s /opt/conda/lib/libtinfo.so /opt/conda/lib/libtinfor.so.6\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d659dd20-a9ab-4008-8bce-a5ff5acf5690",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Install pyspark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fdb46e-7eef-4af7-bd41-587e716e3be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pip\n",
    "\n",
    "def install(package):\n",
    "    if hasattr(pip, 'main'):\n",
    "        pip.main(['install', package])\n",
    "    else:\n",
    "        pip._internal.main(['install', package])\n",
    "\n",
    "install('pyspark')\n",
    "        \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2140ae18-4293-4560-91d6-4324e41fb0b0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Initialize the Spark context variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6573258c-97d5-4282-9278-cfe9ad82a186",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "def initspark(appname = \"Notebook\", servername = \"local[*]\"):\n",
    "    print ('initializing pyspark')\n",
    "    conf = SparkConf().setAppName(appname).setMaster(servername)\n",
    "    sc = SparkContext(conf=conf)\n",
    "    spark = SparkSession.builder.appName(appname).enableHiveSupport().getOrCreate()\n",
    "    sc.setLogLevel(\"ERROR\")\n",
    "    print ('pyspark initialized')\n",
    "    return sc, spark, conf\n",
    "\n",
    "sc, spark, conf = initspark()\n",
    "print(sc, spark)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d2bd3e-f247-4edc-87d1-27aeb165ecc1",
   "metadata": {
    "tags": []
   },
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20303e33-eb39-459b-85cf-743209e5322d",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffbf532-1859-4134-a64f-63b6f14f4268",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 2. <font color='blue' face=\"Fixedsys, monospace\" size=\"+2\">Create</font> allows you to upload data into a <font color='green' size=\"+2\">PCollection</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac7a129-5390-4f87-9108-04bde99ac83b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Get the path of which python we are running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ac7f8e-e4af-456f-ae2e-9dbc32f447cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67f8b59-343b-45c9-b02d-7399bceefbe0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## <img src=\"python.png\" width=40 height=40 /><font color='cadetblue' size=\"+2\">Python</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1397c54-3ff7-4188-bc9e-c72bef0d2670",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Non Beam example of applying a <font color='blue' face=\"Fixedsys, monospace\" size=\"+2\">\tmap</font> function to a collection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb0dd11-7c70-4a35-bc61-51d36bcfaa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ['one', 'two', 'three', 'four']\n",
    "for e in x:\n",
    "    print(e.upper())\n",
    "    \n",
    "print(list(map(str.title, x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fb1aad-7fe0-4b99-96f4-b30fbaae23ed",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Simple transformation, turn the local collection into a <font color='green' size=\"+2\">PCollection</font> and apply a <font color='blue' face=\"Fixedsys, monospace\" size=\"+2\">Map</font> <font color='green' size=\"+2\">PTransform</font> on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faedc12b-27d2-4098-85f0-feba2f9e14f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "p = beam.Pipeline()\n",
    "lines = p | beam.Create(['one', 'two', 'three', 'four'])\n",
    "lines2 = lines | beam.Map(str.title)\n",
    "lines2 | beam.Map(print)\n",
    "p.run()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e92d4c-66e3-418b-8c5f-b34cf896547a",
   "metadata": {},
   "source": [
    "### Usually in python we use a <font color='blue' face=\"Fixedsys, monospace\" size=\"+2\">with</font> block instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b34b950-ab89-430d-902e-d1e7c315fbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with beam.Pipeline() as p:\n",
    "    lines = (\n",
    "        p | beam.Create(['one', 'two', 'three', 'four'])\n",
    "          | beam.Map(str.title)\n",
    "          | beam.Map(print)\n",
    "    )\n",
    "    #p.run() # implicit in Python when using with block\n",
    "\n",
    "# lines is a PCollection object\n",
    "print('lines = ', lines)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977dfeee-d660-47fb-92f7-7a0c3bcbb302",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Simple transformation using a user defined function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf4cad9-4ed9-4c26-8894-e7d84eff8edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "def title(x):\n",
    "    return x.title() + '*'\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "    lines = (\n",
    "        p | beam.Create(['one', 'two', 'three', 'four'])\n",
    "          | beam.Map(title)\n",
    "    )\n",
    "    lines | beam.Map(print)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2c8ecc-a678-48eb-9ae8-7fd3e34b8a6c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Simple transformation using a <font color='blue' face=\"Fixedsys, monospace\" size=\"+2\">lambda</font> instead of a built in function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd9b54f-3a72-4688-a5d1-545077e6b1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "    lines = (\n",
    "        p | beam.Create(['one', 'two', 'three', 'four'])\n",
    "          | beam.Map(lambda x : x.title() + '*')\n",
    "    )\n",
    "    lines | beam.Map(print)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f09af7-2678-4b0c-879e-c567625a4a83",
   "metadata": {
    "tags": []
   },
   "source": [
    "### The pipe <font color='blue' face=\"Fixedsys, monospace\" size=\"+2\">|</font> is actually just an operator overload to call the <font color='blue' face=\"Fixedsys, monospace\" size=\"+2\">apply</font> method of the pipeline. You would never do this in Python, but it helps to understand what is going on under the hood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292e7a3d-99fc-4904-a1cd-baf93d088b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "        lines = ((p | beam.Create(['one', 'two', 'three', 'four']))\n",
    "             .apply(beam.Map(str.title)) \n",
    "        )\n",
    "        lines.apply(beam.Map(print))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b057071-63e3-4414-820d-71e07ed0959d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### The Spark equivalent would be to upload a local Python <font color='blue' face=\"Fixedsys, monospace\" size=\"+2\">list</font> into a Spark <font color='green' size=\"+2\">RDD</font> and do a simple transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b110e0-45a0-476b-a2ca-d33cecaec241",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd1 = ( sc.parallelize(['one', 'two', 'three', 'four'])\n",
    "        \n",
    "#           .map(str.title)\n",
    "       )\n",
    "rdd1.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beebfb43-8dd1-491e-9422-350ecda44d1a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## <img src=\"java.png\" width=40 height=40 /><font color='indigo' size=\"+2\">Java</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e33b715-0a74-4b46-8736-7798c51b313a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Simple transformation using a <font color='green' size=\"+2\">lambda</font>.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8420314f-13dd-410f-90a8-569c9f3770ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%java verbose\n",
    "package samples.quickstart;\n",
    "\n",
    "import org.apache.beam.sdk.Pipeline;\n",
    "import org.apache.beam.sdk.values.PCollection;\n",
    "import org.apache.beam.sdk.values.TypeDescriptors;\n",
    "import org.apache.beam.sdk.transforms.Create;\n",
    "import org.apache.beam.sdk.transforms.MapElements;\n",
    "import org.apache.beam.sdk.io.TextIO;\n",
    "\n",
    "import java.util.*;\n",
    "\n",
    "public class Create1 {\n",
    "    public static void main(String[] args) {\n",
    "\n",
    "        String outputsPrefix = \"/tmp/outputs\";\n",
    "        Pipeline p = Pipeline.create();\n",
    "        \n",
    "        PCollection<String> lines = p.apply(Create.of(\"one\", \"two\", \"three\", \"four\"));\n",
    "        lines = lines.apply(MapElements.into(TypeDescriptors.strings()).via((String line) -> line.toUpperCase()));\n",
    "        lines.apply(TextIO.write().to(outputsPrefix));\n",
    "\n",
    "        p.run().waitUntilFinish();\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3db7b6-c42d-4268-847c-24a9c39df7e8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Simple transformation using <font color='blue' face=\"Fixedsys, monospace\" size=\"+2\">SimpleFunction</font> instead of <font color='green' size=\"+2\">lambda</font>.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff75092-0480-4784-afba-9616e9e60d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%java verbose\n",
    "package samples.quickstart;\n",
    "\n",
    "import org.apache.beam.sdk.Pipeline;\n",
    "import org.apache.beam.sdk.values.PCollection;\n",
    "import org.apache.beam.sdk.transforms.Create;\n",
    "import org.apache.beam.sdk.transforms.MapElements;\n",
    "import org.apache.beam.sdk.transforms.SimpleFunction;\n",
    "import org.apache.beam.sdk.io.TextIO;\n",
    "import java.util.*;\n",
    "\n",
    "public class Create2 {\n",
    "    public static void main(String[] args) {\n",
    "\n",
    "        String outputsPrefix = \"/tmp/outputs\";\n",
    "        Pipeline p = Pipeline.create();\n",
    "        \n",
    "        PCollection<String> lines = p.apply(Create.of(\"one\", \"two\", \"three\", \"four\"));\n",
    "        lines = lines.apply(MapElements.via(\n",
    "            new SimpleFunction<String, String>() {\n",
    "              @Override\n",
    "              public String apply(String line) {\n",
    "                String ret = line.toUpperCase();\n",
    "                //System.out.println(\"** \" + ret);\n",
    "                return ret;\n",
    "              }\n",
    "            }));\n",
    "\n",
    "        lines.apply(\"Write\", TextIO.write().to(outputsPrefix));\n",
    "\n",
    "        p.run().waitUntilFinish();\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f27aee-6b1c-44a5-815d-31d039c24475",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Java simple transformation using <font color='blue' face=\"Fixedsys, monospace\" size=\"+2\">SimpleFunction</font> to wrap a User Defined Function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5c178e-2cfa-4316-95de-5779b243f8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%java\n",
    "package samples.quickstart;\n",
    "\n",
    "import org.apache.beam.sdk.Pipeline;\n",
    "import org.apache.beam.sdk.values.PCollection;\n",
    "import org.apache.beam.sdk.transforms.Create;\n",
    "import org.apache.beam.sdk.transforms.MapElements;\n",
    "import org.apache.beam.sdk.transforms.SimpleFunction;\n",
    "import org.apache.beam.sdk.io.TextIO;\n",
    "import java.util.*;\n",
    "\n",
    "public class Create3 {\n",
    "    public static void main(String[] args) {\n",
    "\n",
    "        String outputsPrefix = \"/tmp/outputs\";\n",
    "        Pipeline p = Pipeline.create();\n",
    "        \n",
    "        PCollection<String> lines = p.apply(Create.of(\"one\", \"two\", \"three\", \"four\"));\n",
    "        lines = lines.apply(MapElements.via(\n",
    "            new SimpleFunction<String, String>() {\n",
    "              @Override\n",
    "              public String apply(String line) {\n",
    "                return upper(line);\n",
    "              }\n",
    "            }));\n",
    "\n",
    "        lines.apply(\"Write\", TextIO.write().to(outputsPrefix));\n",
    "\n",
    "        p.run().waitUntilFinish();\n",
    "    }\n",
    "    \n",
    "    public static String upper(String line) {\n",
    "        return line.toUpperCase();\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d5781d-6836-44ce-bca3-34585c5e352f",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591af669-d68f-471e-a03a-82dbaaa7a609",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931beffe-4cf4-48e4-a28d-8a2dfaed62c0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 3. <font color='blue' face=\"Fixedsys, monospace\" size=\"+2\">ReadFromText</font> allows you to read a text file into a <font color='green' size=\"+2\">PCollection</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19db17f3-ea3a-4418-b12e-5b859d1e9856",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <img src=\"python.png\" width=40 height=40 /><font color='cadetblue' size=\"+2\">Python</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab382f85-16e9-4544-a56b-06c6d4edc7b6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### It's a good idea to start naming the steps for debugging and monitoring later. Names must be unique in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53066990-43fc-42c0-9545-ddf723145fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm /tmp/outputs*\n",
    "\n",
    "import apache_beam as beam\n",
    "from apache_beam.io import ReadFromText, WriteToText\n",
    "\n",
    "def parse_tuple(x):\n",
    "    regionid, regionname = x.split(',')\n",
    "    return (int(regionid), regionname.upper())\n",
    "    \n",
    "regionsfilename = 'datasets/northwind/CSV/regions/regions.csv'\n",
    "with beam.Pipeline() as p:\n",
    "    regions = (\n",
    "        p | 'Read' >> ReadFromText(regionsfilename)\n",
    "          # | 'Parse Tuple' >> beam.Map(parse_tuple)\n",
    "          # | 'Parse' >> beam.Map(lambda x : x.split(','))\n",
    "          # | 'Transform' >> beam.Map(lambda x : (int(x[0]), x[1].upper()))\n",
    "    )\n",
    "    #regions | 'Write' >> WriteToText('/tmp/outputs')\n",
    "    regions | 'Print' >> beam.Map(print)\n",
    "\n",
    "! cat /tmp/outputs*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee88479c-60c3-48c3-b8c1-3e8113f0d39a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Read from CSV and use <font color='green' size=\"+2\">ParDo</font>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94887a8a-f945-414f-bfaa-2e72fa1aa746",
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.io import ReadFromText, WriteToText\n",
    "\n",
    "class RegionParseTuple(beam.DoFn):\n",
    "    def process(self, element: str):\n",
    "        regionid, regionname = element.split(',')\n",
    "        yield (int(regionid), regionname) # Can also use yield instead of returning a list\n",
    "#        return [(int(regionid), regionname)] # ParDo's need to return a list\n",
    "#        yield (int(regionid), regionname.upper()) # Include a transformation instead of doing it as a separate step\n",
    "\n",
    "class RegionParseDict(beam.DoFn):\n",
    "    def process(self, element: str):\n",
    "        regionid, regionname = element.split(',')\n",
    "        yield {'regionid': int(regionid), 'regionname': regionname}\n",
    "\n",
    "regionsfilename = 'datasets/northwind/CSV/regions/regions.csv'\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "    regions = (\n",
    "        p | 'Read' >> ReadFromText(regionsfilename)\n",
    "          | 'Parse' >> beam.ParDo(RegionParseTuple())\n",
    "          | 'Filter' >> beam.Filter(lambda x : x[0] < 3)\n",
    "          # | 'Parse' >> beam.ParDo(RegionParseDict())\n",
    "          # | 'Filter' >> beam.Filter(lambda x : x['regionid'] < 3)\n",
    "    )\n",
    "    #region | 'Write' >> WriteToText('regions.out')\n",
    "    regions | 'Print' >> beam.Map(print)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b77b3ea-a41a-4743-b67a-f597b0e7f3d9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Read from CSV and use <font color='green' size=\"+2\">ParDo</font> with <font color='green' size=\"+2\">Row</font> object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28526b3b-32db-40e1-b393-21cdeb985918",
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.io import ReadFromText, WriteToText\n",
    "\n",
    "class RegionParseRow(beam.DoFn):\n",
    "    def process(self, element: str):\n",
    "        regionid, regionname = element.split(',')\n",
    "        yield beam.Row(regionid = int(regionid), regionname = regionname)\n",
    "\n",
    "\n",
    "regionsfilename = 'datasets/northwind/CSV/regions/regions.csv'\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "    regions = (\n",
    "        p | 'Read' >> ReadFromText(regionsfilename)\n",
    "          | 'Parse' >> beam.ParDo(RegionParseRow())\n",
    "          | 'Filter' >> beam.Filter(lambda x : x.regionid < 3)\n",
    "    )\n",
    "    regions | 'Print' >> beam.Map(print)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f3fd79-61c1-4d9f-acf1-5ee7af3ff832",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <img src=\"java.png\" width=40 height=40 /><font color='indigo' size=\"+2\">Java</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d05cc4-e81e-44d7-adad-d38ee19848c7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Read from CSV and use <font color='blue' face=\"Fixedsys, monospace\" size=\"+2\">Map</font> with <font color='green' >lambda</font>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28492eea-c43a-43ab-aa7f-ceca3f199a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%java\n",
    "package samples.quickstart;\n",
    "\n",
    "import org.apache.beam.sdk.Pipeline;\n",
    "import org.apache.beam.sdk.values.PCollection;\n",
    "import org.apache.beam.sdk.values.TypeDescriptors;\n",
    "import org.apache.beam.sdk.transforms.MapElements;\n",
    "import org.apache.beam.sdk.io.TextIO;\n",
    "\n",
    "public class ReadRegions1 {\n",
    "    public static void main(String[] args) {\n",
    "        Pipeline p = Pipeline.create();\n",
    "\n",
    "        String regionsInputFileName = \"datasets/northwind/CSV/regions/regions.csv\";\n",
    "        String outputsPrefix = \"/tmp/outputs\";\n",
    "\n",
    "        PCollection<String> regions = p\n",
    "            .apply(\"Read\", TextIO.read().from(regionsInputFileName))\n",
    "            .apply(\"Parse\", MapElements.into(TypeDescriptors.strings()).via((String element) -> element.toUpperCase()));\n",
    "        \n",
    "        regions.apply(TextIO.write().to(outputsPrefix));\n",
    "        p.run().waitUntilFinish();\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffc4515-7a9b-40f9-99cf-c456065c3e11",
   "metadata": {
    "tags": []
   },
   "source": [
    "### <font color='green' size=\"+2\">ParDo</font> using a defined class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8543a5-9d2e-4a6e-81f4-5ae59aedcf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%java\n",
    "package samples.quickstart;\n",
    "\n",
    "import org.apache.beam.sdk.Pipeline;\n",
    "import org.apache.beam.sdk.values.PCollection;\n",
    "import org.apache.beam.sdk.values.TypeDescriptors;\n",
    "import org.apache.beam.sdk.io.TextIO;\n",
    "import org.apache.beam.sdk.transforms.ParDo;\n",
    "import org.apache.beam.sdk.transforms.DoFn;\n",
    "import org.apache.beam.sdk.transforms.DoFn.ProcessContext;\n",
    "\n",
    "public class ReadRegions3 {\n",
    "    public static void main(String[] args) {\n",
    "        Pipeline p = Pipeline.create();\n",
    "\n",
    "        String regionsInputFileName = \"datasets/northwind/CSV/regions/regions.csv\";\n",
    "        String outputsPrefix = \"/tmp/outputs\";\n",
    "\n",
    "\n",
    "        PCollection<String> regions = p\n",
    "            .apply(\"Read\", TextIO.read().from(regionsInputFileName))\n",
    "            .apply(\"Parse\", ParDo.of(new AddStar()));\n",
    "        \n",
    "        regions.apply(TextIO.write().to(outputsPrefix));\n",
    "        p.run().waitUntilFinish();\n",
    "    }\n",
    "    \n",
    "    static class AddStar extends DoFn<String, String> {\n",
    "        @ProcessElement\n",
    "        public void process(@Element String line, OutputReceiver<String> out) {\n",
    "            out.output(line + \"*\");\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fbd1da-0fed-43c9-8ab1-e1b73cc9534f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### <font color='green' size=\"+2\">ParDo</font> Example using anonymous class inline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14327a97-f8cd-489b-87eb-82ad962f701e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%java\n",
    "package samples.quickstart;\n",
    "\n",
    "import org.apache.beam.sdk.Pipeline;\n",
    "import org.apache.beam.sdk.values.PCollection;\n",
    "import org.apache.beam.sdk.values.TypeDescriptors;\n",
    "import org.apache.beam.sdk.io.TextIO;\n",
    "import org.apache.beam.sdk.transforms.ParDo;\n",
    "import org.apache.beam.sdk.transforms.DoFn;\n",
    "import org.apache.beam.sdk.transforms.DoFn.ProcessContext;\n",
    "\n",
    "public class ReadRegions2 {\n",
    "    public static void main(String[] args) {\n",
    "        Pipeline p = Pipeline.create();\n",
    "\n",
    "        String regionsInputFileName = \"datasets/northwind/CSV/regions/regions.csv\";\n",
    "        String outputsPrefix = \"/tmp/outputs\";\n",
    "\n",
    "\n",
    "        PCollection<String> regions = p\n",
    "            .apply(\"Read\", TextIO.read().from(regionsInputFileName))\n",
    "            .apply(\"Parse\", ParDo.of(new DoFn<String, String>() {\n",
    "                @ProcessElement\n",
    "                public void process(ProcessContext c) {\n",
    "                    String element = c.element();\n",
    "                    // String[] elements = element.split(\",\");\n",
    "                    c.output(element + \"*\");\n",
    "                }\n",
    "            }));\n",
    "        \n",
    "        regions.apply(TextIO.write().to(outputsPrefix));\n",
    "        p.run().waitUntilFinish();\n",
    "    }\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5ce401-ba9d-4fd8-a21c-670049b2a716",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3889a629-d0e8-4cbc-9673-840de48cbf00",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cae856-d38b-4ce9-a4c1-511284e1f9bc",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 4. Parse into a model class.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f4b34a-2b4a-4f8f-aa9c-af369f7ef9bb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <img src=\"python.png\" width=40 height=40 /><font color='cadetblue' size=\"+2\">Python</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebebb6b4-3c55-4b79-a0d8-4d3c017162c7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create a model based on <font color='blue' face=\"Fixedsys, monospace\" size=\"+2\">typing.NamedTuple</font> so you can use properties instead of keys for <font color='green' size=\"+2\">dict</font> or position for <font color='green' size=\"+2\">tuple</font> and use the <font color='blue' face=\"Fixedsys, monospace\" size=\"+2\">Filter</font> <font color='green' size=\"+2\">PTransform</font> with <font color='blue' face=\"Fixedsys, monospace\" size=\"+2\">lambda</font>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0dd7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.io import ReadFromText, WriteToText\n",
    "import typing\n",
    "\n",
    "class Territory(typing.NamedTuple):\n",
    "    territoryid: int\n",
    "    territoryname: str\n",
    "    regionid: int\n",
    "\n",
    "    # def __str__(self):\n",
    "    #     return f'territoryid = {self.territoryid}, regionid = {self.regionid}, territoryname = {self.territoryname}'\n",
    "\n",
    "beam.coders.registry.register_coder(Territory, beam.coders.RowCoder)\n",
    "        \n",
    "class TerritoryParseClass(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        territoryid, territoryname, regionid = element.split(',')\n",
    "        yield Territory(int(territoryid), territoryname, int(regionid))\n",
    "\n",
    "territoriesfilename = 'datasets/northwind/CSV/territories/territories.csv'\n",
    "with beam.Pipeline() as p:\n",
    "    regions = (\n",
    "        p | 'Read' >> ReadFromText(territoriesfilename)\n",
    "          | 'Parse' >> beam.ParDo(TerritoryParseClass())\n",
    "          # | 'Filter 1' >> beam.Filter(lambda x : x.regionid % 2 == 0)\n",
    "          # | 'Filter 2' >> beam.Filter(lambda x : x.territoryname.startswith('S'))\n",
    "    )\n",
    "    regions | 'Print' >> beam.Map(print)\n",
    "#   regions | 'Write' >> WriteToText('regions.out')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5230451d-cfb3-450f-82b6-e5dd24e6e2e4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Use <font color='blue' face=\"Fixedsys, monospace\" size=\"+2\">Filter</font> with a UDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07089b39-7ccf-42cf-830b-3189ab269566",
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.io import ReadFromText, WriteToText\n",
    "import typing\n",
    "\n",
    "class Territory(typing.NamedTuple):\n",
    "    territoryid: int\n",
    "    territoryname: str\n",
    "    regionid: int\n",
    "beam.coders.registry.register_coder(Territory, beam.coders.RowCoder)\n",
    "        \n",
    "class TerritoryParseClass(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        territoryid, territoryname, regionid = element.split(',')\n",
    "        yield Territory(int(territoryid), territoryname, int(regionid))\n",
    "\n",
    "def startsWithS(element):\n",
    "    return element.territoryname.startswith('S')\n",
    "\n",
    "territoriesfilename = 'datasets/northwind/CSV/territories/territories.csv'\n",
    "with beam.Pipeline() as p:\n",
    "    territories = (\n",
    "        p | 'Read' >> ReadFromText(territoriesfilename)\n",
    "          | 'Parse' >> beam.ParDo(TerritoryParseClass())\n",
    "          | 'Filter' >> beam.Filter(startsWithS)\n",
    "    )\n",
    "    territories | 'Print' >> beam.Map(print)\n",
    "#   territories | 'Write' >> WriteToText('regions.out')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ac3ac5-d61b-496d-bf95-2801b014b28e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Use a <font color='green' size=\"+2\">ParDo</font> class to accomplish filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54691011-9bfd-49d9-8992-ff1333c65824",
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.io import ReadFromText, WriteToText\n",
    "import typing\n",
    "\n",
    "class Territory(typing.NamedTuple):\n",
    "    territoryid: int\n",
    "    territoryname: str\n",
    "    regionid: int\n",
    "beam.coders.registry.register_coder(Territory, beam.coders.RowCoder)\n",
    "        \n",
    "class TerritoryParseClass(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        territoryid, territoryname, regionid = element.split(',')\n",
    "        yield Territory(int(territoryid), territoryname, int(regionid))\n",
    "\n",
    "class StartsWithSFilter(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        if element.territoryname.startswith('S'):\n",
    "            yield element\n",
    "            \n",
    "territoriesfilename = 'datasets/northwind/CSV/territories/territories.csv'\n",
    "with beam.Pipeline() as p:\n",
    "    regions = (\n",
    "        p | 'Read' >> ReadFromText(territoriesfilename)\n",
    "          | 'Parse' >> beam.ParDo(TerritoryParseClass())\n",
    "          | 'Filter' >> beam.ParDo(StartsWithSFilter())\n",
    "    )\n",
    "    regions | 'Print' >> beam.Map(print)\n",
    "#   regions | 'Write' >> WriteToText('regions.out')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39807dbe-b99a-4767-be21-16b38ff287f8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Put the parsing and filtering all into one <font color='green' size=\"+2\">ParDo</font>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2091357-5550-42fb-8810-3e5fc8d2cb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.io import ReadFromText, WriteToText\n",
    "import typing\n",
    "\n",
    "class Territory(typing.NamedTuple):\n",
    "    territoryid: int\n",
    "    territoryname: str\n",
    "    regionid: int\n",
    "beam.coders.registry.register_coder(Territory, beam.coders.RowCoder)\n",
    "        \n",
    "class TerritoryParseClass(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        territoryid, territoryname, regionid = element.split(',')\n",
    "        if territoryname.startswith('S'):\n",
    "            yield Territory(int(territoryid), territoryname, int(regionid))\n",
    "\n",
    "territoriesfilename = 'datasets/northwind/CSV/territories/territories.csv'\n",
    "with beam.Pipeline() as p:\n",
    "    regions = (\n",
    "        p | 'Read' >> ReadFromText(territoriesfilename)\n",
    "          | 'Parse' >> beam.ParDo(TerritoryParseClass())\n",
    "    )\n",
    "    regions | 'Print' >> beam.Map(print)\n",
    "#   regions | 'Write' >> WriteToText('regions.out')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bb0592-e4b0-4204-b4f0-775e75d8f02c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <img src=\"java.png\" width=40 height=40 /><font color='indigo' size=\"+2\">Java</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e66252-cdcd-411c-866e-44857a6b4379",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Parse a CSV into a <font color='green' size=\"+2\">Row</font> object and filter it using a <font color='green' size=\"+2\">Pardo</font>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e1e99c-eece-43f4-9b8e-2ba9df28d888",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%java --verbose\n",
    "package samples.quickstart;\n",
    "\n",
    "import org.apache.beam.sdk.Pipeline;\n",
    "import org.apache.beam.sdk.values.PCollection;\n",
    "import org.apache.beam.sdk.values.TypeDescriptors;\n",
    "import org.apache.beam.sdk.io.TextIO;\n",
    "import org.apache.beam.sdk.transforms.MapElements;\n",
    "import org.apache.beam.sdk.transforms.ParDo;\n",
    "import org.apache.beam.sdk.transforms.DoFn;\n",
    "import org.apache.beam.sdk.transforms.Filter;\n",
    "import org.apache.beam.sdk.transforms.DoFn.ProcessContext;\n",
    "import org.apache.beam.sdk.coders.DefaultCoder;\n",
    "import org.apache.beam.sdk.coders.AvroCoder;\n",
    "import org.apache.beam.sdk.transforms.SerializableFunction;\n",
    "import org.apache.beam.sdk.values.Row;\n",
    "import org.apache.beam.sdk.schemas.Schema;\n",
    "\n",
    "import org.slf4j.Logger;\n",
    "import org.slf4j.LoggerFactory;\n",
    "\n",
    "public class ReadTerritories {\n",
    "\n",
    "\n",
    "    public static void main(String[] args) {\n",
    "        Pipeline p = Pipeline.create();\n",
    "\n",
    "        \n",
    "        String territoriesInputFileName = \"datasets/northwind/CSV/territories/territories.csv\";\n",
    "        String outputsPrefix = \"/tmp/outputs\";\n",
    "\n",
    "        PCollection<Row> territories = p\n",
    "            .apply(\"Read\", TextIO.read().from(territoriesInputFileName))\n",
    "            .apply(\"Parse\", ParDo.of(new ParseTerritories())).setRowSchema(TerritorySchema.territorySchema);\n",
    "        ;                   \n",
    "        \n",
    "        territories.apply(\"Print\", MapElements.into(TypeDescriptors.strings())\n",
    "        .via(\n",
    "            x -> {\n",
    "              System.out.println(x);\n",
    "              return \"\";\n",
    "            }));\n",
    "        p.run().waitUntilFinish();\n",
    "    }\n",
    "    \n",
    "    static class TerritorySchema {\n",
    "            static Schema territorySchema = Schema.of(\n",
    "            Schema.Field.of(\"territoryid\", Schema.FieldType.INT64),\n",
    "            Schema.Field.of(\"territoryname\", Schema.FieldType.STRING),\n",
    "            Schema.Field.of(\"regionid\", Schema.FieldType.INT64)\n",
    "            );\n",
    "\n",
    "    }\n",
    "    \n",
    "    static class ParseTerritories extends DoFn<String, Row> {\n",
    "        private static final Logger LOG = LoggerFactory.getLogger(ParseTerritories.class);\n",
    "\n",
    "        @ProcessElement\n",
    "        public void process(ProcessContext c) {\n",
    "            String[] columns = c.element().split(\",\");\n",
    "            try {\n",
    "                Long territoryID = Long.parseLong(columns[0].trim());\n",
    "                String territoryName = columns[1].trim();\n",
    "                Long regionID = Long.parseLong(columns[2].trim());\n",
    "                Row row = Row.withSchema(TerritorySchema.territorySchema).addValue(territoryID).addValue(territoryName).addValue(regionID).build();\n",
    "                c.output(row);\n",
    "            } catch (ArrayIndexOutOfBoundsException | NumberFormatException e) {\n",
    "                LOG.info(\"ParseTerritories: parse error on '\" + c.element() + \"': \" + e.getMessage());\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e99ed53-4035-4ef9-bb71-ac03bfd64ddd",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Parse a CSV into a class and filter it using a <font color='green' size=\"+2\">Pardo</font>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c32dcb-1f4c-43a2-9e8e-e2c31f2fae3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%java\n",
    "package samples.quickstart;\n",
    "\n",
    "import org.apache.beam.sdk.Pipeline;\n",
    "import org.apache.beam.sdk.values.PCollection;\n",
    "import org.apache.beam.sdk.values.TypeDescriptors;\n",
    "import org.apache.beam.sdk.io.TextIO;\n",
    "import org.apache.beam.sdk.transforms.ParDo;\n",
    "import org.apache.beam.sdk.transforms.DoFn;\n",
    "import org.apache.beam.sdk.transforms.Filter;\n",
    "import org.apache.beam.sdk.transforms.DoFn.ProcessContext;\n",
    "import org.apache.beam.sdk.coders.DefaultCoder;\n",
    "import org.apache.beam.sdk.coders.AvroCoder;\n",
    "import org.apache.beam.sdk.transforms.SerializableFunction;\n",
    "\n",
    "import org.slf4j.Logger;\n",
    "import org.slf4j.LoggerFactory;\n",
    "\n",
    "public class ReadTerritories {\n",
    "    public static void main(String[] args) {\n",
    "        Pipeline p = Pipeline.create();\n",
    "\n",
    "        String territoriesInputFileName = \"datasets/northwind/CSV/territories/territories.csv\";\n",
    "        String outputsPrefix = \"/tmp/outputs\";\n",
    "\n",
    "        PCollection<Territory> territories = p\n",
    "            .apply(\"Read\", TextIO.read().from(territoriesInputFileName))\n",
    "            .apply(\"Parse\", ParDo.of(new ParseTerritories()))\n",
    "            .apply(\"Filter\", ParDo.of(new FilterTerritories()))\n",
    "        ;                   \n",
    "        \n",
    "        territories.apply(TextIO.<Territory>writeCustomType().to(outputsPrefix).withFormatFunction(new SerializeTerritory()));\n",
    "        p.run().waitUntilFinish();\n",
    "    }\n",
    "    \n",
    "    @DefaultCoder(AvroCoder.class)\n",
    "    static class Territory {\n",
    "        Long territoryID;\n",
    "        String territoryName;\n",
    "        Long regionID;\n",
    "        \n",
    "        Territory() {}\n",
    "        \n",
    "        Territory(long territoryID, String territoryName, long regionID) {\n",
    "            this.territoryID = territoryID;\n",
    "            this.territoryName = territoryName;\n",
    "            this.regionID = regionID;\n",
    "        }\n",
    "        \n",
    "        @Override\n",
    "        public String toString() {\n",
    "            return String.format(\"(territoryID = %d, territoryName = %s, regionID = %d)\", territoryID, territoryName, regionID);\n",
    "        }\n",
    "\n",
    "    }\n",
    "    \n",
    "    static class SerializeTerritory implements SerializableFunction<Territory, String> {\n",
    "        @Override\n",
    "        public String apply(Territory input) {\n",
    "          return input.toString();\n",
    "        }\n",
    "    }\n",
    "\n",
    "    static class ParseTerritories extends DoFn<String, Territory> {\n",
    "        private static final Logger LOG = LoggerFactory.getLogger(ParseTerritories.class);\n",
    "\n",
    "        @ProcessElement\n",
    "        public void process(ProcessContext c) {\n",
    "            String[] columns = c.element().split(\",\");\n",
    "            try {\n",
    "                Long territoryID = Long.parseLong(columns[0].trim());\n",
    "                String territoryName = columns[1].trim();\n",
    "                Long regionID = Long.parseLong(columns[2].trim());\n",
    "                c.output(new Territory(territoryID, territoryName, regionID));\n",
    "            } catch (ArrayIndexOutOfBoundsException | NumberFormatException e) {\n",
    "                LOG.info(\"ParseTerritories: parse error on '\" + c.element() + \"': \" + e.getMessage());\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    static class FilterTerritories extends DoFn<Territory, Territory> {\n",
    "        private static final Logger LOG = LoggerFactory.getLogger(FilterTerritories.class);\n",
    "\n",
    "        @ProcessElement\n",
    "        public void process(@Element Territory t, OutputReceiver<Territory> o) {\n",
    "            if (t.territoryID % 2 == 0 && t.territoryName.startsWith(\"S\")) {\n",
    "                o.output(t);\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7378c125-c36c-4ac0-9443-35f54539258a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Parse a CSV into a class and filter it using and anonymous class to create the condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7292cee7-d525-44b6-a9db-36b5f3acf839",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%java\n",
    "package samples.quickstart;\n",
    "\n",
    "import org.apache.beam.sdk.Pipeline;\n",
    "import org.apache.beam.sdk.values.PCollection;\n",
    "import org.apache.beam.sdk.values.TypeDescriptors;\n",
    "import org.apache.beam.sdk.io.TextIO;\n",
    "import org.apache.beam.sdk.transforms.ParDo;\n",
    "import org.apache.beam.sdk.transforms.DoFn;\n",
    "import org.apache.beam.sdk.transforms.Filter;\n",
    "import org.apache.beam.sdk.transforms.DoFn.ProcessContext;\n",
    "import org.apache.beam.sdk.coders.DefaultCoder;\n",
    "import org.apache.beam.sdk.coders.AvroCoder;\n",
    "import org.apache.beam.sdk.transforms.SerializableFunction;\n",
    "\n",
    "import org.slf4j.Logger;\n",
    "import org.slf4j.LoggerFactory;\n",
    "\n",
    "public class ReadTerritories {\n",
    "    public static void main(String[] args) {\n",
    "        Pipeline p = Pipeline.create();\n",
    "\n",
    "        String territoriesInputFileName = \"datasets/northwind/CSV/territories/territories.csv\";\n",
    "        String outputsPrefix = \"/tmp/outputs\";\n",
    "\n",
    "        PCollection<Territory> territories = p\n",
    "            .apply(\"Read\", TextIO.read().from(territoriesInputFileName))\n",
    "            .apply(\"Parse\", ParDo.of(new ParseTerritories()))\n",
    "            .apply(\"Filter\", Filter.by(new SerializableFunction<Territory, Boolean>() {\n",
    "                @Override\n",
    "                public Boolean apply(Territory t) {\n",
    "                    return t.territoryID % 2 == 0 && t.territoryName.startsWith(\"S\");\n",
    "                }\n",
    "            }))\n",
    "        ;                   \n",
    "        \n",
    "        territories.apply(TextIO.<Territory>writeCustomType().to(outputsPrefix).withFormatFunction(new SerializeTerritory()));\n",
    "        p.run().waitUntilFinish();\n",
    "    }\n",
    "    \n",
    "    @DefaultCoder(AvroCoder.class)\n",
    "    static class Territory {\n",
    "        Long territoryID;\n",
    "        String territoryName;\n",
    "        Long regionID;\n",
    "        \n",
    "        Territory() {}\n",
    "        \n",
    "        Territory(long territoryID, String territoryName, long regionID) {\n",
    "            this.territoryID = territoryID;\n",
    "            this.territoryName = territoryName;\n",
    "            this.regionID = regionID;\n",
    "        }\n",
    "        \n",
    "        @Override\n",
    "        public String toString() {\n",
    "            return String.format(\"(territoryID = %d, territoryName = %s, regionID = %d)\", territoryID, territoryName, regionID);\n",
    "        }\n",
    "\n",
    "    }\n",
    "    \n",
    "    static class SerializeTerritory implements SerializableFunction<Territory, String> {\n",
    "        @Override\n",
    "        public String apply(Territory input) {\n",
    "          return input.toString();\n",
    "        }\n",
    "    }\n",
    "\n",
    "    static class ParseTerritories extends DoFn<String, Territory> {\n",
    "        private static final Logger LOG = LoggerFactory.getLogger(ParseTerritories.class);\n",
    "\n",
    "        @ProcessElement\n",
    "        public void process(ProcessContext c) {\n",
    "            String[] columns = c.element().split(\",\");\n",
    "            try {\n",
    "                Long territoryID = Long.parseLong(columns[0].trim());\n",
    "                String territoryName = columns[1].trim();\n",
    "                Long regionID = Long.parseLong(columns[2].trim());\n",
    "                c.output(new Territory(territoryID, territoryName, regionID));\n",
    "            } catch (ArrayIndexOutOfBoundsException | NumberFormatException e) {\n",
    "                LOG.info(\"ParseTerritories: parse error on '\" + c.element() + \"': \" + e.getMessage());\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    static class FilterTerritories extends DoFn<Territory, Territory> {\n",
    "        private static final Logger LOG = LoggerFactory.getLogger(FilterTerritories.class);\n",
    "\n",
    "        @ProcessElement\n",
    "        public void process(@Element Territory t, OutputReceiver<Territory> o) {\n",
    "            if (t.territoryID % 2 == 0 && t.territoryName.startsWith(\"S\")) {\n",
    "                o.output(t);\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c2fc88-b027-42bf-9136-c02d6583a04c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Parse a CSV into a class and filter it in one step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9339e563-880b-4fae-9cc6-3e8ba50d85d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%java\n",
    "package samples.quickstart;\n",
    "\n",
    "import org.apache.beam.sdk.Pipeline;\n",
    "import org.apache.beam.sdk.values.PCollection;\n",
    "import org.apache.beam.sdk.values.TypeDescriptors;\n",
    "import org.apache.beam.sdk.io.TextIO;\n",
    "import org.apache.beam.sdk.transforms.ParDo;\n",
    "import org.apache.beam.sdk.transforms.DoFn;\n",
    "import org.apache.beam.sdk.transforms.Filter;\n",
    "import org.apache.beam.sdk.transforms.DoFn.ProcessContext;\n",
    "import org.apache.beam.sdk.coders.DefaultCoder;\n",
    "import org.apache.beam.sdk.coders.AvroCoder;\n",
    "import org.apache.beam.sdk.transforms.SerializableFunction;\n",
    "\n",
    "import org.slf4j.Logger;\n",
    "import org.slf4j.LoggerFactory;\n",
    "\n",
    "public class ReadTerritories {\n",
    "    public static void main(String[] args) {\n",
    "        Pipeline p = Pipeline.create();\n",
    "\n",
    "        String territoriesInputFileName = \"datasets/northwind/CSV/territories/territories.csv\";\n",
    "        String outputsPrefix = \"/tmp/outputs\";\n",
    "\n",
    "        PCollection<Territory> territories = p\n",
    "            .apply(\"Read\", TextIO.read().from(territoriesInputFileName))\n",
    "            .apply(\"Parse\", ParDo.of(new ParseTerritories()))\n",
    "        ;                   \n",
    "        \n",
    "        territories.apply(TextIO.<Territory>writeCustomType().to(outputsPrefix).withFormatFunction(new SerializeTerritory()));\n",
    "        p.run().waitUntilFinish();\n",
    "    }\n",
    "    \n",
    "    @DefaultCoder(AvroCoder.class)\n",
    "    static class Territory {\n",
    "        Long territoryID;\n",
    "        String territoryName;\n",
    "        Long regionID;\n",
    "        \n",
    "        Territory() {}\n",
    "        \n",
    "        Territory(long territoryID, String territoryName, long regionID) {\n",
    "            this.territoryID = territoryID;\n",
    "            this.territoryName = territoryName;\n",
    "            this.regionID = regionID;\n",
    "        }\n",
    "        \n",
    "        @Override\n",
    "        public String toString() {\n",
    "            return String.format(\"(territoryID = %d, territoryName = %s, regionID = %d)\", territoryID, territoryName, regionID);\n",
    "        }\n",
    "\n",
    "    }\n",
    "    \n",
    "    static class SerializeTerritory implements SerializableFunction<Territory, String> {\n",
    "        @Override\n",
    "        public String apply(Territory input) {\n",
    "          return input.toString();\n",
    "        }\n",
    "    }\n",
    "\n",
    "    static class ParseTerritories extends DoFn<String, Territory> {\n",
    "        private static final Logger LOG = LoggerFactory.getLogger(ParseTerritories.class);\n",
    "\n",
    "        @ProcessElement\n",
    "        public void process(ProcessContext c) {\n",
    "            String[] columns = c.element().split(\",\");\n",
    "            try {\n",
    "                Long territoryID = Long.parseLong(columns[0].trim());\n",
    "                String territoryName = columns[1].trim();\n",
    "                Long regionID = Long.parseLong(columns[2].trim());\n",
    "                if (territoryName.startsWith(\"S\")) {\n",
    "                    c.output(new Territory(territoryID, territoryName, regionID));\n",
    "                }\n",
    "            } catch (ArrayIndexOutOfBoundsException | NumberFormatException e) {\n",
    "                LOG.info(\"ParseTerritories: parse error on '\" + c.element() + \"': \" + e.getMessage());\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    static class FilterTerritories extends DoFn<Territory, Territory> {\n",
    "        private static final Logger LOG = LoggerFactory.getLogger(FilterTerritories.class);\n",
    "\n",
    "        @ProcessElement\n",
    "        public void process(@Element Territory t, OutputReceiver<Territory> o) {\n",
    "            if (t.territoryID % 2 == 0 && t.territoryName.startsWith(\"S\")) {\n",
    "                o.output(t);\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362f1f94-6b7b-40d4-8284-77bcb9de04d1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### There are special methods like <font color='blue' face=\"Fixedsys, monospace\" size=\"+2\">whereFieldName</font> but they don't do anything differently than just using a regular <font color='green' size=\"+2\">ParDo</font>. This code doesn't actually run, but shows what it would look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d7320c-e979-4bde-a318-1cc4d1064268",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%java verbose\n",
    "package samples.quickstart;\n",
    "\n",
    "import org.apache.beam.sdk.Pipeline;\n",
    "import org.apache.beam.sdk.values.PCollection;\n",
    "import org.apache.beam.sdk.values.TypeDescriptors;\n",
    "import org.apache.beam.sdk.io.TextIO;\n",
    "import org.apache.beam.sdk.transforms.ParDo;\n",
    "import org.apache.beam.sdk.transforms.DoFn;\n",
    "//import org.apache.beam.sdk.transforms.Filter;\n",
    "import org.apache.beam.sdk.schemas.transforms.Filter;\n",
    "import org.apache.beam.sdk.transforms.DoFn.ProcessContext;\n",
    "import org.apache.beam.sdk.coders.DefaultCoder;\n",
    "import org.apache.beam.sdk.coders.AvroCoder;\n",
    "import org.apache.beam.sdk.transforms.SerializableFunction;\n",
    "import org.apache.beam.sdk.values.Row;\n",
    "\n",
    "import org.slf4j.Logger;\n",
    "import org.slf4j.LoggerFactory;\n",
    "\n",
    "public class ReadTerritories {\n",
    "    public static void main(String[] args) {\n",
    "        Pipeline p = Pipeline.create();\n",
    "\n",
    "        String territoriesInputFileName = \"datasets/northwind/CSV/territories/territories.csv\";\n",
    "        String outputsPrefix = \"/tmp/outputs\";\n",
    "\n",
    "        PCollection<Territory> territories = p\n",
    "            .apply(\"Read\", TextIO.read().from(territoriesInputFileName))\n",
    "            .apply(\"Parse\", ParDo.of(new ParseTerritories()))\n",
    "            .apply(\"Filter\", Filter.<Territory>create().whereFieldName(\"regionID\", (Long regionID) -> regionID == 1))\n",
    "        ;                   \n",
    "        \n",
    "        territories.apply(TextIO.<Territory>writeCustomType().to(outputsPrefix).withFormatFunction(new SerializeTerritory()));\n",
    "        p.run().waitUntilFinish();\n",
    "    }\n",
    "    \n",
    "    @DefaultCoder(AvroCoder.class)\n",
    "    static class Territory {\n",
    "        Long territoryID;\n",
    "        String territoryName;\n",
    "        Long regionID;\n",
    "        \n",
    "        Territory() {}\n",
    "        \n",
    "        Territory(long territoryID, String territoryName, long regionID) {\n",
    "            this.territoryID = territoryID;\n",
    "            this.territoryName = territoryName;\n",
    "            this.regionID = regionID;\n",
    "        }\n",
    "        \n",
    "        @Override\n",
    "        public String toString() {\n",
    "            return String.format(\"(territoryID = %d, territoryName = %s, regionID = %d)\", territoryID, territoryName, regionID);\n",
    "        }\n",
    "\n",
    "    }\n",
    "    \n",
    "    static class SerializeTerritory implements SerializableFunction<Territory, String> {\n",
    "        @Override\n",
    "        public String apply(Territory input) {\n",
    "          return input.toString();\n",
    "        }\n",
    "    }\n",
    "\n",
    "    static class ParseTerritories extends DoFn<String, Territory> {\n",
    "        private static final Logger LOG = LoggerFactory.getLogger(ParseTerritories.class);\n",
    "\n",
    "        @ProcessElement\n",
    "        public void process(ProcessContext c) {\n",
    "            String[] columns = c.element().split(\",\");\n",
    "            try {\n",
    "                Long territoryID = Long.parseLong(columns[0].trim());\n",
    "                String territoryName = columns[1].trim();\n",
    "                Long regionID = Long.parseLong(columns[2].trim());\n",
    "                c.output(new Territory(territoryID, territoryName, regionID));\n",
    "            } catch (ArrayIndexOutOfBoundsException | NumberFormatException e) {\n",
    "                LOG.info(\"ParseTerritories: parse error on '\" + c.element() + \"': \" + e.getMessage());\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505552a2-9b45-48b2-a0b1-5165573d33bf",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72891e0-232c-4a11-a7ec-1880c8c71425",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e5c5a3-327e-4279-af35-bcf57e7ab9f1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 5. Create multiple outputs from a single read."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bc9883-ba3b-4b67-ad1c-05b281ef9474",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <img src=\"python.png\" width=40 height=40 /><font color='cadetblue' size=\"+2\">Python</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93edcd4b-aac7-412a-a728-d772fd625f56",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Send the same data down multiple paths, such as to group it on two different keys with one read from the source. Also show how to read AVRO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfb9728",
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam import pvalue\n",
    "from apache_beam.io import ReadFromText, WriteToText\n",
    "import typing\n",
    "\n",
    "class Territory(typing.NamedTuple):\n",
    "    territoryid: int\n",
    "    territoryname: str\n",
    "    regionid: int\n",
    "beam.coders.registry.register_coder(Territory, beam.coders.RowCoder)\n",
    "        \n",
    "class TerritoryParseClass(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        yield Territory(int(element['territoryid']), element['territorydescription'], int(element['regionid']))\n",
    "\n",
    "territoriesfilename = 'datasets/northwind/AVRO/territories/territories.avro'\n",
    "with beam.Pipeline() as p:\n",
    "    territories = (p | 'Read' >> beam.io.ReadFromAvro(territoriesfilename)\n",
    "                     | 'Parse' >> beam.ParDo(TerritoryParseClass())\n",
    "                  )\n",
    "\n",
    "    # Branch 1\n",
    "    (territories \n",
    "         | 'Lowercase' >> beam.Map(lambda x : (x.territoryid, x.territoryname.lower(), x.regionid))\n",
    "         | 'Write Lower' >> WriteToText('/tmp/territories_lower.out')\n",
    "    )\n",
    "    \n",
    "    # Branch 2\n",
    "    (territories \n",
    "         | 'Uppercase' >> beam.Map(lambda x : (x.territoryid, x.territoryname.upper(), x.regionid))\n",
    "         | 'Write Upper' >> WriteToText('/tmp/territories_upper.out')\n",
    "    )\n",
    "\n",
    "! echo \"Lower\" && cat /tmp/territories_lower.out* && echo \"Upper\" && cat /tmp/territories_upper.out*\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b7374d-4d8b-4923-81b6-4c32e9e13c99",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Branching uses <font color='blue' face=\"Fixedsys, monospace\" size=\"+2\">TaggedOutput</font> in the <font color='green' size=\"+2\">ParDo</font> to split data into two different paths with different data on each. Also show how to read Parquet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7649fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam import pvalue\n",
    "from apache_beam.pvalue import TaggedOutput\n",
    "from apache_beam.io import ReadFromText, WriteToText\n",
    "import typing\n",
    "\n",
    "class Territory(typing.NamedTuple):\n",
    "    territoryid: int\n",
    "    territoryname: str\n",
    "    regionid: int\n",
    "beam.coders.registry.register_coder(Territory, beam.coders.RowCoder)\n",
    "        \n",
    "class OddEvenTerritoryParseClass(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        territoryid, territoryname, regionid = int(element['territoryid']), element['territoryname'], int(element['regionid'])\n",
    "        if int(regionid) % 2 == 0:\n",
    "            yield pvalue.TaggedOutput('Even', Territory(int(territoryid), territoryname, int(regionid)))\n",
    "        else:\n",
    "            yield TaggedOutput('Odd', Territory(int(territoryid), territoryname, int(regionid)))\n",
    "\n",
    "territoriesfilename = 'datasets/northwind/PARQUET/territories/territories.parquet'\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "    territories = p | 'Read' >> beam.io.ReadFromParquet(territoriesfilename) \n",
    "    # territories would return a tuple of the two tagged outputs\n",
    "    # unpack the two outputs to two separate variables to process differently\n",
    "    # x = territories | 'Parse' >> beam.ParDo(OddEvenTerritoryParseClass()).with_outputs(\"Even\", \"Odd\")\n",
    "    # print(x, type(x))\n",
    "    \n",
    "    evens, odds = territories | 'Parse' >> beam.ParDo(OddEvenTerritoryParseClass()).with_outputs(\"Even\", \"Odd\")\n",
    "    \n",
    "    evens | 'Write Even' >> WriteToText('/tmp/territories_even.out')\n",
    "    \n",
    "    odds | 'Write Odd' >> WriteToText('/tmp/territories_odd.out')\n",
    "\n",
    "! echo \"Evens\" && cat /tmp/territories_even.out* && echo \"Odds\" && cat /tmp/territories_odd.out*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5a3ae2-0add-4eaf-8515-d9420834fa34",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <img src=\"java.png\" width=40 height=40 /><font color='indigo' size=\"+2\">Java</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491ce4a7-eacc-41dd-b51b-1746546fcbcd",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Send the same output down two different paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f43ccc6-3890-4349-8482-c7c2498e9258",
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm /tmp/territories*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9847873-48ba-4b10-9e17-9bfe3004ed33",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%java nooutput\n",
    "package samples.quickstart;\n",
    "\n",
    "import org.apache.beam.sdk.Pipeline;\n",
    "import org.apache.beam.sdk.values.PCollection;\n",
    "import org.apache.beam.sdk.values.TypeDescriptors;\n",
    "import org.apache.beam.sdk.io.TextIO;\n",
    "import org.apache.beam.sdk.transforms.ParDo;\n",
    "import org.apache.beam.sdk.transforms.DoFn;\n",
    "import org.apache.beam.sdk.transforms.Filter;\n",
    "import org.apache.beam.sdk.transforms.DoFn.ProcessContext;\n",
    "import org.apache.beam.sdk.coders.DefaultCoder;\n",
    "import org.apache.beam.sdk.coders.AvroCoder;\n",
    "import org.apache.beam.sdk.transforms.SerializableFunction;\n",
    "import org.apache.beam.sdk.values.TupleTag;\n",
    "import org.apache.beam.sdk.values.PCollectionTuple;\n",
    "import org.apache.beam.sdk.values.TupleTagList;\n",
    "\n",
    "import org.slf4j.Logger;\n",
    "import org.slf4j.LoggerFactory;\n",
    "\n",
    "public class ReadTerritories {\n",
    "\n",
    "    public static void main(String[] args) {\n",
    "        Pipeline p = Pipeline.create();\n",
    "\n",
    "        String territoriesInputFileName = \"datasets/northwind/CSV/territories/territories.csv\";\n",
    "        String outputsPrefix = \"/tmp/outputs\";\n",
    "\n",
    "        PCollection<Territory> territories = p\n",
    "            .apply(\"Read\", TextIO.read().from(territoriesInputFileName))\n",
    "            .apply(\"Parse Territory\", ParDo.of(new ParseTerritories()))\n",
    "        ;                   \n",
    "        \n",
    "            \n",
    "        territories\n",
    "            .apply(\"Upper\", ParDo.of(new DoFn<Territory, Territory>() {\n",
    "                @ProcessElement\n",
    "                public void process(ProcessContext c) {\n",
    "                    Territory t = c.element();\n",
    "                    c.output(new Territory(t.territoryID, t.territoryName.toUpperCase(), t.regionID));\n",
    "                }\n",
    "            }))\n",
    "             .apply(TextIO.<Territory>writeCustomType().to(\"/tmp/territories_upper\").withFormatFunction(new SerializeTerritory()));\n",
    "\n",
    "        territories\n",
    "            .apply(\"Lower\", ParDo.of(new DoFn<Territory, Territory>() {\n",
    "                @ProcessElement\n",
    "                public void process(ProcessContext c) {\n",
    "                    Territory t = c.element();\n",
    "                    c.output(new Territory(t.territoryID, t.territoryName.toLowerCase(), t.regionID));\n",
    "                }\n",
    "            }))\n",
    "             .apply(TextIO.<Territory>writeCustomType().to(\"/tmp/territories_lower\").withFormatFunction(new SerializeTerritory()));\n",
    "\n",
    "        \n",
    "        p.run().waitUntilFinish();\n",
    "    }\n",
    "    \n",
    "    @DefaultCoder(AvroCoder.class)\n",
    "    static class Territory {\n",
    "        Long territoryID;\n",
    "        String territoryName;\n",
    "        Long regionID;\n",
    "        \n",
    "        Territory() {}\n",
    "        \n",
    "        Territory(long territoryID, String territoryName, long regionID) {\n",
    "            this.territoryID = territoryID;\n",
    "            this.territoryName = territoryName;\n",
    "            this.regionID = regionID;\n",
    "        }\n",
    "        \n",
    "        @Override\n",
    "        public String toString() {\n",
    "            return String.format(\"(territoryID = %d, territoryName = %s, regionID = %d)\", territoryID, territoryName, regionID);\n",
    "        }\n",
    "\n",
    "    }\n",
    "    \n",
    "    static class SerializeTerritory implements SerializableFunction<Territory, String> {\n",
    "        @Override\n",
    "        public String apply(Territory input) {\n",
    "          return input.toString();\n",
    "        }\n",
    "    }\n",
    "\n",
    "    static class ParseTerritories extends DoFn<String, Territory> {\n",
    "        private static final Logger LOG = LoggerFactory.getLogger(ParseTerritories.class);\n",
    "\n",
    "        @ProcessElement\n",
    "        public void process(ProcessContext c) {\n",
    "            String[] columns = c.element().split(\",\");\n",
    "            try {\n",
    "                Long territoryID = Long.parseLong(columns[0].trim());\n",
    "                String territoryName = columns[1].trim();\n",
    "                Long regionID = Long.parseLong(columns[2].trim());\n",
    "                c.output(new Territory(territoryID, territoryName, regionID));\n",
    "            } catch (ArrayIndexOutOfBoundsException | NumberFormatException e) {\n",
    "                LOG.info(\"ParseTerritoriesOddEvenSplit: parse error on '\" + c.element() + \"': \" + e.getMessage());\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae170dd2-fdd2-46fc-b741-5e8423269d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "! echo \"Upper\" && cat /tmp/territories_upper* && echo \"Lower\" && cat /tmp/territories_lower*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992c0f98-4b4b-4253-8045-4bb46bebfa7e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Branching uses <font color='blue' face=\"Fixedsys, monospace\" size=\"+2\">TupleTag</font> to split the output into two separate path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25158a5b-169d-4672-9683-38732dbca1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm /tmp/territories*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dde632-b934-4bf6-9a58-b551ab264385",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%java nooutput\n",
    "package samples.quickstart;\n",
    "\n",
    "import org.apache.beam.sdk.Pipeline;\n",
    "import org.apache.beam.sdk.values.PCollection;\n",
    "import org.apache.beam.sdk.values.TypeDescriptors;\n",
    "import org.apache.beam.sdk.io.TextIO;\n",
    "import org.apache.beam.sdk.transforms.ParDo;\n",
    "import org.apache.beam.sdk.transforms.DoFn;\n",
    "import org.apache.beam.sdk.transforms.Filter;\n",
    "import org.apache.beam.sdk.transforms.DoFn.ProcessContext;\n",
    "import org.apache.beam.sdk.coders.DefaultCoder;\n",
    "import org.apache.beam.sdk.coders.AvroCoder;\n",
    "import org.apache.beam.sdk.transforms.SerializableFunction;\n",
    "import org.apache.beam.sdk.values.TupleTag;\n",
    "import org.apache.beam.sdk.values.PCollectionTuple;\n",
    "import org.apache.beam.sdk.values.TupleTagList;\n",
    "\n",
    "import org.slf4j.Logger;\n",
    "import org.slf4j.LoggerFactory;\n",
    "\n",
    "public class ReadTerritories {\n",
    "\n",
    "    final static TupleTag<Territory> evenTag = new TupleTag<Territory>() {};\n",
    "    final static TupleTag<Territory> oddTag = new TupleTag<Territory>() {};\n",
    "\n",
    "    public static void main(String[] args) {\n",
    "        Pipeline p = Pipeline.create();\n",
    "\n",
    "        String territoriesInputFileName = \"territories.csv\";\n",
    "        String outputsPrefix = \"/tmp/outputs\";\n",
    "\n",
    "        PCollectionTuple territories = p\n",
    "            .apply(\"Read\", TextIO.read().from(territoriesInputFileName))\n",
    "            .apply(\"OddEvenSplit\", ParDo.of(new ParseTerritoriesOddEvenSplit()).withOutputTags(evenTag, TupleTagList.of(oddTag)))\n",
    "        ;                   \n",
    "        \n",
    "        PCollection<Territory> evenTerritories = territories.get(evenTag);\n",
    "        evenTerritories.apply(TextIO.<Territory>writeCustomType().to(outputsPrefix + \"_even\").withFormatFunction(new SerializeTerritory()));\n",
    "\n",
    "        PCollection<Territory> oddTerritories = territories.get(oddTag);\n",
    "        oddTerritories.apply(TextIO.<Territory>writeCustomType().to(outputsPrefix + \"_odd\").withFormatFunction(new SerializeTerritory()));\n",
    "        p.run().waitUntilFinish();\n",
    "    }\n",
    "    \n",
    "    @DefaultCoder(AvroCoder.class)\n",
    "    static class Territory {\n",
    "        Long territoryID;\n",
    "        String territoryName;\n",
    "        Long regionID;\n",
    "        \n",
    "        Territory() {}\n",
    "        \n",
    "        Territory(long territoryID, String territoryName, long regionID) {\n",
    "            this.territoryID = territoryID;\n",
    "            this.territoryName = territoryName;\n",
    "            this.regionID = regionID;\n",
    "        }\n",
    "        \n",
    "        @Override\n",
    "        public String toString() {\n",
    "            return String.format(\"(territoryID = %d, territoryName = %s, regionID = %d)\", territoryID, territoryName, regionID);\n",
    "        }\n",
    "\n",
    "    }\n",
    "    \n",
    "    static class SerializeTerritory implements SerializableFunction<Territory, String> {\n",
    "        @Override\n",
    "        public String apply(Territory input) {\n",
    "          return input.toString();\n",
    "        }\n",
    "    }\n",
    "\n",
    "    static class ParseTerritoriesOddEvenSplit extends DoFn<String, Territory> {\n",
    "        private static final Logger LOG = LoggerFactory.getLogger(ParseTerritoriesOddEvenSplit.class);\n",
    "\n",
    "        @ProcessElement\n",
    "        public void process(ProcessContext c) {\n",
    "\n",
    "\n",
    "            String[] columns = c.element().split(\",\");\n",
    "            try {\n",
    "                Long territoryID = Long.parseLong(columns[0].trim());\n",
    "                String territoryName = columns[1].trim();\n",
    "                Long regionID = Long.parseLong(columns[2].trim());\n",
    "                if (regionID % 2 == 0) {\n",
    "                    c.output(evenTag, new Territory(territoryID, territoryName, regionID));\n",
    "                } else {\n",
    "                    c.output(oddTag, new Territory(territoryID, territoryName, regionID));\n",
    "                }\n",
    "            } catch (ArrayIndexOutOfBoundsException | NumberFormatException e) {\n",
    "                LOG.info(\"ParseTerritoriesOddEvenSplit: parse error on '\" + c.element() + \"': \" + e.getMessage());\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6d6ae9-a392-4d7f-9222-017e3f2a8d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "! echo \"Odd\" && cat /tmp/outputs_odd* && echo \"Even\" && cat /tmp/outputs_even*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6574254-039b-49ee-b81d-c12aec4d740d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a64199d-86e5-4a52-b8d5-e56b34685278",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec19b5d-5bcf-4edb-ad94-124e7489604e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 6. Group and Join"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c69d69-d541-4d25-aae0-6a165c2f6531",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <img src=\"python.png\" width=40 height=40 /><font color='cadetblue' size=\"+2\">Python</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3040dd12-e0d2-4eeb-ba6f-ec490542e822",
   "metadata": {
    "tags": []
   },
   "source": [
    "### <font color='blue' face=\"Fixedsys, monospace\" size=\"+2\">WithKeys</font> will reshape your data first, then <font color='blue' face=\"Fixedsys, monospace\" size=\"+2\">GroupByKey</font> will cluster the elements as a list under each unique key. The data must be in a <font color='green' size=\"+2\">KV</font> tuple pair first. Also not how to read a JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf6f82f-8a76-49b2-9fc6-d5c8c9651d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.io import ReadFromText\n",
    "import json\n",
    "import typing\n",
    "\n",
    "class Territory(typing.NamedTuple):\n",
    "    territoryid: int\n",
    "    territoryname: str\n",
    "    regionid: int\n",
    "beam.coders.registry.register_coder(Territory, beam.coders.RowCoder)\n",
    "        \n",
    "class TerritoryParseClass(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        territoryid, territoryname, regionid = int(element['territoryid']), element['territoryname'], int(element['regionid'])\n",
    "        yield Territory(int(territoryid), territoryname, int(regionid))\n",
    "\n",
    "territoriesfilename = 'datasets/northwind/JSON/territories/territories.json'\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "    territories = (\n",
    "                  p | 'Read Territories' >> ReadFromText(territoriesfilename)\n",
    "                    # | 'From json' >> beam.Map(json.loads)\n",
    "                    # | 'Parse Territories' >> beam.ParDo(TerritoryParseClass())\n",
    "                    # | 'Territories With Keys' >> beam.util.WithKeys(lambda x : x.regionid)\n",
    "                    # | 'Group Territories' >> beam.GroupByKey() \n",
    "                  )\n",
    "    territories | 'Print Territories' >> beam.Map(print)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4986d67f-7a28-4323-8943-cbab751ee1a6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### <font color='blue' face=\"Fixedsys, monospace\" size=\"+2\">Combine</font> is equivalent to a SQL <font color='blue' face=\"Fixedsys, monospace\" size=\"+2\">GROUP BY</font> query\n",
    "### <font color='blue' face=\"Fixedsys, monospace\" size=\"+2\">SELECT key, sum(value) as total FROM source GROUP BY key</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c53775",
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "    data = (\n",
    "        p | 'Create' >> beam.Create([('a', 10), ('a', 20), ('b', 30), ('b', 40), ('c', 50), ('a', 60)])\n",
    "          #| 'Combine' >> beam.CombinePerKey(sum)\n",
    "        | beam.GroupByKey()\n",
    "          | 'Print' >> beam.Map(print)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e542b61e-9a43-4c33-b05b-b18ea5d0ac39",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Custom <font color='blue' face=\"Fixedsys, monospace\" size=\"+2\">CombineFn</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e60d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "class CustomCombine(beam.CombineFn):\n",
    "    \"\"\"\n",
    "    This custom combiner will calculate the max of the first element, sum of the second element and a count of total elements\n",
    "    The final step will also return the average of the second element.\n",
    "    \"\"\"\n",
    "    def create_accumulator(self):\n",
    "        # method defining how to create an empty accumulator\n",
    "        return dict()\n",
    "\n",
    "    def add_input(self, accumulator, input):\n",
    "        # get the input and split it up for easier manipulation\n",
    "        k, v = input\n",
    "        # get the values from the accumulator for the input key or initialize it if it's the first time we see this key\n",
    "        m, s, c = accumulator.get(k, (0, 0, 0))\n",
    "\n",
    "        # take the max for the first element of the tuple and sum the second element and count for the third\n",
    "        accumulator[k] = (v[0] if v[0] > m else m, s + v[1], c + 1)\n",
    "        return accumulator\n",
    "\n",
    "    def merge_accumulators(self, accumulators):\n",
    "        # merge the accumulators from the various workers once they have finished accumulating locally\n",
    "        merged = dict()\n",
    "        for accum in accumulators:\n",
    "          for k, v in accum.items():\n",
    "            m, s, c = merged.get(k, (0, 0, 0))\n",
    "            merged[k] = (v[0] if v[0] > m else m, s + v[1], c + v[2])\n",
    "        return merged\n",
    "\n",
    "    def extract_output(self, accumulator):\n",
    "        # called when all the works accumulators have been merge to render the final output\n",
    "        # return the max, the sum, the count and the average for the key\n",
    "        return {k : (v[0], v[1], v[2], v[1]/v[2]) for k, v in accumulator.items()}\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "    data = (\n",
    "        p | 'Create' >> beam.Create([('a', (1, 10)), ('a', (2, 20)), \n",
    "                                     ('b', (3, 30)), ('c', (5, 50)), \n",
    "                                     ('b', (4, 40)), ('a', (6, 60))])\n",
    "          | 'Combine' >> beam.CombineGlobally(CustomCombine())\n",
    "          | 'Print' >> beam.Map(print)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97109e52-fbf6-42eb-8266-fec461471367",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create a nested repeating output\n",
    "### First create a dataset. Here is Python code for the equivalent bq command of <font color='blue' face=\"Fixedsys, monospace\" size=\"+2\">bq mk dataflow</font>.\n",
    "<br>or the SQL commnd<br>\n",
    "<font color='blue' face=\"Fixedsys, monospace\" size=\"+2\">create table dataflow.region_territory\n",
    "(regionid int\n",
    ", regionname string\n",
    ", territories array<struct<territoryid int, territoryname string>>\n",
    ")\n",
    "</font>\n",
    "<br>Make sure to use the proper project ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cfbe66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same as doing bq mk dataflow\n",
    "\n",
    "from google.cloud import bigquery\n",
    "\n",
    "# Construct a BigQuery client object.\n",
    "client = bigquery.Client()\n",
    "\n",
    "PROJECT_ID = 'qwiklabs-gcp-04-b1b7cded1c4b'\n",
    "dataset_id = f\"{PROJECT_ID}.dataflow\" #.format(client.project)\n",
    "\n",
    "try:\n",
    "    client.get_dataset(dataset_id)  # Make an API request.\n",
    "    print(\"Dataset {} already exists\".format(dataset_id))\n",
    "except:\n",
    "    print(\"Dataset {} is not found\".format(dataset_id))\n",
    "    dataset = bigquery.Dataset(dataset_id)\n",
    "    dataset.location = \"US\"\n",
    "    dataset = client.create_dataset(dataset, timeout=30)  # Make an API request.\n",
    "    print(\"Created dataset {}.{}\".format(client.project, dataset.dataset_id))\n",
    "    \n",
    "    \n",
    "\n",
    "schema = [\n",
    "    bigquery.SchemaField(\"regionid\", \"INTEGER\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"regionname\", \"STRING\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"territories\", \"RECORD\", mode=\"REPEATED\", \n",
    "            fields=[\n",
    "                    bigquery.SchemaField(\"territoryid\", \"STRING\", mode=\"REQUIRED\"),\n",
    "                    bigquery.SchemaField(\"territoryname\", \"STRING\", mode=\"REQUIRED\")\n",
    "                   ]\n",
    "                        )\n",
    "]\n",
    "\n",
    "# create table dataflow.region_territory\n",
    "# (regionid NUMERIC\n",
    "# ,regionname STRING\n",
    "# ,territories ARRAY<STRUCT<territoryid NUMERIC, territoryname STRING>>)\n",
    "\n",
    "table_id = f\"{PROJECT_ID}.dataflow.region_territory\"\n",
    "\n",
    "try:\n",
    "    table = client.get_table(table_id)  # Make an API request.\n",
    "    print(\"Table {} already exists.\".format(table_id))\n",
    "    print(table)\n",
    "except:\n",
    "    table = bigquery.Table(table_id, schema=schema)\n",
    "    table = client.create_table(table)  # Make an API request.\n",
    "    print(\"Table {} created.\".format(table_id))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f289745-bf0e-473f-81f0-943bc1232ba0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### The code here is tricky: \n",
    "### First parse the two tables into <font color='green' size=\"+2\">tuples</font>, <font color='black' face=\"Fixedsys, monospace\" size=\"+1\">(regionid, regionname)</font> & <font color='black' face=\"Fixedsys, monospace\" size=\"+1\">(regionid, {'territoryid':territoryid, 'territoryname':territoryname})</font>\n",
    "### <font color='blue' face=\"Fixedsys, monospace\" size=\"+2\">CoGroupByKey</font> yields a shape like <font color='black' face=\"Fixedsys, monospace\" size=\"+1\">(regionid, {'regions':['regionname'], 'territories':[{}])</font> so we need to reshape it to <font color='green' size=\"+2\">dicts</font> to write it to BQ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce154df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.io import ReadFromText\n",
    "\n",
    "class RegionParseTuple(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        regionid, regionname = element.split(',')\n",
    "        yield (int(regionid), regionname) # Can also use yield instead of returning a list\n",
    "\n",
    "class TerritoryParseTuple(beam.DoFn):\n",
    "    # split territory into KV pair of (regionid, (territoryid, territoryname))\n",
    "    def process(self, element):\n",
    "        territoryid, territoryname, regionid = element.split(',')\n",
    "        yield(int(regionid), {'territoryid': int(territoryid), 'territoryname':territoryname})\n",
    "\n",
    "class SortTerritories(beam.DoFn):\n",
    "    #{'regionid': 1, 'regionname': 'Eastern', 'territories': [{'territoryid': 1730, 'territoryname': 'Bedford'}, \n",
    "    def process(self, element):\n",
    "        territories = element['territories']\n",
    "        element['territories'] = sorted(territories, key = lambda x : x['territoryid'])\n",
    "        yield element\n",
    "\n",
    "regionsfilename = 'datasets/northwind/CSV/regions/regions.csv'\n",
    "territoriesfilename = 'datasets/northwind/CSV/territories/territories.csv'\n",
    "\n",
    "PROJECT_ID = 'qwiklabs-gcp-03-66d8bf72e256'\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "    regions = (\n",
    "              p | 'Read Regions' >> ReadFromText(regionsfilename)\n",
    "                | 'Parse Regions' >> beam.ParDo(RegionParseTuple())\n",
    "              )\n",
    "    regions | 'Print Regions' >> beam.Map(print)\n",
    "        \n",
    "    territories = (\n",
    "                  p | 'Read Territories' >> ReadFromText('territories.csv')\n",
    "                    | 'Parse Territories' >> beam.ParDo(TerritoryParseTuple())\n",
    "                  )\n",
    "    territories | 'Print Territories' >> beam.Map(print)\n",
    "\n",
    "    nested = ( \n",
    "        {'regions':regions, 'territories':territories} \n",
    "              | 'Nest territories into regions' >> beam.CoGroupByKey()\n",
    "              | 'Reshape to dict' >> beam.Map(lambda x : {'regionid': x[0], 'regionname': x[1]['regions'][0], \n",
    "                                                         'territories': x[1]['territories']})\n",
    "              | 'Sort by territoryid' >> beam.ParDo(SortTerritories())\n",
    "    )\n",
    "    nested | 'Print' >> beam.Map(print)\n",
    "    nested | 'Write nested region_territory to BQ' >> beam.io.WriteToBigQuery('region_territory', dataset = 'dataflow'\n",
    "                                                                             , project = PROJECT_ID\n",
    "                                                                             , method = 'STREAMING_INSERTS'\n",
    "                                                                             )\n",
    "             \n",
    "#help(beam.io.WriteToBigQuery)    \n",
    "#(1, {'regions': ['Eastern'], 'territories': [{'territoryid': 1730, 'territoryname': 'Bedford'}, {'territoryid': 1581, 'territoryname': 'Westboro'}, {'territoryid': 1833, 'territoryname': 'Georgetow'}, {'territoryid': 2116, 'territoryname': 'Bosto\n",
    "#{'regionid': 1, 'regionname':'Eastern', 'territories' : [{'territoryid':1, 'territoryname':'name1'}, {}, {}]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ae0097-3880-4cbc-9010-078fb1aa10df",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Query the table to show it was populated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2411903b-871d-487c-8324-089f330cb701",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "# Construct a BigQuery client object.\n",
    "client = bigquery.Client()\n",
    "\n",
    "table_id = f\"{PROJECT_ID}.dataflow.region_territory\"\n",
    "\n",
    "query_job = client.query(f\"\"\"SELECT * FROM {table_id}\"\"\")\n",
    "\n",
    "results = query_job.result()  # Waits for job to complete.\n",
    "display(list(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168bc155-d9d3-419e-8bd8-6b5a41718bdf",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Helper functions to make a generic transform to nest children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd6c54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "class NestJoin(beam.PTransform):\n",
    "    '''\n",
    "    This PTransform will take a dictionary to the left of the | which will be the collection of the two\n",
    "    PCollections you want to join together. Both must be a dictionary. You will then pass in the name of each\n",
    "    PCollection and the key to join them on.\n",
    "    It will automatically reshape the two dicts into tuples of (key, dict) where it removes the key from each dict\n",
    "    It then CoGroups them and reshapes the tuple into a dict ready for insertion to a BQ table\n",
    "    '''\n",
    "    def __init__(self, parent_pipeline_name, parent_key, child_pipeline_name, child_key, sort = lambda x : x):\n",
    "        self.parent_pipeline_name = parent_pipeline_name\n",
    "        self.parent_key = parent_key\n",
    "        self.child_pipeline_name = child_pipeline_name\n",
    "        self.child_key = child_key\n",
    "        self.sort = sort\n",
    "\n",
    "    def expand(self, pcols):\n",
    "        def reshapeToKV(item, key):\n",
    "            # pipeline object should be a dictionary\n",
    "            item1 = item.copy()\n",
    "            del item1[key]\n",
    "            return (item[key], item1)\n",
    "\n",
    "        def reshapeCoGroupToDict(item):\n",
    "            ret = {self.parent_key : item[0]}\n",
    "            ret.update(item[1][self.parent_pipeline_name][0])\n",
    "            ret[self.child_pipeline_name] = item[1][self.child_pipeline_name]\n",
    "            return ret\n",
    "\n",
    "        return (\n",
    "                {\n",
    "                self.parent_pipeline_name : pcols[self.parent_pipeline_name] | f'Convert {self.parent_pipeline_name} to KV' \n",
    "                    >> beam.Map(reshapeToKV, self.parent_key)\n",
    "                ,self.child_pipeline_name : pcols[self.child_pipeline_name] | f'Convert {self.child_pipeline_name} to KV'\n",
    "                    >> beam.Map(reshapeToKV, self.child_key)\n",
    "                } | f'CoGroupByKey {self.child_pipeline_name} into {self.parent_pipeline_name}'\n",
    "                    >> beam.CoGroupByKey()\n",
    "                  | f'Reshape to dictionary'\n",
    "                    >> beam.Map(reshapeCoGroupToDict)\n",
    "                  | f'Sort the nested data' >> beam.Map(self.sort)\n",
    "            \n",
    "        )\n",
    "\n",
    "class RegionParseDict(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        regionid, regionname = element.split(',')\n",
    "        yield {'regionid':int(regionid), 'regionname':regionname.title()}\n",
    "      \n",
    "class TerritoryParseDict(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        territoryid, territoryname, regionid = element.split(',')\n",
    "        yield {'territoryid':int(territoryid), 'territoryname' : territoryname, 'regionid':int(regionid)}\n",
    "    \n",
    "regionsfilename = 'datasets/northwind/CSV/regions/regions.csv'\n",
    "territoriesfilename = 'datasets/northwind/CSV/territories/territories.csv'\n",
    "\n",
    "def sort_territories(element):\n",
    "    territories = element['territories']\n",
    "    element['territories'] = list(sorted(territories, key = lambda x : x['territoryid']))\n",
    "    return element\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "    regions = (\n",
    "              p | 'Read Regions' >> ReadFromText(regionsfilename)\n",
    "                | 'Parse Regions' >> beam.ParDo(RegionParseDict())\n",
    "                #| 'Print Regions' >> beam.Map(print)\n",
    "              )\n",
    "        \n",
    "    territories = (\n",
    "                  p | 'Read Territories' >> ReadFromText('territories.csv')\n",
    "                    | 'Parse Territories' >> beam.ParDo(TerritoryParseDict())\n",
    "                    #| 'Print Territories' >> beam.Map(print)\n",
    "                  )\n",
    "\n",
    "    nestjoin = {'regions':regions, 'territories':territories} | NestJoin('regions', 'regionid', 'territories', 'regionid', sort = sort_territories)\n",
    "    nestjoin | 'Print Nest Join' >> beam.Map(print)\n",
    "#     nestjoin | 'Write nested region_territory to BQ' >> beam.io.WriteToBigQuery('region_territory', dataset = 'dataflow'\n",
    "#                                                                              , project = PROJECT_ID\n",
    "#                                                                              , method = 'STREAMING_INSERTS'\n",
    "#                                                                              )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8bdeb1-854c-48df-b8e8-d3f0c81e3b46",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Simulate an Outer Join with <font color='blue' face=\"Fixedsys, monospace\" size=\"+2\">CoGroup</font>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0108d942-1b57-461e-83e7-70574e318f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "class LeftJoin(beam.PTransform):\n",
    "    '''\n",
    "    This PTransform will take a dictionary to the left of the | which will be the collection of the two\n",
    "    PCollections you want to join together. Both must be a dictionary. You will then pass in the name of each\n",
    "    PCollection and the key to join them on.\n",
    "    It will automatically reshape the two dicts into tuples of (key, dict) where it removes the key from each dict\n",
    "    It then CoGroups them and reshapes the tuple into a dict ready for insertion to a BQ table\n",
    "    '''\n",
    "    def __init__(self, parent_pipeline_name, parent_key, child_pipeline_name, child_key):\n",
    "        self.parent_pipeline_name = parent_pipeline_name\n",
    "        self.parent_key = parent_key\n",
    "        self.child_pipeline_name = child_pipeline_name\n",
    "        self.child_key = child_key\n",
    "\n",
    "    def expand(self, pcols):\n",
    "        def reshapeToKV(item, key):\n",
    "            # pipeline object should be a dictionary\n",
    "            item1 = item.copy()\n",
    "            del item1[key]\n",
    "            return (item[key], item1)\n",
    "\n",
    "        def reshapeCoGroupToFlatDict(item):\n",
    "            parent = {self.parent_key : item[0]}\n",
    "            parent.update(item[1][self.parent_pipeline_name][0])\n",
    "            ret = []\n",
    "            for row1 in item[1][self.child_pipeline_name]:\n",
    "                row = parent.copy()\n",
    "                row.update(row1)\n",
    "                ret.append(row)\n",
    "            return ret\n",
    "\n",
    "        return (\n",
    "                {\n",
    "                self.parent_pipeline_name : pcols[self.parent_pipeline_name] | f'Convert {self.parent_pipeline_name} to KV' \n",
    "                    >> beam.Map(reshapeToKV, self.parent_key)\n",
    "                ,self.child_pipeline_name : pcols[self.child_pipeline_name] | f'Convert {self.child_pipeline_name} to KV'\n",
    "                    >> beam.Map(reshapeToKV, self.child_key)\n",
    "                } | f'CoGroupByKey {self.child_pipeline_name} into {self.parent_pipeline_name}'\n",
    "                    >> beam.CoGroupByKey()\n",
    "                  | f'Reshape to dictionary'\n",
    "                    >> beam.FlatMap(reshapeCoGroupToFlatDict)\n",
    "        )\n",
    "\n",
    "class RegionParseDict(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        regionid, regionname = element.split(',')\n",
    "        yield {'regionid':int(regionid), 'regionname':regionname.title()}\n",
    "\n",
    "class TerritoryParseDict(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        territoryid, territoryname, regionid = element.split(',')\n",
    "        yield {'territoryid':int(territoryid), 'territoryname' : territoryname, 'regionid':int(regionid)}\n",
    "    \n",
    "regionsfilename = 'datasets/northwind/CSV/regions/regions.csv'\n",
    "territoriesfilename = 'datasets/northwind/CSV/territories/territories.csv'\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "    regions = (\n",
    "              p | 'Read Regions' >> ReadFromText(regionsfilename)\n",
    "                | 'Parse Regions' >> beam.ParDo(RegionParseDict())\n",
    "              )\n",
    "#    regions  | 'Print Regions' >> beam.Map(print)\n",
    "        \n",
    "    territories = (\n",
    "                  p | 'Read Territories' >> ReadFromText('territories.csv')\n",
    "                    | 'Parse Territories' >> beam.ParDo(TerritoryParseDict())\n",
    "                  )\n",
    "#    territories | 'Print Territories' >> beam.Map(print)\n",
    "\n",
    "    nestjoin = {'regions':regions, 'territories':territories} | LeftJoin('regions', 'regionid', 'territories', 'regionid')\n",
    "    nestjoin | 'Print Nest Join' >> beam.Map(print)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2dbd91-e4b8-4bd1-8c75-89064613bbd8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## <img src=\"java.png\" width=40 height=40 /><font color='indigo' size=\"+2\">Java</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167426fd-5abf-40b0-a06d-bfabda42f6c3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### For Java you don't need to group into KV shape first, instead you could use the <font color='blue' face=\"Fixedsys, monospace\" size=\"+2\">Group</font> and <font color='blue' face=\"Fixedsys, monospace\" size=\"+2\">Select</font> methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de985dc-b8b4-4aa0-a152-715056b2dd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%java \n",
    "package samples.quickstart;\n",
    "\n",
    "import org.apache.beam.sdk.Pipeline;\n",
    "import org.apache.beam.sdk.values.PCollection;\n",
    "import org.apache.beam.sdk.values.TypeDescriptors;\n",
    "import org.apache.beam.sdk.io.TextIO;\n",
    "import org.apache.beam.sdk.transforms.ParDo;\n",
    "import org.apache.beam.sdk.transforms.DoFn;\n",
    "import org.apache.beam.sdk.transforms.Filter;\n",
    "import org.apache.beam.sdk.transforms.DoFn.ProcessContext;\n",
    "import org.apache.beam.sdk.coders.DefaultCoder;\n",
    "import org.apache.beam.sdk.coders.AvroCoder;\n",
    "import org.apache.beam.sdk.transforms.SerializableFunction;\n",
    "import org.apache.beam.sdk.schemas.transforms.Group;\n",
    "import org.apache.beam.sdk.schemas.transforms.Select;\n",
    "import org.apache.beam.sdk.transforms.*;\n",
    "import org.apache.beam.sdk.schemas.JavaFieldSchema;\n",
    "import org.apache.beam.sdk.schemas.annotations.DefaultSchema;\n",
    "import org.apache.beam.sdk.values.Row;\n",
    "import org.apache.beam.sdk.schemas.transforms.Convert;\n",
    "\n",
    "import org.slf4j.Logger;\n",
    "import org.slf4j.LoggerFactory;\n",
    "\n",
    "public class GroupTerritories {\n",
    "    public static void main(String[] args) {\n",
    "        Pipeline p = Pipeline.create();\n",
    "\n",
    "        String territoriesInputFileName = \"datasets/northwind/CSV/territories/territories.csv\";\n",
    "        String outputsPrefix = \"/tmp/outputs\";\n",
    "\n",
    "        PCollection<Result> territories = p\n",
    "            .apply(\"Read\", TextIO.read().from(territoriesInputFileName))\n",
    "            .apply(\"Parse\", ParDo.of(new ParseTerritories()))\n",
    "            .apply(\"GroupBy regionID\", Group.<Territory>byFieldNames(\"regionID\")\n",
    "                                            .aggregateField(\"territoryID\", Count.combineFn(), \"cnt\"))\n",
    "            .apply(\"Select\", Select.fieldNames(\"key.regionID\", \"value.cnt\"))\n",
    "            .apply(Convert.fromRows(Result.class))\n",
    "                   \n",
    "        ;                   \n",
    "        \n",
    "        territories.apply(TextIO.<Result>writeCustomType().to(outputsPrefix).withFormatFunction(new SerializeResult()));\n",
    "        p.run().waitUntilFinish();\n",
    "    }\n",
    "    \n",
    "    @DefaultCoder(AvroCoder.class)\n",
    "    @DefaultSchema(JavaFieldSchema.class)\n",
    "    static class Territory {\n",
    "        Long territoryID;\n",
    "        String territoryName;\n",
    "        Long regionID;\n",
    "        \n",
    "        Territory() {}\n",
    "        \n",
    "        Territory(long territoryID, String territoryName, long regionID) {\n",
    "            this.territoryID = territoryID;\n",
    "            this.territoryName = territoryName;\n",
    "            this.regionID = regionID;\n",
    "        }\n",
    "        \n",
    "        @Override\n",
    "        public String toString() {\n",
    "            return String.format(\"(territoryID = %d, territoryName = %s, regionID = %d)\", territoryID, territoryName, regionID);\n",
    "        }\n",
    "\n",
    "    }\n",
    "    \n",
    "    static class SerializeTerritory implements SerializableFunction<Territory, String> {\n",
    "        @Override\n",
    "        public String apply(Territory input) {\n",
    "          return input.toString();\n",
    "        }\n",
    "    }\n",
    "\n",
    "    static class ParseTerritories extends DoFn<String, Territory> {\n",
    "        private static final Logger LOG = LoggerFactory.getLogger(ParseTerritories.class);\n",
    "\n",
    "        @ProcessElement\n",
    "        public void process(ProcessContext c) {\n",
    "            String[] columns = c.element().split(\",\");\n",
    "            try {\n",
    "                Long territoryID = Long.parseLong(columns[0].trim());\n",
    "                String territoryName = columns[1].trim();\n",
    "                Long regionID = Long.parseLong(columns[2].trim());\n",
    "                c.output(new Territory(territoryID, territoryName, regionID));\n",
    "            } catch (ArrayIndexOutOfBoundsException | NumberFormatException e) {\n",
    "                LOG.info(\"ParseTerritories: parse error on '\" + c.element() + \"': \" + e.getMessage());\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    @DefaultCoder(AvroCoder.class)\n",
    "    @DefaultSchema(JavaFieldSchema.class)\n",
    "    static class Result {\n",
    "        Long regionID;\n",
    "        Long cnt;\n",
    "        \n",
    "        Result() {}\n",
    "        \n",
    "        Result(Long regionID, Long cnt) {\n",
    "            this.regionID = regionID;\n",
    "            this.cnt = cnt;\n",
    "        }\n",
    "        \n",
    "        @Override\n",
    "        public String toString() {\n",
    "            return String.format(\"(regionid = %d, cnt = %d)\", regionID, cnt);\n",
    "        }\n",
    "    }\n",
    "    static class SerializeResult implements SerializableFunction<Result, String> {\n",
    "        @Override\n",
    "        public String apply(Result input) {\n",
    "          return input.toString();\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be08fffa-0c55-4c8a-8469-a03d87facb3b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### But for the <font color='blue' face=\"Fixedsys, monospace\" size=\"+2\">JOIN</font> extension function you still need to shape the data into a KV pair and then unnest it when done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0030bb71-8ee0-48e6-aa39-284b2c65c042",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%java\n",
    "package samples.quickstart;\n",
    "\n",
    "import org.apache.beam.sdk.Pipeline;\n",
    "import org.apache.beam.sdk.values.PCollection;\n",
    "import org.apache.beam.sdk.values.TypeDescriptors;\n",
    "import org.apache.beam.sdk.io.TextIO;\n",
    "import org.apache.beam.sdk.transforms.ParDo;\n",
    "import org.apache.beam.sdk.transforms.DoFn;\n",
    "import org.apache.beam.sdk.transforms.Filter;\n",
    "import org.apache.beam.sdk.transforms.DoFn.ProcessContext;\n",
    "import org.apache.beam.sdk.coders.DefaultCoder;\n",
    "import org.apache.beam.sdk.coders.AvroCoder;\n",
    "import org.apache.beam.sdk.transforms.SerializableFunction;\n",
    "import org.apache.beam.sdk.schemas.transforms.Group;\n",
    "import org.apache.beam.sdk.schemas.transforms.Select;\n",
    "import org.apache.beam.sdk.transforms.*;\n",
    "import org.apache.beam.sdk.schemas.JavaFieldSchema;\n",
    "import org.apache.beam.sdk.schemas.annotations.DefaultSchema;\n",
    "import org.apache.beam.sdk.values.Row;\n",
    "import org.apache.beam.sdk.schemas.transforms.Convert;\n",
    "import org.apache.beam.sdk.extensions.joinlibrary.Join;\n",
    "import org.apache.beam.sdk.values.KV;\n",
    "import org.apache.beam.sdk.transforms.WithKeys;\n",
    "\n",
    "import org.slf4j.Logger;\n",
    "import org.slf4j.LoggerFactory;\n",
    "\n",
    "public class JoinTerritories {\n",
    "    public static void main(String[] args) {\n",
    "        Pipeline p = Pipeline.create();\n",
    "        \n",
    "        String regionsInputFileName = \"datasets/northwind/CSV/regions/regions.csv\";\n",
    "        String territoriesInputFileName = \"datasets/northwind/CSV/territories/territories.csv\";\n",
    "        String outputsPrefix = \"/tmp/outputs\";\n",
    "\n",
    "        PCollection<KV<Long, Region>> regions = p\n",
    "            .apply(\"Read Regions\", TextIO.read().from(regionsInputFileName))\n",
    "            .apply(\"Parse Regions\", ParDo.of(new CSVToRegion()))\n",
    "            .apply(\"Regions KV\", WithKeys.of(new SerializableFunction<Region, Long>() {\n",
    "                @Override\n",
    "                public Long apply(Region r) {\n",
    "                  return r.regionid;\n",
    "                }}));\n",
    "          ;\n",
    "        \n",
    "        PCollection<KV<Long, Territory>> territories = p\n",
    "            .apply(\"Read Territories\", TextIO.read().from(territoriesInputFileName))\n",
    "            .apply(\"Parse Territories\", ParDo.of(new ParseTerritories()))\n",
    "            .apply(\"Territories KV\", WithKeys.of(new SerializableFunction<Territory, Long>() {\n",
    "                @Override\n",
    "                public Long apply(Territory t) {\n",
    "                  return t.regionid;\n",
    "                }}));\n",
    "          ;\n",
    "        \n",
    "        PCollection<KV<Long, KV<Region, Territory>>> result =\n",
    "            Join.innerJoin(regions, territories);  \n",
    "        \n",
    "        PCollection<Result> result2 = result\n",
    "        \n",
    "            .apply(\"Unnest KV\", ParDo.of(new DoFn<KV<Long, KV<Region, Territory>>, Result>() {\n",
    "                @ProcessElement\n",
    "                public void process(ProcessContext c) {\n",
    "                    KV<Long, KV<Region, Territory>> e = c.element();\n",
    "                    Long regionid = e.getKey();\n",
    "                    KV<Region, Territory> v = e.getValue();\n",
    "                    Region r = v.getKey();\n",
    "                    Territory t = v.getValue(); \n",
    "                    String regionname = r.regionname;\n",
    "                    Long territoryid = t.territoryid;\n",
    "                    String territoryname = t.territoryname;\n",
    "                    //c.output(new Result(1L, \"regionname\", 2L, \"territoryname\"));\n",
    "                    c.output(new Result(regionid, regionname, territoryid, territoryname));\n",
    "                }\n",
    "                \n",
    "            })\n",
    "            );\n",
    "\n",
    "        \n",
    "        result2.apply(TextIO.<Result>writeCustomType().to(outputsPrefix).withFormatFunction(new SerializeResult()));\n",
    "        p.run().waitUntilFinish();\n",
    "    }\n",
    "    \n",
    "    @DefaultCoder(AvroCoder.class)\n",
    "    @DefaultSchema(JavaFieldSchema.class)\n",
    "    static class Region {\n",
    "        Long regionid;\n",
    "        String regionname;\n",
    "        \n",
    "        Region() {}\n",
    "        \n",
    "        Region(Long regionid, String regionname) {\n",
    "            this.regionid = regionid;\n",
    "            this.regionname = regionname;\n",
    "        }\n",
    "        \n",
    "        @Override\n",
    "        public String toString() {\n",
    "            return String.format(\"(regionid = %d, regionname = %s)\", regionid, regionname);\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    static class SerializeRegion implements SerializableFunction<Region, String> {\n",
    "        @Override\n",
    "        public String apply(Region input) {\n",
    "          return input.toString();\n",
    "        }\n",
    "    }\n",
    "\n",
    "    static class CSVToRegion extends DoFn<String, Region> {\n",
    "        private static final Logger LOG = LoggerFactory.getLogger(CSVToRegion.class);\n",
    "\n",
    "        @ProcessElement\n",
    "        public void process(ProcessContext c) {\n",
    "            String[] columns = c.element().split(\",\");\n",
    "            try {\n",
    "                Long regionid = Long.parseLong(columns[0].trim());\n",
    "                String regionname = columns[1].trim();\n",
    "                c.output(new Region(regionid, regionname));\n",
    "            } catch (ArrayIndexOutOfBoundsException | NumberFormatException e) {\n",
    "                LOG.info(\"CSVToRegion: parse error on '\" + c.element() + \"': \" + e.getMessage());\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    @DefaultCoder(AvroCoder.class)\n",
    "    @DefaultSchema(JavaFieldSchema.class)\n",
    "    static class Territory {\n",
    "        Long territoryid;\n",
    "        String territoryname;\n",
    "        Long regionid;\n",
    "        \n",
    "        Territory() {}\n",
    "        \n",
    "        Territory(long territoryid, String territoryname, long regionid) {\n",
    "            this.territoryid = territoryid;\n",
    "            this.territoryname = territoryname;\n",
    "            this.regionid = regionid;\n",
    "        }\n",
    "        \n",
    "        @Override\n",
    "        public String toString() {\n",
    "            return String.format(\"(territoryid = %d, territoryname = %s, regionid = %d)\", territoryid, territoryname, regionid);\n",
    "        }\n",
    "\n",
    "    }\n",
    "    \n",
    "    static class SerializeTerritory implements SerializableFunction<Territory, String> {\n",
    "        @Override\n",
    "        public String apply(Territory input) {\n",
    "          return input.toString();\n",
    "        }\n",
    "    }\n",
    "\n",
    "    static class ParseTerritories extends DoFn<String, Territory> {\n",
    "        private static final Logger LOG = LoggerFactory.getLogger(ParseTerritories.class);\n",
    "\n",
    "        @ProcessElement\n",
    "        public void process(ProcessContext c) {\n",
    "            String[] columns = c.element().split(\",\");\n",
    "            try {\n",
    "                Long territoryid = Long.parseLong(columns[0].trim());\n",
    "                String territoryname = columns[1].trim();\n",
    "                Long regionid = Long.parseLong(columns[2].trim());\n",
    "                c.output(new Territory(territoryid, territoryname, regionid));\n",
    "            } catch (ArrayIndexOutOfBoundsException | NumberFormatException e) {\n",
    "                LOG.info(\"ParseTerritories: parse error on '\" + c.element() + \"': \" + e.getMessage());\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    @DefaultCoder(AvroCoder.class)\n",
    "    @DefaultSchema(JavaFieldSchema.class)\n",
    "    static class Result {\n",
    "        Long regionid;\n",
    "        String regionname;\n",
    "        Long territoryid;\n",
    "        String territoryname;\n",
    "        \n",
    "        Result() {}\n",
    "        \n",
    "        Result(Long regionid, String regionname, Long territoryid, String territoryname) {\n",
    "            this.regionid = regionid;\n",
    "            this.regionname = regionname;\n",
    "            this.territoryid = territoryid;\n",
    "            this.territoryname = territoryname;\n",
    "        }\n",
    "        \n",
    "        @Override\n",
    "        public String toString() {\n",
    "            return String.format(\"(regionid = %d, regionname = %s, territoryid = %d, territoryname = %s)\", regionid, regionname, territoryid, territoryname);\n",
    "        }\n",
    "    }\n",
    "    static class SerializeResult implements SerializableFunction<Result, String> {\n",
    "        @Override\n",
    "        public String apply(Result input) {\n",
    "          return input.toString();\n",
    "        }\n",
    "    }\n",
    "}\n",
    "                   \n",
    "                   \n",
    "// KV{3, KV{(regionid = 3, regionname = Northern), (territoryid = 3801, territoryname = Portsmouth, regionid = 3)}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fc2a94-7ddf-4a23-8581-e58bac8e7240",
   "metadata": {
    "tags": []
   },
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f548cd66-511d-460d-ab91-42090216ba1e",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcaad46b-2a1d-40df-a573-02e5716279c6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 7. BeamSQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c07e256-d80c-4465-a6cf-8930c1825f2a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <img src=\"python.png\" width=40 height=40 /><font color='cadetblue' size=\"+2\">Python</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a986c8bd-d52f-40f8-9638-ef5ccfeb59d5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### SQL Transform uses <font color='green' size=\"+2\">PCOLLECTION</font> as the name of a single source passed into it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391af3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.io import ReadFromText\n",
    "from apache_beam import coders\n",
    "from apache_beam.transforms.sql import SqlTransform\n",
    "\n",
    "import typing\n",
    "import json\n",
    "\n",
    "class Territory(typing.NamedTuple):\n",
    "    territoryid: int\n",
    "    territoryname: str\n",
    "    regionid: int\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'territoryid = {self.territoryid} territoryname = {self.territoryname} regionid = {self.regionid}'\n",
    "coders.registry.register_coder(Territory, coders.RowCoder)\n",
    "        \n",
    "@beam.typehints.with_output_types(Territory)\n",
    "class TerritoryParseClass(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        territoryid, territoryname, regionid = element.split(',')\n",
    "        yield Territory(int(territoryid), territoryname.title(), int(regionid))\n",
    "    \n",
    "class RegionCount(typing.NamedTuple):\n",
    "    regionid: int\n",
    "    count: int\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'regionid = {self.regionid} count = {self.count}'\n",
    "coders.registry.register_coder(RegionCount, coders.RowCoder)\n",
    "        \n",
    "        \n",
    "territoriesfilename = 'territories.csv'\n",
    "with beam.Pipeline() as p:\n",
    "    territories = (\n",
    "                  p | 'Read Territories' >> ReadFromText('territories.csv')\n",
    "#                    | 'Parse Territories' >> beam.ParDo(TerritoryParseClass()).with_output_types(Territory) # if we didn't have with_output_types decorator\n",
    "                    | 'Parse Territories' >> beam.ParDo(TerritoryParseClass())\n",
    "                    | 'SQL Territories' >> SqlTransform(\"\"\"SELECT regionid, count(*) as `count` FROM PCOLLECTION GROUP BY regionid\"\"\")\n",
    "#                    | 'Map Territories for Print' >> beam.Map(lambda x : f'regionid = {x.regionid}  count = {x.count}')\n",
    "                    | 'Convert to RegionCount Class' >> beam.Map(lambda x : RegionCount(x.regionid, x.count))\n",
    "                    )\n",
    "    territories | 'Print SQL' >> beam.Map(print)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10c3a7c-0584-4268-a2f5-fbc04534eacc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### For a SQL query that has more than one source, bundle the sources together in a dictionary, they keys become the table names inside the SQL string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc93081",
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.io import ReadFromText\n",
    "from apache_beam import coders\n",
    "from apache_beam.transforms.sql import SqlTransform\n",
    "\n",
    "import typing\n",
    "import json\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "    parent = (\n",
    "            p | 'Create Parent' >> beam.Create([(1, 'Vowel'), (2, 'Consonant'), (4, 'Unknown')])\n",
    "              | 'Map Parent' >> beam.Map(lambda x : beam.Row(parent_id = x[0], parent_name = x[1]))\n",
    "    )\n",
    "\n",
    "    child = (\n",
    "            p | 'Create Child' >> beam.Create([('Alpha', 1), ('Beta', 2), ('Gamma', 2), ('Delta', 2), ('Epsilon', 1), ('Pi', 3)])\n",
    "              | 'Map Child' >> beam.Map(lambda x : beam.Row(child_name = x[0], parent_id = x[1]))\n",
    "    )\n",
    "    \n",
    "    result = ( {'parent': parent, 'child' : child} \n",
    "         | SqlTransform(\"\"\"\n",
    "             SELECT p.parent_id, p.parent_name, c.child_name \n",
    "             FROM parent as p \n",
    "             INNER JOIN child as c ON p.parent_id = c.parent_id\n",
    "             \"\"\")\n",
    "        | 'Format Output' >> beam.Map(lambda x : f'{x.parent_id}, {x.parent_name}, {x.child_name}')\n",
    "        )\n",
    "    result | 'Print Join' >> beam.Map(print)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e11a34-1834-4402-b1e3-d00b1bfce2d5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Real example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d426a5c0-80c8-4605-bb8e-371cb5d9d459",
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam import pvalue\n",
    "from apache_beam.io import ReadFromText, WriteToText\n",
    "import typing\n",
    "\n",
    "class Region(typing.NamedTuple):\n",
    "    regionid: int\n",
    "    regionname: str\n",
    "beam.coders.registry.register_coder(Region, beam.coders.RowCoder)\n",
    "        \n",
    "class RegionParseClass(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        yield Region(int(element['regionid']), element['regiondescription'])\n",
    "\n",
    "class Territory(typing.NamedTuple):\n",
    "    territoryid: int\n",
    "    territoryname: str\n",
    "    regionid: int\n",
    "beam.coders.registry.register_coder(Territory, beam.coders.RowCoder)\n",
    "        \n",
    "class TerritoryParseClass(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        yield Territory(int(element['territoryid']), element['territorydescription'], int(element['regionid']))\n",
    "\n",
    "class Result(typing.NamedTuple):\n",
    "    regionid: int\n",
    "    regionname: str\n",
    "    cnt: int\n",
    "beam.coders.registry.register_coder(Result, beam.coders.RowCoder)\n",
    "               \n",
    "regionsfilename = 'datasets/northwind/AVRO/regions/*.avro'\n",
    "territoriesfilename = 'datasets/northwind/AVRO/territories/territories.avro'\n",
    "with beam.Pipeline() as p:\n",
    "    regions = (p | 'Read Regions' >> beam.io.ReadFromAvro(regionsfilename)\n",
    "                     | 'Parse Regions' >> beam.ParDo(RegionParseClass())\n",
    "                  )\n",
    "\n",
    "    territories = (p | 'Read Territories' >> beam.io.ReadFromAvro(territoriesfilename)\n",
    "                     | 'Parse Territories' >> beam.ParDo(TerritoryParseClass())\n",
    "                  )\n",
    "\n",
    "    result = ( {'regions': regions, 'territories' : territories} \n",
    "         | SqlTransform(\"\"\"\n",
    "SELECT r.regionid AS regionid, r.regionname AS regionname, SUM(1) AS cnt \n",
    "FROM regions AS r \n",
    "JOIN territories AS t on t.regionid = r.regionid \n",
    "GROUP BY r.regionid, r.regionname\n",
    "\"\"\")\n",
    "        | 'Convert to Result Class' >> beam.Map(lambda x : Result(x.regionid, x.regionname, x.cnt))\n",
    "#        | 'Format Output' >> beam.Map(lambda x : f'{x.regionid}, {x.regionname}, {x.cnt}')\n",
    "             )\n",
    "    result | 'Print Join' >> beam.Map(print)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe17701-cec9-4a53-b8ea-66f8bf5ad2ae",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <img src=\"java.png\" width=40 height=40 /><font color='indigo' size=\"+2\">Java</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e65dd25-b71a-470f-8634-a9719bf580fa",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Beam SQL using Pojo with a simple query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5950d747-c1dc-4390-85f5-5191cfcb4afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%java verbose\n",
    "package samples.quickstart;\n",
    "\n",
    "import org.apache.beam.sdk.Pipeline;\n",
    "import org.apache.beam.sdk.values.PCollection;\n",
    "import org.apache.beam.sdk.values.TypeDescriptors;\n",
    "import org.apache.beam.sdk.io.TextIO;\n",
    "import org.apache.beam.sdk.transforms.ParDo;\n",
    "import org.apache.beam.sdk.transforms.DoFn;\n",
    "import org.apache.beam.sdk.transforms.Filter;\n",
    "import org.apache.beam.sdk.transforms.DoFn.ProcessContext;\n",
    "import org.apache.beam.sdk.coders.DefaultCoder;\n",
    "import org.apache.beam.sdk.coders.AvroCoder;\n",
    "import org.apache.beam.sdk.transforms.SerializableFunction;\n",
    "import org.apache.beam.sdk.schemas.Schema;\n",
    "import org.apache.beam.sdk.schemas.Schema.FieldType;\n",
    "import org.apache.beam.sdk.values.Row;\n",
    "import org.apache.beam.sdk.extensions.sql.SqlTransform;\n",
    "import org.apache.beam.sdk.transforms.MapElements;\n",
    "import org.apache.beam.sdk.transforms.SimpleFunction;\n",
    "import org.apache.beam.sdk.schemas.AutoValueSchema;\n",
    "import org.apache.beam.sdk.schemas.annotations.DefaultSchema;\n",
    "import org.apache.beam.sdk.schemas.JavaFieldSchema;\n",
    "import org.apache.beam.sdk.schemas.annotations.SchemaCreate;\n",
    "import com.google.auto.value.AutoValue;\n",
    "import org.apache.beam.sdk.schemas.transforms.Convert;\n",
    "import com.google.gson.Gson;\n",
    "\n",
    "import org.slf4j.Logger;\n",
    "import org.slf4j.LoggerFactory;\n",
    "\n",
    "\n",
    "public class ReadTerritories {\n",
    "    public static void main(String[] args) {\n",
    "        System.getProperties().put(\"org.apache.commons.logging.simplelog.defaultlog\",\"fatal\");\n",
    "\n",
    "        Pipeline p = Pipeline.create();\n",
    "        p.getSchemaRegistry().registerPOJO(Territory.class);\n",
    " \n",
    "        String territoriesInputFileName = \"datasets/northwind/JSON/territories/territories.json\";\n",
    "        String outputsPrefix = \"/tmp/outputs\";\n",
    "\n",
    "        PCollection<Territory> result = p\n",
    "            .apply(\"Read\", TextIO.read().from(territoriesInputFileName))\n",
    "            .apply(\"Parse\", ParDo.of(new JsonToTerritory()))\n",
    "            .apply(SqlTransform.query(\"SELECT territoryid, upper(territoryname) as territoryname, regionid FROM PCOLLECTION WHERE regionid = 1\"))\n",
    "            .apply(Convert.fromRows(Territory.class))\n",
    "        ;\n",
    "\n",
    "        /*\n",
    "        result.apply(MapElements.via(\n",
    "            new SimpleFunction<Territory, Territory>() {\n",
    "              @Override\n",
    "              public Territory apply(Territory t) {\n",
    "                System.out.println(\"** \" + t);\n",
    "                return t;\n",
    "              }\n",
    "            })); \n",
    "        */\n",
    "        \n",
    "        result.apply(TextIO.<Territory>writeCustomType().to(outputsPrefix).withFormatFunction(new SerializeTerritory()));\n",
    "        \n",
    "        p.run().waitUntilFinish();\n",
    "    }\n",
    "    \n",
    "\n",
    "    @DefaultSchema(JavaFieldSchema.class)\n",
    "    static class Territory {\n",
    "        Long territoryid;\n",
    "        String territoryname;\n",
    "        Long regionid;\n",
    "        \n",
    "        Territory() {}\n",
    "        \n",
    "        Territory(long territoryid, String territoryname, long regionid) {\n",
    "            this.territoryid = territoryid;\n",
    "            this.territoryname = territoryname;\n",
    "            this.regionid = regionid;\n",
    "        }\n",
    "        \n",
    "        @Override\n",
    "        public String toString() {\n",
    "            return String.format(\"(territoryID = %d, territoryName = %s, regionID = %d)\", territoryid, territoryname, regionid);\n",
    "        }\n",
    "\n",
    "    }\n",
    "    \n",
    "    static class SerializeTerritory implements SerializableFunction<Territory, String> {\n",
    "        @Override\n",
    "        public String apply(Territory input) {\n",
    "          return input.toString();\n",
    "        }\n",
    "    }\n",
    "\n",
    "    static class JsonToTerritory extends DoFn<String, Territory> {\n",
    "        @ProcessElement\n",
    "        public void process(@Element String json, OutputReceiver<Territory> r) throws Exception {\n",
    "            Gson gson = new Gson();\n",
    "            Territory t = gson.fromJson(json, Territory.class);\n",
    "            r.output(t);\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa61dbd-c2bf-4010-a657-35e4732dc3ed",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Beam SQL using multiple sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfee942f-062c-4711-bee5-e8f7ec6709c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%java\n",
    "package samples.quickstart;\n",
    "\n",
    "import org.apache.beam.sdk.Pipeline;\n",
    "import org.apache.beam.sdk.values.PCollection;\n",
    "import org.apache.beam.sdk.values.TypeDescriptors;\n",
    "import org.apache.beam.sdk.io.TextIO;\n",
    "import org.apache.beam.sdk.transforms.ParDo;\n",
    "import org.apache.beam.sdk.transforms.DoFn;\n",
    "import org.apache.beam.sdk.transforms.Filter;\n",
    "import org.apache.beam.sdk.transforms.DoFn.ProcessContext;\n",
    "import org.apache.beam.sdk.coders.DefaultCoder;\n",
    "import org.apache.beam.sdk.coders.AvroCoder;\n",
    "import org.apache.beam.sdk.transforms.SerializableFunction;\n",
    "import org.apache.beam.sdk.schemas.Schema;\n",
    "import org.apache.beam.sdk.schemas.Schema.FieldType;\n",
    "import org.apache.beam.sdk.values.Row;\n",
    "import org.apache.beam.sdk.extensions.sql.SqlTransform;\n",
    "import org.apache.beam.sdk.transforms.MapElements;\n",
    "import org.apache.beam.sdk.transforms.SimpleFunction;\n",
    "import org.apache.beam.sdk.schemas.AutoValueSchema;\n",
    "import org.apache.beam.sdk.schemas.annotations.DefaultSchema;\n",
    "import org.apache.beam.sdk.schemas.JavaFieldSchema;\n",
    "import org.apache.beam.sdk.schemas.annotations.SchemaCreate;\n",
    "import com.google.auto.value.AutoValue;\n",
    "import org.apache.beam.sdk.schemas.transforms.Convert;\n",
    "import com.google.gson.Gson;\n",
    "import org.apache.beam.sdk.values.PCollectionTuple;\n",
    "import org.apache.beam.sdk.values.TupleTag;\n",
    "import java.io.Serializable;\n",
    "\n",
    "import org.slf4j.Logger;\n",
    "import org.slf4j.LoggerFactory;\n",
    "\n",
    "\n",
    "public class ReadTerritories {\n",
    "    public static void main(String[] args) {\n",
    "        System.getProperties().put(\"org.apache.commons.logging.simplelog.defaultlog\",\"fatal\");\n",
    "\n",
    "        Pipeline p = Pipeline.create();\n",
    "        p.getSchemaRegistry().registerPOJO(Region.class);\n",
    "        p.getSchemaRegistry().registerPOJO(Territory.class);\n",
    "        p.getSchemaRegistry().registerPOJO(Result.class);\n",
    " \n",
    "        String regionsInputFileName = \"datasets/northwind/CSV/regions/regions.csv\";\n",
    "        String territoriesInputFileName = \"datasets/northwind/JSON/territories/territories.json\";\n",
    "        String outputsPrefix = \"/tmp/outputs\";\n",
    "\n",
    "        PCollection<Region> regions = p\n",
    "            .apply(\"Read Regions\", TextIO.read().from(regionsInputFileName))\n",
    "            .apply(\"Parse Regions\", ParDo.of(new CSVToRegion()));\n",
    "\n",
    "        PCollection<Territory> territories = p\n",
    "            .apply(\"Read Territories\", TextIO.read().from(territoriesInputFileName))\n",
    "            .apply(\"Parse Territories\", ParDo.of(new JsonToTerritory()));\n",
    "        \n",
    "         PCollectionTuple joinSources = PCollectionTuple\n",
    "                                        .of(new TupleTag<>(\"regions\"), regions)\n",
    "                                        .and(new TupleTag<>(\"territories\"), territories);                                          \n",
    "                                                    \n",
    "\n",
    "\n",
    "        PCollection<Result> result = joinSources\n",
    "            .apply(SqlTransform.query(\"SELECT r.regionid AS regionid, r.regionname AS regionname, SUM(1) AS cnt FROM regions AS r JOIN territories AS t on t.regionid = r.regionid group by r.regionid, r.regionname\"))\n",
    "            .apply(Convert.fromRows(Result.class))\n",
    "        ;\n",
    "\n",
    "        result.apply(TextIO.<Result>writeCustomType().to(outputsPrefix).withFormatFunction(new SerializeResult()));\n",
    "        \n",
    "        p.run().waitUntilFinish();\n",
    "    }\n",
    "    \n",
    "    @DefaultCoder(AvroCoder.class)\n",
    "    @DefaultSchema(JavaFieldSchema.class)\n",
    "    static class Region {\n",
    "        Long regionid;\n",
    "        String regionname;\n",
    "        \n",
    "        Region() {}\n",
    "        \n",
    "        Region(Long regionid, String regionname) {\n",
    "            this.regionid = regionid;\n",
    "            this.regionname = regionname;\n",
    "        }\n",
    "        \n",
    "        @Override\n",
    "        public String toString() {\n",
    "            return String.format(\"(regionid = %d, regionname = %s)\", regionid, regionname);\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    static class SerializeRegion implements SerializableFunction<Region, String> {\n",
    "        @Override\n",
    "        public String apply(Region input) {\n",
    "          return input.toString();\n",
    "        }\n",
    "    }\n",
    "\n",
    "    static class CSVToRegion extends DoFn<String, Region> {\n",
    "        private static final Logger LOG = LoggerFactory.getLogger(CSVToRegion.class);\n",
    "\n",
    "        @ProcessElement\n",
    "        public void process(ProcessContext c) {\n",
    "            String[] columns = c.element().split(\",\");\n",
    "            try {\n",
    "                Long regionid = Long.parseLong(columns[0].trim());\n",
    "                String regionname = columns[1].trim();\n",
    "                c.output(new Region(regionid, regionname));\n",
    "            } catch (ArrayIndexOutOfBoundsException | NumberFormatException e) {\n",
    "                LOG.info(\"CSVToRegion: parse error on '\" + c.element() + \"': \" + e.getMessage());\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    @DefaultCoder(AvroCoder.class)\n",
    "    @DefaultSchema(JavaFieldSchema.class)\n",
    "    static class Territory {\n",
    "        Long territoryid;\n",
    "        String territoryname;\n",
    "        Long regionid;\n",
    "        \n",
    "        Territory() {}\n",
    "        \n",
    "        Territory(Long territoryid, String territoryname, Long regionid) {\n",
    "            this.territoryid = territoryid;\n",
    "            this.territoryname = territoryname;\n",
    "            this.regionid = regionid;\n",
    "        }\n",
    "        \n",
    "        @Override\n",
    "        public String toString() {\n",
    "            return String.format(\"(territoryid = %d, territoryname = %s, regionID = %d)\", territoryid, territoryname, regionid);\n",
    "        }\n",
    "        /*\n",
    "        @Override\n",
    "        public boolean equals (Object o) {\n",
    "            if (o == this)\n",
    "                return true;\n",
    "            return false;\n",
    "         }\n",
    "        */\n",
    "    }\n",
    "    \n",
    "    static class SerializeTerritory implements SerializableFunction<Territory, String> {\n",
    "        @Override\n",
    "        public String apply(Territory input) {\n",
    "          return input.toString();\n",
    "        }\n",
    "    }\n",
    "\n",
    "    static class JsonToTerritory extends DoFn<String, Territory> {\n",
    "        @ProcessElement\n",
    "        public void process(@Element String json, OutputReceiver<Territory> r) throws Exception {\n",
    "            Gson gson = new Gson();\n",
    "            Territory t = gson.fromJson(json, Territory.class);\n",
    "            r.output(t);\n",
    "        }\n",
    "    }\n",
    "     \n",
    "    @DefaultCoder(AvroCoder.class)\n",
    "    @DefaultSchema(JavaFieldSchema.class)\n",
    "    static class Result {\n",
    "        Long regionid;\n",
    "        String regionname;\n",
    "        int cnt;\n",
    "        \n",
    "        Result() {}\n",
    "        \n",
    "        Result(Long regionid, String regionname, int cnt) {\n",
    "            this.regionid = regionid;\n",
    "            this.regionname = regionname;\n",
    "            this.cnt = cnt;\n",
    "        }\n",
    "        \n",
    "        @Override\n",
    "        public String toString() {\n",
    "            return String.format(\"(regionid = %d, regionname = %s, cnt = %d)\", regionid, regionname, cnt);\n",
    "        }\n",
    "        /*\n",
    "        @Override\n",
    "        public boolean equals (Object o) {\n",
    "            if (o == this)\n",
    "                return true;\n",
    "            return false;\n",
    "         }\n",
    "        */\n",
    "    }\n",
    "    \n",
    "    static class SerializeResult implements SerializableFunction<Result, String> {\n",
    "        @Override\n",
    "        public String apply(Result input) {\n",
    "          return input.toString();\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640c41a3-cb72-403d-8b41-7309459b22ee",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Example from Beam documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f836c9-1a79-41b0-be02-d3d7fb5a2ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%java verbose\n",
    "package samples.quickstart;\n",
    "\n",
    "import org.apache.beam.sdk.Pipeline;\n",
    "import org.apache.beam.sdk.extensions.sql.SqlTransform;\n",
    "import org.apache.beam.sdk.options.PipelineOptions;\n",
    "import org.apache.beam.sdk.options.PipelineOptionsFactory;\n",
    "import org.apache.beam.sdk.schemas.Schema;\n",
    "import org.apache.beam.sdk.transforms.Create;\n",
    "import org.apache.beam.sdk.transforms.MapElements;\n",
    "import org.apache.beam.sdk.transforms.SimpleFunction;\n",
    "import org.apache.beam.sdk.values.PBegin;\n",
    "import org.apache.beam.sdk.values.PCollection;\n",
    "import org.apache.beam.sdk.values.PCollectionTuple;\n",
    "import org.apache.beam.sdk.values.Row;\n",
    "import org.apache.beam.sdk.values.TupleTag;\n",
    "\n",
    "/**\n",
    " * This is a quick example, which uses Beam SQL DSL to create a data pipeline.\n",
    " *\n",
    " * <p>Run the example from the Beam source root with\n",
    " *\n",
    " * <pre>\n",
    " *   ./gradlew :sdks:java:extensions:sql:runBasicExample\n",
    " * </pre>\n",
    " *\n",
    " * <p>The above command executes the example locally using direct runner. Running the pipeline in\n",
    " * other runners require additional setup and are out of scope of the SQL examples. Please consult\n",
    " * Beam documentation on how to run pipelines.\n",
    " */\n",
    "class BeamSqlExample {\n",
    "\n",
    "  public static void main(String[] args) {\n",
    "    PipelineOptions options = PipelineOptionsFactory.fromArgs(args).create();\n",
    "    Pipeline p = Pipeline.create(options);\n",
    "\n",
    "    // define the input row format\n",
    "    Schema type =\n",
    "        Schema.builder().addInt32Field(\"c1\").addStringField(\"c2\").addDoubleField(\"c3\").build();\n",
    "\n",
    "    Row row1 = Row.withSchema(type).addValues(1, \"row\", 1.0).build();\n",
    "    Row row2 = Row.withSchema(type).addValues(2, \"row\", 2.0).build();\n",
    "    Row row3 = Row.withSchema(type).addValues(3, \"row\", 3.0).build();\n",
    "\n",
    "    // create a source PCollection with Create.of();\n",
    "    PCollection<Row> inputTable =\n",
    "        PBegin.in(p).apply(Create.of(row1, row2, row3).withRowSchema(type));\n",
    "\n",
    "    // Case 1. run a simple SQL query over input PCollection with BeamSql.simpleQuery;\n",
    "    PCollection<Row> outputStream =\n",
    "        inputTable.apply(SqlTransform.query(\"select c1, c2, c3 from PCOLLECTION where c1 > 1\"));\n",
    "\n",
    "    // print the output record of case 1;\n",
    "    outputStream\n",
    "        .apply(\n",
    "            \"log_result\",\n",
    "            MapElements.via(\n",
    "                new SimpleFunction<Row, Row>() {\n",
    "                  @Override\n",
    "                  public Row apply(Row input) {\n",
    "                    // expect output:\n",
    "                    //  PCOLLECTION: [3, row, 3.0]\n",
    "                    //  PCOLLECTION: [2, row, 2.0]\n",
    "                    System.out.println(\"PCOLLECTION: \" + input.getValues());\n",
    "                    return input;\n",
    "                  }\n",
    "                }))\n",
    "        .setRowSchema(type);\n",
    "\n",
    "    // Case 2. run the query with SqlTransform.query over result PCollection of case 1.\n",
    "    PCollection<Row> outputStream2 =\n",
    "        PCollectionTuple.of(new TupleTag<>(\"CASE1_RESULT\"), outputStream)\n",
    "            .apply(SqlTransform.query(\"select c2, sum(c3) from CASE1_RESULT group by c2\"));\n",
    "\n",
    "    // print the output record of case 2;\n",
    "    outputStream2\n",
    "        .apply(\n",
    "            \"log_result\",\n",
    "            MapElements.via(\n",
    "                new SimpleFunction<Row, Row>() {\n",
    "                  @Override\n",
    "                  public Row apply(Row input) {\n",
    "                    // expect output:\n",
    "                    //  CASE1_RESULT: [row, 5.0]\n",
    "                    System.out.println(\"CASE1_RESULT: \" + input.getValues());\n",
    "                    return input;\n",
    "                  }\n",
    "                }))\n",
    "        .setRowSchema(\n",
    "            Schema.builder().addStringField(\"stringField\").addDoubleField(\"doubleField\").build());\n",
    "\n",
    "    p.run().waitUntilFinish();\n",
    "  }\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844a012b-77f4-4e56-be03-eb8ec0f50a1e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Beam SQL using Pojo into a Result Pojo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b385018-4d9a-4085-ab75-88d9021b7017",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%java \n",
    "package samples.quickstart;\n",
    "\n",
    "import org.apache.beam.sdk.Pipeline;\n",
    "import org.apache.beam.sdk.values.PCollection;\n",
    "import org.apache.beam.sdk.values.TypeDescriptors;\n",
    "import org.apache.beam.sdk.io.TextIO;\n",
    "import org.apache.beam.sdk.transforms.ParDo;\n",
    "import org.apache.beam.sdk.transforms.DoFn;\n",
    "import org.apache.beam.sdk.transforms.Filter;\n",
    "import org.apache.beam.sdk.transforms.DoFn.ProcessContext;\n",
    "import org.apache.beam.sdk.coders.DefaultCoder;\n",
    "import org.apache.beam.sdk.coders.AvroCoder;\n",
    "import org.apache.beam.sdk.transforms.SerializableFunction;\n",
    "import org.apache.beam.sdk.schemas.Schema;\n",
    "import org.apache.beam.sdk.schemas.Schema.FieldType;\n",
    "import org.apache.beam.sdk.values.Row;\n",
    "import org.apache.beam.sdk.extensions.sql.SqlTransform;\n",
    "import org.apache.beam.sdk.transforms.MapElements;\n",
    "import org.apache.beam.sdk.transforms.SimpleFunction;\n",
    "import org.apache.beam.sdk.schemas.AutoValueSchema;\n",
    "import org.apache.beam.sdk.schemas.annotations.DefaultSchema;\n",
    "import org.apache.beam.sdk.schemas.JavaFieldSchema;\n",
    "import org.apache.beam.sdk.schemas.annotations.SchemaCreate;\n",
    "import com.google.auto.value.AutoValue;\n",
    "import org.apache.beam.sdk.schemas.transforms.Convert;\n",
    "import com.google.gson.Gson;\n",
    "\n",
    "import org.slf4j.Logger;\n",
    "import org.slf4j.LoggerFactory;\n",
    "\n",
    "\n",
    "public class ReadTerritories {\n",
    "    public static void main(String[] args) {\n",
    "        System.getProperties().put(\"org.apache.commons.logging.simplelog.defaultlog\",\"fatal\");\n",
    "\n",
    "        Pipeline p = Pipeline.create();\n",
    "        p.getSchemaRegistry().registerPOJO(Result.class);\n",
    " \n",
    "        String territoriesInputFileName = \"datasets/northwind/JSON/territories/territories.json\";\n",
    "        String outputsPrefix = \"/tmp/outputs\";\n",
    "\n",
    "        // Define the schema to hold the results.\n",
    "        Schema resultSchema = Schema.of(\n",
    "            Schema.Field.of(\"regionid\", Schema.FieldType.INT64), \n",
    "            Schema.Field.of(\"cnt\", Schema.FieldType.INT64));\n",
    "\n",
    "        PCollection<Result> result = p\n",
    "            .apply(\"Read\", TextIO.read().from(territoriesInputFileName))\n",
    "            .apply(\"Parse\", ParDo.of(new JsonToTerritory()))\n",
    "            .apply(SqlTransform.query(\"SELECT regionid, COUNT(*) as cnt FROM PCOLLECTION GROUP BY regionid\"))\n",
    "            .apply(Convert.fromRows(Result.class))\n",
    "        ;\n",
    "        \n",
    "        result.apply(TextIO.<Result>writeCustomType().to(outputsPrefix).withFormatFunction(new SerializeResult()));\n",
    "        \n",
    "        p.run().waitUntilFinish();\n",
    "    }\n",
    "    \n",
    "\n",
    "    @DefaultSchema(JavaFieldSchema.class)\n",
    "    static class Territory {\n",
    "        Long territoryid;\n",
    "        String territoryname;\n",
    "        Long regionid;\n",
    "        \n",
    "        Territory() {}\n",
    "        \n",
    "        Territory(long territoryid, String territoryname, long regionid) {\n",
    "            this.territoryid = territoryid;\n",
    "            this.territoryname = territoryname;\n",
    "            this.regionid = regionid;\n",
    "        }\n",
    "        \n",
    "        @Override\n",
    "        public String toString() {\n",
    "            return String.format(\"(territoryID = %d, territoryName = %s, regionID = %d)\", territoryid, territoryname, regionid);\n",
    "        }\n",
    "\n",
    "    }\n",
    "    \n",
    "    static class SerializeTerritory implements SerializableFunction<Territory, String> {\n",
    "        @Override\n",
    "        public String apply(Territory input) {\n",
    "          return input.toString();\n",
    "        }\n",
    "    }\n",
    "\n",
    "    static class JsonToTerritory extends DoFn<String, Territory> {\n",
    "        @ProcessElement\n",
    "        public void process(@Element String json, OutputReceiver<Territory> r) throws Exception {\n",
    "            Gson gson = new Gson();\n",
    "            Territory t = gson.fromJson(json, Territory.class);\n",
    "            r.output(t);\n",
    "        }\n",
    "    }\n",
    "     \n",
    "    @DefaultSchema(JavaFieldSchema.class)\n",
    "    static class Result {\n",
    "        Long regionid;\n",
    "        Long cnt;\n",
    "        \n",
    "        Result() {}\n",
    "        \n",
    "        Result(Long regionid, Long cnt) {\n",
    "            this.regionid = regionid;\n",
    "            this.cnt = cnt;\n",
    "        }\n",
    "        \n",
    "        @Override\n",
    "        public String toString() {\n",
    "            return String.format(\"(regionid = %d, cnt = %d)\", regionid, cnt);\n",
    "        }\n",
    "        @Override\n",
    "        public boolean equals (Object o) {\n",
    "            if (o == this)\n",
    "                return true;\n",
    "            return false;\n",
    "         }\n",
    "    }\n",
    "    \n",
    "    static class SerializeResult implements SerializableFunction<Result, String> {\n",
    "        @Override\n",
    "        public String apply(Result input) {\n",
    "          return input.toString();\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5490fb-33e0-4949-9f1a-45c5d4254aad",
   "metadata": {
    "tags": []
   },
   "source": [
    "### BeamSQL Java working wrong way with schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb24f9f2-4b5f-47a8-9718-8b553c2814fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%java verbose nooutput\n",
    "package samples.quickstart;\n",
    "\n",
    "import org.apache.beam.sdk.Pipeline;\n",
    "import org.apache.beam.sdk.values.PCollection;\n",
    "import org.apache.beam.sdk.values.TypeDescriptors;\n",
    "import org.apache.beam.sdk.io.TextIO;\n",
    "import org.apache.beam.sdk.transforms.ParDo;\n",
    "import org.apache.beam.sdk.transforms.DoFn;\n",
    "import org.apache.beam.sdk.transforms.Filter;\n",
    "import org.apache.beam.sdk.transforms.DoFn.ProcessContext;\n",
    "import org.apache.beam.sdk.coders.DefaultCoder;\n",
    "import org.apache.beam.sdk.coders.AvroCoder;\n",
    "import org.apache.beam.sdk.transforms.SerializableFunction;\n",
    "import org.apache.beam.sdk.schemas.Schema;\n",
    "import org.apache.beam.sdk.schemas.Schema.FieldType;\n",
    "import org.apache.beam.sdk.values.Row;\n",
    "import org.apache.beam.sdk.extensions.sql.SqlTransform;\n",
    "import org.apache.beam.sdk.transforms.MapElements;\n",
    "import org.apache.beam.sdk.transforms.SimpleFunction;\n",
    "import org.apache.beam.sdk.schemas.AutoValueSchema;\n",
    "import org.apache.beam.sdk.schemas.annotations.DefaultSchema;\n",
    "import org.apache.beam.sdk.schemas.annotations.SchemaCreate;\n",
    "import com.google.auto.value.AutoValue;\n",
    "import org.apache.beam.sdk.schemas.transforms.Convert;\n",
    "\n",
    "import org.slf4j.Logger;\n",
    "import org.slf4j.LoggerFactory;\n",
    "\n",
    "public class ReadTerritories {\n",
    "    public static void main(String[] args) {\n",
    "        Pipeline p = Pipeline.create();\n",
    "\n",
    "        String territoriesInputFileName = \"datasets/northwind/CSV/territories/territories.csv\";\n",
    "        String outputsPrefix = \"/tmp/outputs\";\n",
    "\n",
    "        PCollection<Territory> territories = p\n",
    "            .apply(\"Read\", TextIO.read().from(territoriesInputFileName))\n",
    "            .apply(\"Parse\", ParDo.of(new ParseTerritories()))\n",
    "        ;                   \n",
    "        \n",
    "        // Define the schema for the records.\n",
    "        Schema territorySchema = Schema\n",
    "          .builder()\n",
    "          .addInt64Field(\"territoryID\")\n",
    "          .addStringField(\"territoryName\")\n",
    "          .addInt64Field(\"regionID\")\n",
    "          .build();\n",
    "        // Define the schema to hold the results.\n",
    "        \n",
    "        Schema resultSchema = Schema.of(\n",
    "            Schema.Field.of(\"regionID\", Schema.FieldType.INT64), \n",
    "            Schema.Field.of(\"cnt\", Schema.FieldType.INT64));\n",
    "        \n",
    "        // Convert them to Rows with the same schema as defined above via a DoFn.\n",
    "        PCollection<Row> territories2 = territories\n",
    "          .apply(\n",
    "          ParDo.of(new DoFn<Territory, Row>() {\n",
    "            @ProcessElement\n",
    "            public void process(ProcessContext c) {\n",
    "              // Get the current POJO instance\n",
    "              Territory t = c.element();\n",
    "\n",
    "              // Create a Row with the appSchema schema\n",
    "              // and values from the current POJO\n",
    "              Row territoryRow =\n",
    "                    Row\n",
    "                      .withSchema(territorySchema)\n",
    "                      .addValues(\n",
    "                        t.territoryID,\n",
    "                        t.territoryName,\n",
    "                        t.regionID)\n",
    "                      .build();\n",
    "\n",
    "              // Output the Row representing the current POJO\n",
    "              c.output(territoryRow);\n",
    "            }\n",
    "          })).setRowSchema(territorySchema);\n",
    "        \n",
    "          PCollection<Row> territories3 = territories2.apply(Convert.toRows()).apply(\n",
    "             SqlTransform.query(\"SELECT regionID, COUNT(*) as cnt from PCOLLECTION GROUP BY regionID\")).setRowSchema(resultSchema);\n",
    "        \n",
    "          territories3.apply(\n",
    "              \"Print\", MapElements.via(new SimpleFunction<Row, Row>() {\n",
    "                  @Override\n",
    "                  public Row apply(Row input) {\n",
    "                      System.out.println(\"SQL Result: \" + input.getValues());\n",
    "                      return input;\n",
    "                  }\n",
    "              }\n",
    "          )).setRowSchema(resultSchema);\n",
    "//        territories3.apply(TextIO.<Row>writeCustomType().to(outputsPrefix).withFormatFunction(new SerializeTerritory()));\n",
    "        p.run().waitUntilFinish();\n",
    "    }\n",
    "\n",
    "/*    \n",
    "    @schemultSchema(AutoValueSchema.class)\n",
    "    @AutoValue\n",
    "    public static abstract class Territory {\n",
    "      public abstract Long getTerritoryID();\n",
    "      public abstract String getTerritoryName();\n",
    "      public abstract Long getRegionID();\n",
    "\n",
    "      @SchemaCreate\n",
    "      public static Territory create(Long territoryID, String territoryName, Long regionID) {\n",
    "        return new AutoValue_TerritoryClass(territoryID, territoryName, regionID);\n",
    "      }\n",
    "*/    \n",
    "    \n",
    "    @DefaultCoder(AvroCoder.class)\n",
    "    static class Territory {\n",
    "        Long territoryID;\n",
    "        String territoryName;\n",
    "        Long regionID;\n",
    "        \n",
    "        Territory() {}\n",
    "        \n",
    "        Territory(long territoryID, String territoryName, long regionID) {\n",
    "            this.territoryID = territoryID;\n",
    "            this.territoryName = territoryName;\n",
    "            this.regionID = regionID;\n",
    "        }\n",
    "        \n",
    "        @Override\n",
    "        public String toString() {\n",
    "            return String.format(\"(territoryID = %d, territoryName = %s, regionID = %d)\", territoryID, territoryName, regionID);\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    static class SerializeTerritory implements SerializableFunction<Territory, String> {\n",
    "        @Override\n",
    "        public String apply(Territory input) {\n",
    "          return input.toString();\n",
    "        }\n",
    "    }\n",
    "\n",
    "    static class ParseTerritories extends DoFn<String, Territory> {\n",
    "        private static final Logger LOG = LoggerFactory.getLogger(ParseTerritories.class);\n",
    "\n",
    "        @ProcessElement\n",
    "        public void process(ProcessContext c) {\n",
    "            String[] columns = c.element().split(\",\");\n",
    "            try {\n",
    "                Long territoryID = Long.parseLong(columns[0].trim());\n",
    "                String territoryName = columns[1].trim();\n",
    "                Long regionID = Long.parseLong(columns[2].trim());\n",
    "                c.output(new Territory(territoryID, territoryName, regionID));\n",
    "            } catch (ArrayIndexOutOfBoundsException | NumberFormatException e) {\n",
    "                LOG.info(\"ParseTerritories: parse error on '\" + c.element() + \"': \" + e.getMessage());\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "\n",
    "    \n",
    "     \n",
    "/*    \n",
    "    \n",
    "    \n",
    "    @DefaultCoder(AvroCoder.class)\n",
    "    static class Region {\n",
    "        Long regionID;\n",
    "        Long cnt regionName;\n",
    "        \n",
    "        Region() {}\n",
    "        \n",
    "        Region(long regionID, long cnt) {\n",
    "            this.regionID = regionID;\n",
    "            this.cnt = cnt;\n",
    "        }\n",
    "        \n",
    "        @Override\n",
    "        public String toString() {\n",
    "            return String.format(\"(regionID = %d, cnt = %d)\", regionID, cnt);\n",
    "        }\n",
    "\n",
    "    }\n",
    "    \n",
    "    static class SerializeTerritory implements SerializableFunction<Region, String> {\n",
    "        @Override\n",
    "        public String apply(Region input) {\n",
    "          return input.toString();\n",
    "        }\n",
    "    }\n",
    "\n",
    "    \n",
    "    \n",
    "private class Transform extends PTransform<pcollectionlist<row>, PCollection<row>> {\n",
    " \n",
    "    @Override\n",
    "    public PCollection<row> expand(PCollectionList<row> pinput) {\n",
    "      checkArgument(\n",
    "          pinput.size() == 1,\n",
    "          \"Wrong number of inputs for %s: %s\",\n",
    "          BeamUncollectRel.class.getSimpleName(),\n",
    "          pinput);\n",
    "      PCollection<row> upstream = pinput.get(0);\n",
    " \n",
    "      // Each row of the input contains a single array of things to be emitted; Calcite knows\n",
    "      // what the row looks like\n",
    "      Schema outputSchema = CalciteUtils.toSchema(getRowType());\n",
    " \n",
    "      PCollection<row> uncollected =\n",
    "          upstream.apply(ParDo.of(new UncollectDoFn(outputSchema))).setRowSchema(outputSchema);\n",
    " \n",
    "      return uncollected;\n",
    "    }\n",
    "  }    \n",
    "    static class ParseRegions extends DoFn<Row, Region> {\n",
    "        private static final Logger LOG = LoggerFactory.getLogger(ParseTerritories.class);\n",
    "\n",
    "        @ProcessElement\n",
    "        public void process(ProcessContext c) {\n",
    "            \n",
    "            String[] columns = c.element().split(\",\");\n",
    "            try {\n",
    "                Long territoryID = Long.parseLong(columns[0].trim());\n",
    "                String territoryName = columns[1].trim();\n",
    "                Long regionID = Long.parseLong(columns[2].trim());\n",
    "                c.output(new Territory(territoryID, territoryName, regionID));\n",
    "            } catch (ArrayIndexOutOfBoundsException | NumberFormatException e) {\n",
    "                LOG.info(\"ParseTerritories: parse error on '\" + c.element() + \"': \" + e.getMessage());\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    \n",
    "    \n",
    "*/\n",
    "    \n",
    "    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66766ce8-77db-471d-8938-f6bfada4c0ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fdd2ffb3-9158-4ae6-9c8e-999f9a0ab3b8",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19a8d33-1cd4-42c6-8277-da98c7cf15a8",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f139a1-db8c-41b5-9881-1a5eb2570f5d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 8. <font color='green' size=\"+2\">DoFn</font> Lifecycle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0cb066-030c-4846-a446-eeada7ddd4af",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <img src=\"python.png\" width=40 height=40 /><font color='cadetblue' size=\"+2\">Python</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8143846d-38ce-438a-bd4d-85e0838f716f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### <font color='green' size=\"+2\">DoFn</font> Lifecycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3951161-ad01-4a5b-aee3-9e3b220883d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.pvalue import AsSingleton, AsDict\n",
    "from apache_beam.io import ReadFromText\n",
    "\n",
    "class TerritoryParseTuple(beam.DoFn):\n",
    "    # split territory into KV pair of (regionid, (territoryid, territoryname))\n",
    "    def process(self, element):\n",
    "        territoryid, territoryname, regionid = element.split(',')\n",
    "        yield(int(territoryid), territoryname, int(regionid))\n",
    "        \n",
    "                \n",
    "class LookupRegion(beam.DoFn):\n",
    "    def setup(self):\n",
    "        self.lookup = {1:'North', 2:'South', 3:'East', 4:'West'}\n",
    "        print('setup')\n",
    "        \n",
    "    def start_bundle(self):\n",
    "        print('start bundle')\n",
    "        \n",
    "    def process(self, element, uppercase = 0):\n",
    "        #lookuptable = {1:'North', 2:'South', 3:'East', 4:'West'}\n",
    "        territoryid, territoryname, regionid = element\n",
    "        region = self.lookup.get(regionid, 'No Region')\n",
    "        if uppercase == 1:\n",
    "            region = region.upper()\n",
    "        yield(territoryid, territoryname, regionid, region)\n",
    "        \n",
    "    def finish_bundle(self):\n",
    "        print('finish bundle')\n",
    "\n",
    "    def teardown(self):\n",
    "        print('teardown')\n",
    "        del self.lookup\n",
    "    \n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "    territories =  (\n",
    "        p | 'Read Territories' >> ReadFromText('territories.csv')\n",
    "          | 'Parse Territories' >> beam.ParDo(TerritoryParseTuple())\n",
    "    )\n",
    "    \n",
    "    lookup = (\n",
    "        territories\n",
    "        | beam.ParDo(LookupRegion(), uppercase = 1 ) \n",
    "    )\n",
    "    lookup | 'Print Loopup' >> beam.Map(print)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13c622d-8a76-41da-afb2-60258b499577",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89ac07ff-2799-4372-8e75-9c35d849a6d6",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958a99c8-0cad-4c18-ad35-579923651e25",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e93fc8-c37b-4f8c-b56e-8e114161ef10",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 9. Side Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cfa540-e59d-44b2-a561-84d5142cf63e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <img src=\"python.png\" width=40 height=40 /><font color='cadetblue' size=\"+2\">Python</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8562667-e840-48c5-a9e3-db3432ae2d4a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Side inputs are about passing extra parameters to a function where the parameters are calculated in the pipeline itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28641185",
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.pvalue import AsSingleton, AsDict\n",
    "from apache_beam.io import ReadFromText\n",
    "from apache_beam.transforms.combiners import Sample\n",
    "\n",
    "class TerritoryParseTuple(beam.DoFn):\n",
    "    # split territory into KV pair of (regionid, (territoryid, territoryname))\n",
    "    def process(self, element, uppercase = '0'):\n",
    "        # It's a bit weird here but what is passed in is a single element array of a string\n",
    "        territoryid, territoryname, regionid = element.split(',')\n",
    "        yield(int(territoryid), territoryname if uppercase[0] == '0' else territoryname.upper(), int(regionid))\n",
    "\n",
    "        \n",
    "with beam.Pipeline() as p:\n",
    "    # x == 10\n",
    "    # uppcase = ['0' if x == 10 else '1']\n",
    "    sideinput = (\n",
    "        p | 'Read sideinput.txt' >> ReadFromText('sideinput.txt')\n",
    "          | Sample.FixedSizeGlobally(1)\n",
    "    )\n",
    "    \n",
    "    territories =  (\n",
    "        p | 'Read Territories' >> ReadFromText('territories.csv')\n",
    "#          | 'Parse Territories' >> beam.ParDo(TerritoryParseTuple(), uppercase = [\"1\"]) # This is not a side input but just passing a fixed parameter\n",
    "#          | 'Parse Territories' >> beam.ParDo(TerritoryParseTuple(), uppercase = sideinput)  # fails because sideinput is a PCollection not an integer\n",
    "          | 'Parse Territories' >> beam.ParDo(TerritoryParseTuple(), uppercase = beam.pvalue.AsSingleton(sideinput))  # When the parameter is calculated in the pipeline itself, that makes it a side input\n",
    "    )\n",
    "    territories | 'Print Loopup' >> beam.Map(print)\n",
    "\n",
    "#    maxregion | 'Print Min' >> beam.Map(print)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d992ca3-1da8-43d4-8f3a-872e03edfeae",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c26898-5abc-4684-9479-f2eeb466f506",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aaa0b05-c939-477e-aa81-2398a962902e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 10. Windows (Not Complete)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204410b6-c6e1-41e5-a6fb-5671d01ab43d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <img src=\"python.png\" width=40 height=40 /><font color='cadetblue' size=\"+2\">Python</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fafb3c-c6a4-4948-9ad1-cc9568269365",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Side inputs are about passing extra parameters to a function where the parameters are calculated in the pipeline itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06feb5b-0868-4b0d-bfd4-b85dc1a6b8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.transforms.sql import SqlTransform\n",
    "\n",
    "#dir(beam.io)\n",
    "#help(SqlTransform)\n",
    "from datetime import datetime\n",
    "print(datetime.strptime('1997-03-12', '%Y-%m-%d').date())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0d3134-f036-4f86-9be9-163329f85db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.io import ReadFromAvro, ReadFromParquet\n",
    "from apache_beam.transforms.combiners import Sample\n",
    "from datetime import datetime\n",
    "import time\n",
    "import typing\n",
    "from apache_beam import coders\n",
    "from apache_beam.transforms.sql import SqlTransform\n",
    "from apache_beam import window\n",
    "\n",
    "class GetTimestampFn(beam.DoFn):\n",
    "    def process(self, element, window=beam.DoFn.WindowParam):\n",
    "        #print(element, type(element), dir(element))\n",
    "        # window_start = window.start.to_utc_datetime().strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
    "        # window_end = window.end.to_utc_datetime().strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
    "        window_start = window.start.to_utc_datetime()\n",
    "        window_end = window.end.to_utc_datetime()\n",
    "        output = { **(element._asdict()), 'window_start': window_start, 'window_end': window_end}\n",
    "        yield output\n",
    "\n",
    "class LeftJoin(beam.PTransform):\n",
    "    '''\n",
    "    This PTransform will take a dictionary to the left of the | which will be the collection of the two\n",
    "    PCollections you want to join together. Both must be a dictionary. You will then pass in the name of each\n",
    "    PCollection and the key to join them on.\n",
    "    It will automatically reshape the two dicts into tuples of (key, dict) where it removes the key from each dict\n",
    "    It then CoGroups them and reshapes the tuple into a dict ready for insertion to a BQ table\n",
    "    '''\n",
    "    def __init__(self, parent_pipeline_name, parent_key, child_pipeline_name, child_key):\n",
    "        self.parent_pipeline_name = parent_pipeline_name\n",
    "        self.parent_key = parent_key\n",
    "        self.child_pipeline_name = child_pipeline_name\n",
    "        self.child_key = child_key\n",
    "\n",
    "    def expand(self, pcols):\n",
    "        def reshapeToKV(item, key):\n",
    "            # pipeline object should be a dictionary\n",
    "            item1 = item.copy()\n",
    "            del item1[key]\n",
    "            return (item[key], item1)\n",
    "\n",
    "        def reshapeCoGroupToFlatDict(item):\n",
    "            parent = {self.parent_key : item[0]}\n",
    "            parent.update(item[1][self.parent_pipeline_name][0])\n",
    "            ret = []\n",
    "            for row1 in item[1][self.child_pipeline_name]:\n",
    "                row = parent.copy()\n",
    "                row.update(row1)\n",
    "                ret.append(row)\n",
    "            return ret\n",
    "#            yield ret\n",
    "\n",
    "        return (\n",
    "                {\n",
    "                self.parent_pipeline_name : pcols[self.parent_pipeline_name] | f'Convert {self.parent_pipeline_name} to KV' \n",
    "                    >> beam.Map(reshapeToKV, self.parent_key)\n",
    "                ,self.child_pipeline_name : pcols[self.child_pipeline_name] | f'Convert {self.child_pipeline_name} to KV'\n",
    "                    >> beam.Map(reshapeToKV, self.child_key)\n",
    "                } | f'CoGroupByKey {self.child_pipeline_name} into {self.parent_pipeline_name}'\n",
    "                    >> beam.CoGroupByKey()\n",
    "                  | f'Reshape to dictionary'\n",
    "                    >> beam.FlatMap(reshapeCoGroupToFlatDict)\n",
    "        )\n",
    "\n",
    "\n",
    "ordersfile = 'datasets/northwind/AVRO/orders/orders.avro'\n",
    "orderdetailsfile = 'datasets/northwind/PARQUET/orderdetails/orderdetails.parquet'\n",
    "with beam.Pipeline() as p:\n",
    "    \n",
    "    \n",
    "    orders = (p | 'Read Orders' >> beam.io.ReadFromAvro(ordersfile)\n",
    "#                | 'Parse Orders' >> beam.ParDo(ParseOrder())\n",
    "                  )\n",
    "\n",
    "    orderdetails = (p | 'Read OrderDetails' >> beam.io.ReadFromParquet(orderdetailsfile)\n",
    "#                      | 'Parse OrderDetails' >> beam.ParDo(ParseOrderDetail())\n",
    "                   )\n",
    "\n",
    "    leftjoin = (\n",
    "        {'orders': orders, 'orderdetails': orderdetails} \n",
    "        | 'Join' >> LeftJoin('orders', 'orderid', 'orderdetails', 'orderid')\n",
    "        | 'Select' >> beam.Map(lambda x : {'orderdate': datetime.strptime(x['orderdate'], '%Y-%m-%d').date()\n",
    "                                           , 'shipcountry': x['shipcountry']\n",
    "                                           , 'amount': x['unitprice'] * x['quantity']\n",
    "                                          })\n",
    "       | 'Timestamp' >> beam.Map(lambda x : beam.window.TimestampedValue(x, time.mktime(x['orderdate'].timetuple())))\n",
    "       | 'Window' >> beam.WindowInto(window.FixedWindows(60 * 60 * 24))\n",
    "       | 'Group' >> beam.GroupBy(shipcountry = lambda x: x['shipcountry']).aggregate_field(lambda x: x['amount'], sum, 'totalamount')\n",
    "       | 'AddWindowTimestamp' >> (beam.ParDo(GetTimestampFn()))\n",
    "#       | 'Group' >> beam.GroupBy(shipcountry = lambda x: x['shipcountry']).aggregate_field(lambda x: x['amount'], sum, 'totalamount')\n",
    "      # | 'Group' >> beam.GroupBy(shipcountry = lambda x: x['shipcountry'], orderdate = lambda x: x['orderdate']).aggregate_field(lambda x: x['amount'], sum, 'totalamount')\n",
    "    )\n",
    "    leftjoin | beam.Map(print)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a693cd53-e1d6-4c1d-9a2c-4b90f62dac2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.io import ReadFromText\n",
    "\n",
    "class LeftJoin(beam.PTransform):\n",
    "    '''\n",
    "    This PTransform will take a dictionary to the left of the | which will be the collection of the two\n",
    "    PCollections you want to join together. Both must be a dictionary. You will then pass in the name of each\n",
    "    PCollection and the key to join them on.\n",
    "    It will automatically reshape the two dicts into tuples of (key, dict) where it removes the key from each dict\n",
    "    It then CoGroups them and reshapes the tuple into a dict ready for insertion to a BQ table\n",
    "    '''\n",
    "    def __init__(self, parent_pipeline_name, parent_key, child_pipeline_name, child_key):\n",
    "        self.parent_pipeline_name = parent_pipeline_name\n",
    "        self.parent_key = parent_key\n",
    "        self.child_pipeline_name = child_pipeline_name\n",
    "        self.child_key = child_key\n",
    "\n",
    "    def expand(self, pcols):\n",
    "        def reshapeToKV(item, key):\n",
    "            # pipeline object should be a dictionary\n",
    "            item1 = item.copy()\n",
    "            del item1[key]\n",
    "            return (item[key], item1)\n",
    "\n",
    "        def reshapeCoGroupToFlatDict(item):\n",
    "            parent = {self.parent_key : item[0]}\n",
    "            parent.update(item[1][self.parent_pipeline_name][0])\n",
    "            ret = []\n",
    "            for row1 in item[1][self.child_pipeline_name]:\n",
    "                row = parent.copy()\n",
    "                row.update(row1)\n",
    "                ret.append(row)\n",
    "            return ret\n",
    "\n",
    "        return (\n",
    "                {\n",
    "                self.parent_pipeline_name : pcols[self.parent_pipeline_name] | f'Convert {self.parent_pipeline_name} to KV' \n",
    "                    >> beam.Map(reshapeToKV, self.parent_key)\n",
    "                ,self.child_pipeline_name : pcols[self.child_pipeline_name] | f'Convert {self.child_pipeline_name} to KV'\n",
    "                    >> beam.Map(reshapeToKV, self.child_key)\n",
    "                } | f'CoGroupByKey {self.child_pipeline_name} into {self.parent_pipeline_name}'\n",
    "                    >> beam.CoGroupByKey()\n",
    "                  | f'Reshape to dictionary'\n",
    "                    >> beam.Map(reshapeCoGroupToFlatDict)\n",
    "        )\n",
    "\n",
    "class RegionParseDict(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        regionid, regionname = element.split(',')\n",
    "        yield {'regionid':int(regionid), 'regionname':regionname.title()}\n",
    "\n",
    "class TerritoryParseDict(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        territoryid, territoryname, regionid = element.split(',')\n",
    "        yield {'territoryid':int(territoryid), 'territoryname' : territoryname, 'regionid':int(regionid)}\n",
    "    \n",
    "regionsfilename = 'datasets/northwind/CSV/regions/regions.csv'\n",
    "territoriesfilename = 'datasets/northwind/CSV/territories/territories.csv'\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "    regions = (\n",
    "              p | 'Read Regions' >> ReadFromText(regionsfilename)\n",
    "                | 'Parse Regions' >> beam.ParDo(RegionParseDict())\n",
    "              )\n",
    "#    regions  | 'Print Regions' >> beam.Map(print)\n",
    "        \n",
    "    territories = (\n",
    "                  p | 'Read Territories' >> ReadFromText('territories.csv')\n",
    "                    | 'Parse Territories' >> beam.ParDo(TerritoryParseDict())\n",
    "                  )\n",
    "#    territories | 'Print Territories' >> beam.Map(print)\n",
    "\n",
    "    nestjoin = {'regions':regions, 'territories':territories} | LeftJoin('regions', 'regionid', 'territories', 'regionid')\n",
    "    nestjoin | 'Print Nest Join' >> beam.Map(print)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f72df8b-3263-46bf-a8da-18d65efdc952",
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.io import ReadFromAvro, ReadFromParquet\n",
    "from apache_beam.transforms.combiners import Sample\n",
    "from datetime import datetime\n",
    "import typing\n",
    "from apache_beam import coders\n",
    "from apache_beam.transforms.sql import SqlTransform\n",
    "\n",
    "class Order(typing.NamedTuple):\n",
    "    orderid: int\n",
    "    customerid: str\n",
    "    employeeid: int\n",
    "    orderdate: str\n",
    "    # orderdate: datetime\n",
    "    # requireddate: datetime\n",
    "    # shippeddate: datetime\n",
    "    # shipvia: int\n",
    "    # freight: float\n",
    "    # shipname: str\n",
    "    # shipaddress: str\n",
    "    # shipcity: str\n",
    "    # shipregion: str\n",
    "    # shippostalcode: str\n",
    "    shipcountry: str\n",
    "beam.coders.registry.register_coder(Order, coders.RowCoder)\n",
    "\n",
    "class ParseOrder(beam.DoFn):\n",
    "    # split territory into KV pair of (regionid, (territoryid, territoryname))\n",
    "    def process(self, element):\n",
    "        yield(Order(\n",
    "            int(element['orderid'])\n",
    "            ,element['customerid']\n",
    "            ,int(element['employeeid'])\n",
    "            ,element['orderdate']\n",
    "            # ,datetime.strptime(element['orderdate'], '%Y-%m-%d').date()\n",
    "            # ,datetime.strptime(element['requireddate'], '%Y-%m-%d').date()\n",
    "            # ,datetime.strptime(element['shippeddate'], '%Y-%m-%d').date()\n",
    "            # ,int(element['shipvia'])\n",
    "            # ,float(element['freight'])\n",
    "            # ,element['shipname']\n",
    "            # ,element['shipaddress']\n",
    "            # ,element['shipcity']\n",
    "            # ,element['shipregion']\n",
    "            # ,element['shippostalcode']\n",
    "            ,element['shipcountry']\n",
    "        ))\n",
    "\n",
    "class OrderDetail(typing.NamedTuple):\n",
    "    orderid: int\n",
    "    productid: int\n",
    "    unitprice: float\n",
    "    quantity: int\n",
    "    discount: float\n",
    "beam.coders.registry.register_coder(OrderDetail, coders.RowCoder)\n",
    "\n",
    "class ParseOrderDetail(beam.DoFn):\n",
    "    # split territory into KV pair of (regionid, (territoryid, territoryname))\n",
    "    def process(self, element):\n",
    "        yield(OrderDetail(int(element['orderid']), int(element['productid']), float(element['unitprice']), int(element['quantity']), float(element['discount'])))\n",
    "\n",
    "ordersfile = 'datasets/northwind/AVRO/orders/orders.avro'\n",
    "orderdetailsfile = 'datasets/northwind/PARQUET/orderdetails/orderdetails.parquet'\n",
    "with beam.Pipeline() as p:\n",
    "    \n",
    "    \n",
    "    orders = (p | 'Read Orders' >> beam.io.ReadFromAvro(ordersfile)\n",
    "                | 'Parse Orders' >> beam.ParDo(ParseOrder())\n",
    "                  )\n",
    "\n",
    "    orderdetails = (p | 'Read OrderDetails' >> beam.io.ReadFromParquet(orderdetailsfile)\n",
    "                      | 'Parse OrderDetails' >> beam.ParDo(ParseOrderDetail())\n",
    "                   )\n",
    "\n",
    "    query = ( {'orders': orders, 'orderdetails': orderdetails} \n",
    "              | 'SQL Territories' >> SqlTransform(\n",
    "\"\"\"\n",
    "SELECT o.shipcountry, cast(orderdate as date) as orderdate, od.unitprice * od.quantity as amount\n",
    "FROM orders as o\n",
    "JOIN orderdetails as od on o.orderid = od.orderid\n",
    "\"\"\", dialect = 'zetasql')\n",
    "            )      \n",
    "    query | beam.Map(print)\n",
    "# SELECT o.orderdate, o.shipcountry, sum(od.unitprice * od.quantity) as amount\n",
    "# FROM orders as o\n",
    "# JOIN orderdetails as od on o.orderid = od.orderid\n",
    "# GROUP BY o.orderdate, o.shipcountry\n",
    "    \n",
    "    \n",
    "    # TUMBLE(f_timestamp, INTERVAL '1' HOUR)\n",
    "    # query | beam.Map(print)\n",
    "    \n",
    "    \n",
    "              #     SELECT o.orderdate, sum(od.unitprice * od.quantity) as amount\n",
    "              # FROM orders as o\n",
    "              # JOIN orderdetails as od on o.orderid = od.orderid\n",
    "              # GROUP BY o.orderdate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9668295-b173-48d2-8868-cc72fbaa6927",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Side input that is a lookup list\n",
    "### More realistic example where the entire lookup table is read in the pipeline then distributed to each worker as a side input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20edebef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.pvalue import AsList\n",
    "from apache_beam.io import ReadFromText\n",
    "\n",
    "class RegionParseDict(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        regionid, regionname = element.split(',')\n",
    "        yield {'regionid': int(regionid), 'regionname': regionname.title()}\n",
    "\n",
    "class TerritoryParseTuple(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        territoryid, territoryname, regionid = element.split(',')\n",
    "        yield(int(territoryid), territoryname, int(regionid))\n",
    "        \n",
    "                \n",
    "class LookupRegion(beam.DoFn):\n",
    "    def process(self, element, lookuptable = [{'regionid':1, 'regionname':'North'}, {'regionid':2, 'regionname':'South'}]):\n",
    "        # {1:'North', 2:'South'}\n",
    "        territoryid, territoryname, regionid = element\n",
    "        # Becase the regions PCollection is a different shape, use the following comprehension to make it easier to do a lookup\n",
    "        lookup = {e['regionid'] : e['regionname'] for e in lookuptable } # {1:'North', 2:'South'}\n",
    "        yield(territoryid, territoryname, regionid, lookup.get(regionid, 'No Region'))\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "    regions = (\n",
    "        p | 'Read Regions' >> ReadFromText('regions.csv')\n",
    "          | 'Parse Regions' >> beam.ParDo(RegionParseDict())\n",
    "    )\n",
    "    # regions | 'Print Regions' >> beam.Map(print)\n",
    "\n",
    "    territories =  (\n",
    "        p | 'Read Territories' >> ReadFromText('territories.csv')\n",
    "          | 'Parse Territories' >> beam.ParDo(TerritoryParseTuple())\n",
    "    )\n",
    "    # territories | 'Print Territories' >> beam.Map(print)\n",
    "    \n",
    "    lookup = (\n",
    "        territories\n",
    "        | beam.ParDo(LookupRegion(), lookuptable = beam.pvalue.AsList(regions))\n",
    "    )\n",
    "    lookup | 'Print Loopup' >> beam.Map(print)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "42f07313-f60b-4334-9ac1-6cc74e4854a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'country': 'France', 'totalamount': 440.0, 'window_start': datetime.datetime(1996, 7, 4, 0, 0), 'window_end': datetime.datetime(1996, 7, 5, 0, 0)}\n",
      "{'country': 'France', 'totalamount': 670.8, 'window_start': datetime.datetime(1996, 7, 8, 0, 0), 'window_end': datetime.datetime(1996, 7, 9, 0, 0)}\n",
      "{'country': 'France', 'totalamount': 1176.0, 'window_start': datetime.datetime(1996, 7, 25, 0, 0), 'window_end': datetime.datetime(1996, 7, 26, 0, 0)}\n",
      "{'country': 'France', 'totalamount': 538.6, 'window_start': datetime.datetime(1996, 8, 6, 0, 0), 'window_end': datetime.datetime(1996, 8, 7, 0, 0)}\n",
      "{'country': 'France', 'totalamount': 121.6, 'window_start': datetime.datetime(1996, 9, 2, 0, 0), 'window_end': datetime.datetime(1996, 9, 3, 0, 0)}\n",
      "{'country': 'France', 'totalamount': 1420.0, 'window_start': datetime.datetime(1996, 9, 4, 0, 0), 'window_end': datetime.datetime(1996, 9, 5, 0, 0)}\n",
      "{'country': 'France', 'totalamount': 268.79999999999995, 'window_start': datetime.datetime(1996, 9, 20, 0, 0), 'window_end': datetime.datetime(1996, 9, 21, 0, 0)}\n",
      "{'country': 'France', 'totalamount': 88.5, 'window_start': datetime.datetime(1996, 10, 16, 0, 0), 'window_end': datetime.datetime(1996, 10, 17, 0, 0)}\n",
      "{'country': 'France', 'totalamount': 144.8, 'window_start': datetime.datetime(1996, 10, 21, 0, 0), 'window_end': datetime.datetime(1996, 10, 22, 0, 0)}\n",
      "{'country': 'France', 'totalamount': 2564.4, 'window_start': datetime.datetime(1996, 10, 29, 0, 0), 'window_end': datetime.datetime(1996, 10, 30, 0, 0)}\n",
      "{'country': 'France', 'totalamount': 713.4, 'window_start': datetime.datetime(1996, 11, 11, 0, 0), 'window_end': datetime.datetime(1996, 11, 12, 0, 0)}\n",
      "{'country': 'France', 'totalamount': 452.0, 'window_start': datetime.datetime(1996, 11, 20, 0, 0), 'window_end': datetime.datetime(1996, 11, 21, 0, 0)}\n",
      "{'country': 'France', 'totalamount': 7390.2, 'window_start': datetime.datetime(1996, 11, 22, 0, 0), 'window_end': datetime.datetime(1996, 11, 23, 0, 0)}\n",
      "{'country': 'France', 'totalamount': 1549.6, 'window_start': datetime.datetime(1996, 11, 25, 0, 0), 'window_end': datetime.datetime(1996, 11, 26, 0, 0)}\n",
      "{'country': 'France', 'totalamount': 91.19999999999999, 'window_start': datetime.datetime(1996, 12, 3, 0, 0), 'window_end': datetime.datetime(1996, 12, 4, 0, 0)}\n",
      "{'country': 'France', 'totalamount': 1622.4, 'window_start': datetime.datetime(1997, 1, 8, 0, 0), 'window_end': datetime.datetime(1997, 1, 9, 0, 0)}\n",
      "{'country': 'France', 'totalamount': 2123.2, 'window_start': datetime.datetime(1997, 1, 14, 0, 0), 'window_end': datetime.datetime(1997, 1, 15, 0, 0)}\n",
      "{'country': 'France', 'totalamount': 480.0, 'window_start': datetime.datetime(1997, 1, 24, 0, 0), 'window_end': datetime.datetime(1997, 1, 25, 0, 0)}\n",
      "{'country': 'France', 'totalamount': 2210.8, 'window_start': datetime.datetime(1997, 2, 5, 0, 0), 'window_end': datetime.datetime(1997, 2, 6, 0, 0)}\n",
      "{'country': 'France', 'totalamount': 1838.2, 'window_start': datetime.datetime(1997, 2, 18, 0, 0), 'window_end': datetime.datetime(1997, 2, 19, 0, 0)}\n",
      "{'country': 'France', 'totalamount': 531.4, 'window_start': datetime.datetime(1997, 2, 19, 0, 0), 'window_end': datetime.datetime(1997, 2, 20, 0, 0)}\n",
      "{'country': 'France', 'totalamount': 414.0, 'window_start': datetime.datetime(1997, 2, 21, 0, 0), 'window_end': datetime.datetime(1997, 2, 22, 0, 0)}\n",
      "{'country': 'France', 'totalamount': 1688.0, 'window_start': datetime.datetime(1997, 2, 27, 0, 0), 'window_end': datetime.datetime(1997, 2, 28, 0, 0)}\n",
      "{'country': 'France', 'totalamount': 1820.8, 'window_start': datetime.datetime(1997, 3, 11, 0, 0), 'window_end': datetime.datetime(1997, 3, 12, 0, 0)}\n",
      "{'country': 'France', 'totalamount': 496.0, 'window_start': datetime.datetime(1997, 3, 18, 0, 0), 'window_end': datetime.datetime(1997, 3, 19, 0, 0)}\n",
      "{'country': 'France', 'totalamount': 756.0, 'window_start': datetime.datetime(1997, 3, 20, 0, 0), 'window_end': datetime.datetime(1997, 3, 21, 0, 0)}\n",
      "{'country': 'France', 'totalamount': 676.0, 'window_start': datetime.datetime(1997, 4, 2, 0, 0), 'window_end': datetime.datetime(1997, 4, 3, 0, 0)}\n",
      "{'country': 'France', 'totalamount': 550.8, 'window_start': datetime.datetime(1997, 4, 9, 0, 0), 'window_end': datetime.datetime(1997, 4, 10, 0, 0)}\n",
      "{'country': 'France', 'totalamount': 3000.0, 'window_start': datetime.datetime(1997, 4, 18, 0, 0), 'window_end': datetime.datetime(1997, 4, 19, 0, 0)}\n",
      "{'country': 'France', 'totalamount': 846.0, 'window_start': datetime.datetime(1997, 5, 2, 0, 0), 'window_end': datetime.datetime(1997, 5, 3, 0, 0)}\n",
      "{'country': 'France', 'totalamount': 2812.0, 'window_start': datetime.datetime(1997, 5, 23, 0, 0), 'window_end': datetime.datetime(1997, 5, 24, 0, 0)}\n",
      "{'country': 'France', 'totalamount': 547.8, 'window_start': datetime.datetime(1997, 6, 5, 0, 0), 'window_end': datetime.datetime(1997, 6, 6, 0, 0)}\n",
      "{'country': 'France', 'totalamount': 2040.0, 'window_start': datetime.datetime(1997, 6, 12, 0, 0), 'window_end': datetime.datetime(1997, 6, 13, 0, 0)}\n",
      "{'country': 'France', 'totalamount': 625.0, 'window_start': datetime.datetime(1997, 6, 30, 0, 0), 'window_end': datetime.datetime(1997, 7, 1, 0, 0)}\n",
      "{'country': 'France', 'totalamount': 424.0, 'window_start': datetime.datetime(1997, 7, 24, 0, 0), 'window_end': datetime.datetime(1997, 7, 25, 0, 0)}\n",
      "{'country': 'France', 'totalamount': 399.0, 'window_start': datetime.datetime(1997, 7, 25, 0, 0), 'window_end': datetime.datetime(1997, 7, 26, 0, 0)}\n",
      "{'country': 'France', 'totalamount': 450.0, 'window_start': datetime.datetime(1997, 8, 12, 0, 0), 'window_end': datetime.datetime(1997, 8, 13, 0, 0)}\n",
      "{'country': 'France', 'totalamount': 62.0, 'window_start': datetime.datetime(1997, 8, 14, 0, 0), 'window_end': datetime.datetime(1997, 8, 15, 0, 0)}\n",
      "{'country': 'France', 'totalamount': 4985.5, 'window_start': datetime.datetime(1997, 8, 15, 0, 0), 'window_end': datetime.datetime(1997, 8, 16, 0, 0)}\n",
      "{'country': 'France', 'totalamount': 2032.0, 'window_start': datetime.datetime(1997, 9, 10, 0, 0), 'window_end': datetime.datetime(1997, 9, 11, 0, 0)}\n",
      "{'country': 'France', 'totalamount': 920.1, 'window_start': datetime.datetime(1997, 9, 17, 0, 0), 'window_end': datetime.datetime(1997, 9, 18, 0, 0)}\n",
      "{'country': 'France', 'totalamount': 660.0, 'window_start': datetime.datetime(1997, 9, 23, 0, 0), 'window_end': datetime.datetime(1997, 9, 24, 0, 0)}\n",
      "{'country': 'France', 'totalamount': 63.0, 'window_start': datetime.datetime(1997, 9, 26, 0, 0), 'window_end': datetime.datetime(1997, 9, 27, 0, 0)}\n",
      "{'country': 'France', 'totalamount': 1296.0, 'window_start': datetime.datetime(1997, 10, 23, 0, 0), 'window_end': datetime.datetime(1997, 10, 24, 0, 0)}\n",
      "{'country': 'France', 'totalamount': 509.75, 'window_start': datetime.datetime(1997, 11, 5, 0, 0), 'window_end': datetime.datetime(1997, 11, 6, 0, 0)}\n",
      "{'country': 'France', 'totalamount': 360.0, 'window_start': datetime.datetime(1997, 11, 6, 0, 0), 'window_end': datetime.datetime(1997, 11, 7, 0, 0)}\n",
      "{'country': 'France', 'totalamount': 139.8, 'window_start': datetime.datetime(1997, 11, 11, 0, 0), 'window_end': datetime.datetime(1997, 11, 12, 0, 0)}\n",
      "{'country': 'France', 'totalamount': 292.35, 'window_start': datetime.datetime(1997, 11, 12, 0, 0), 'window_end': datetime.datetime(1997, 11, 13, 0, 0)}\n",
      "{'country': 'France', 'totalamount': 2598.0, 'window_start': datetime.datetime(1997, 11, 26, 0, 0), 'window_end': datetime.datetime(1997, 11, 27, 0, 0)}\n",
      "{'country': 'France', 'totalamount': 616.0, 'window_start': datetime.datetime(1997, 12, 3, 0, 0), 'window_end': datetime.datetime(1997, 12, 4, 0, 0)}\n",
      "{'country': 'France', 'totalamount': 2760.8, 'window_start': datetime.datetime(1997, 12, 19, 0, 0), 'window_end': datetime.datetime(1997, 12, 20, 0, 0)}\n",
      "{'country': 'France', 'totalamount': 3687.0, 'window_start': datetime.datetime(1997, 12, 22, 0, 0), 'window_end': datetime.datetime(1997, 12, 23, 0, 0)}\n",
      "{'country': 'France', 'totalamount': 572.1, 'window_start': datetime.datetime(1997, 12, 31, 0, 0), 'window_end': datetime.datetime(1998, 1, 1, 0, 0)}\n",
      "{'country': 'France', 'totalamount': 2070.0, 'window_start': datetime.datetime(1998, 1, 5, 0, 0), 'window_end': datetime.datetime(1998, 1, 6, 0, 0)}\n",
      "{'country': 'France', 'totalamount': 1573.0, 'window_start': datetime.datetime(1998, 1, 12, 0, 0), 'window_end': datetime.datetime(1998, 1, 13, 0, 0)}\n",
      "{'country': 'France', 'totalamount': 568.95, 'window_start': datetime.datetime(1998, 1, 14, 0, 0), 'window_end': datetime.datetime(1998, 1, 15, 0, 0)}\n",
      "{'country': 'France', 'totalamount': 212.0, 'window_start': datetime.datetime(1998, 1, 21, 0, 0), 'window_end': datetime.datetime(1998, 1, 22, 0, 0)}\n",
      "{'country': 'France', 'totalamount': 740.0, 'window_start': datetime.datetime(1998, 1, 23, 0, 0), 'window_end': datetime.datetime(1998, 1, 24, 0, 0)}\n",
      "{'country': 'France', 'totalamount': 1168.0, 'window_start': datetime.datetime(1998, 1, 29, 0, 0), 'window_end': datetime.datetime(1998, 1, 30, 0, 0)}\n",
      "{'country': 'France', 'totalamount': 2083.4, 'window_start': datetime.datetime(1998, 2, 5, 0, 0), 'window_end': datetime.datetime(1998, 2, 6, 0, 0)}\n",
      "{'country': 'France', 'totalamount': 917.0, 'window_start': datetime.datetime(1998, 2, 9, 0, 0), 'window_end': datetime.datetime(1998, 2, 10, 0, 0)}\n",
      "{'country': 'France', 'totalamount': 860.1, 'window_start': datetime.datetime(1998, 2, 16, 0, 0), 'window_end': datetime.datetime(1998, 2, 17, 0, 0)}\n",
      "{'country': 'France', 'totalamount': 108.5, 'window_start': datetime.datetime(1998, 2, 25, 0, 0), 'window_end': datetime.datetime(1998, 2, 26, 0, 0)}\n",
      "{'country': 'France', 'totalamount': 936.0, 'window_start': datetime.datetime(1998, 3, 3, 0, 0), 'window_end': datetime.datetime(1998, 3, 4, 0, 0)}\n",
      "{'country': 'France', 'totalamount': 800.0, 'window_start': datetime.datetime(1998, 3, 5, 0, 0), 'window_end': datetime.datetime(1998, 3, 6, 0, 0)}\n",
      "{'country': 'France', 'totalamount': 1925.4999999999998, 'window_start': datetime.datetime(1998, 3, 6, 0, 0), 'window_end': datetime.datetime(1998, 3, 7, 0, 0)}\n",
      "{'country': 'France', 'totalamount': 360.0, 'window_start': datetime.datetime(1998, 3, 11, 0, 0), 'window_end': datetime.datetime(1998, 3, 12, 0, 0)}\n",
      "{'country': 'France', 'totalamount': 2052.5, 'window_start': datetime.datetime(1998, 3, 20, 0, 0), 'window_end': datetime.datetime(1998, 3, 21, 0, 0)}\n",
      "{'country': 'France', 'totalamount': 2276.11, 'window_start': datetime.datetime(1998, 3, 24, 0, 0), 'window_end': datetime.datetime(1998, 3, 25, 0, 0)}\n",
      "{'country': 'France', 'totalamount': 210.0, 'window_start': datetime.datetime(1998, 4, 22, 0, 0), 'window_end': datetime.datetime(1998, 4, 23, 0, 0)}\n",
      "{'country': 'France', 'totalamount': 45.0, 'window_start': datetime.datetime(1998, 4, 27, 0, 0), 'window_end': datetime.datetime(1998, 4, 28, 0, 0)}\n",
      "{'country': 'France', 'totalamount': 1057.0, 'window_start': datetime.datetime(1998, 5, 6, 0, 0), 'window_end': datetime.datetime(1998, 5, 7, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 1863.4, 'window_start': datetime.datetime(1996, 7, 5, 0, 0), 'window_end': datetime.datetime(1996, 7, 6, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 1746.2, 'window_start': datetime.datetime(1996, 7, 19, 0, 0), 'window_end': datetime.datetime(1996, 7, 20, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 4031.0, 'window_start': datetime.datetime(1996, 7, 29, 0, 0), 'window_end': datetime.datetime(1996, 7, 30, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 2142.4, 'window_start': datetime.datetime(1996, 8, 5, 0, 0), 'window_end': datetime.datetime(1996, 8, 6, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 1200.8, 'window_start': datetime.datetime(1996, 8, 9, 0, 0), 'window_end': datetime.datetime(1996, 8, 10, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 468.0, 'window_start': datetime.datetime(1996, 8, 13, 0, 0), 'window_end': datetime.datetime(1996, 8, 14, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 1452.0, 'window_start': datetime.datetime(1996, 8, 19, 0, 0), 'window_end': datetime.datetime(1996, 8, 20, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 2179.2, 'window_start': datetime.datetime(1996, 8, 20, 0, 0), 'window_end': datetime.datetime(1996, 8, 21, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 3016.0, 'window_start': datetime.datetime(1996, 8, 21, 0, 0), 'window_end': datetime.datetime(1996, 8, 22, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 755.0, 'window_start': datetime.datetime(1996, 9, 9, 0, 0), 'window_end': datetime.datetime(1996, 9, 10, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 1614.8, 'window_start': datetime.datetime(1996, 9, 23, 0, 0), 'window_end': datetime.datetime(1996, 9, 24, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 182.39999999999998, 'window_start': datetime.datetime(1996, 9, 24, 0, 0), 'window_end': datetime.datetime(1996, 9, 25, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 164.4, 'window_start': datetime.datetime(1996, 10, 7, 0, 0), 'window_end': datetime.datetime(1996, 10, 8, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 1497.0, 'window_start': datetime.datetime(1996, 10, 9, 0, 0), 'window_end': datetime.datetime(1996, 10, 10, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 2467.0, 'window_start': datetime.datetime(1996, 10, 24, 0, 0), 'window_end': datetime.datetime(1996, 10, 25, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 2300.8, 'window_start': datetime.datetime(1996, 10, 30, 0, 0), 'window_end': datetime.datetime(1996, 10, 31, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 1586.0, 'window_start': datetime.datetime(1996, 10, 31, 0, 0), 'window_end': datetime.datetime(1996, 11, 1, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 2924.8, 'window_start': datetime.datetime(1996, 11, 4, 0, 0), 'window_end': datetime.datetime(1996, 11, 5, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 396.0, 'window_start': datetime.datetime(1996, 11, 7, 0, 0), 'window_end': datetime.datetime(1996, 11, 8, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 1106.4, 'window_start': datetime.datetime(1996, 11, 18, 0, 0), 'window_end': datetime.datetime(1996, 11, 19, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 2273.6, 'window_start': datetime.datetime(1996, 11, 22, 0, 0), 'window_end': datetime.datetime(1996, 11, 23, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 447.2, 'window_start': datetime.datetime(1996, 11, 26, 0, 0), 'window_end': datetime.datetime(1996, 11, 27, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 86.39999999999999, 'window_start': datetime.datetime(1996, 12, 23, 0, 0), 'window_end': datetime.datetime(1996, 12, 24, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 1903.8000000000002, 'window_start': datetime.datetime(1996, 12, 27, 0, 0), 'window_end': datetime.datetime(1996, 12, 28, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 1194.0, 'window_start': datetime.datetime(1997, 1, 7, 0, 0), 'window_end': datetime.datetime(1997, 1, 8, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 1814.8, 'window_start': datetime.datetime(1997, 1, 17, 0, 0), 'window_end': datetime.datetime(1997, 1, 18, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 567.5, 'window_start': datetime.datetime(1997, 2, 6, 0, 0), 'window_end': datetime.datetime(1997, 2, 7, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 273.6, 'window_start': datetime.datetime(1997, 2, 14, 0, 0), 'window_end': datetime.datetime(1997, 2, 15, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 4277.4, 'window_start': datetime.datetime(1997, 2, 19, 0, 0), 'window_end': datetime.datetime(1997, 2, 20, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 2240.0, 'window_start': datetime.datetime(1997, 2, 25, 0, 0), 'window_end': datetime.datetime(1997, 2, 26, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 717.6, 'window_start': datetime.datetime(1997, 3, 7, 0, 0), 'window_end': datetime.datetime(1997, 3, 8, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 1560.0, 'window_start': datetime.datetime(1997, 3, 27, 0, 0), 'window_end': datetime.datetime(1997, 3, 28, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 1380.6, 'window_start': datetime.datetime(1997, 4, 4, 0, 0), 'window_end': datetime.datetime(1997, 4, 5, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 149.0, 'window_start': datetime.datetime(1997, 4, 9, 0, 0), 'window_end': datetime.datetime(1997, 4, 10, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 462.0, 'window_start': datetime.datetime(1997, 4, 15, 0, 0), 'window_end': datetime.datetime(1997, 4, 16, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 240.0, 'window_start': datetime.datetime(1997, 4, 16, 0, 0), 'window_end': datetime.datetime(1997, 4, 17, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 136.8, 'window_start': datetime.datetime(1997, 4, 17, 0, 0), 'window_end': datetime.datetime(1997, 4, 18, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 2427.5, 'window_start': datetime.datetime(1997, 4, 22, 0, 0), 'window_end': datetime.datetime(1997, 4, 23, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 10588.5, 'window_start': datetime.datetime(1997, 4, 23, 0, 0), 'window_end': datetime.datetime(1997, 4, 24, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 2657.8, 'window_start': datetime.datetime(1997, 4, 30, 0, 0), 'window_end': datetime.datetime(1997, 5, 1, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 1670.0, 'window_start': datetime.datetime(1997, 5, 5, 0, 0), 'window_end': datetime.datetime(1997, 5, 6, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 517.4, 'window_start': datetime.datetime(1997, 5, 12, 0, 0), 'window_end': datetime.datetime(1997, 5, 13, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 2085.0, 'window_start': datetime.datetime(1997, 5, 14, 0, 0), 'window_end': datetime.datetime(1997, 5, 15, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 10191.7, 'window_start': datetime.datetime(1997, 5, 19, 0, 0), 'window_end': datetime.datetime(1997, 5, 20, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 493.8, 'window_start': datetime.datetime(1997, 5, 20, 0, 0), 'window_end': datetime.datetime(1997, 5, 21, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 275.1, 'window_start': datetime.datetime(1997, 5, 26, 0, 0), 'window_end': datetime.datetime(1997, 5, 27, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 4181.5, 'window_start': datetime.datetime(1997, 5, 27, 0, 0), 'window_end': datetime.datetime(1997, 5, 28, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 1819.5, 'window_start': datetime.datetime(1997, 5, 30, 0, 0), 'window_end': datetime.datetime(1997, 5, 31, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 1152.5, 'window_start': datetime.datetime(1997, 6, 3, 0, 0), 'window_end': datetime.datetime(1997, 6, 4, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 1257.3, 'window_start': datetime.datetime(1997, 6, 6, 0, 0), 'window_end': datetime.datetime(1997, 6, 7, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 2147.4, 'window_start': datetime.datetime(1997, 6, 20, 0, 0), 'window_end': datetime.datetime(1997, 6, 21, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 1067.1, 'window_start': datetime.datetime(1997, 6, 26, 0, 0), 'window_end': datetime.datetime(1997, 6, 27, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 330.0, 'window_start': datetime.datetime(1997, 6, 27, 0, 0), 'window_end': datetime.datetime(1997, 6, 28, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 3900.0, 'window_start': datetime.datetime(1997, 7, 3, 0, 0), 'window_end': datetime.datetime(1997, 7, 4, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 543.65, 'window_start': datetime.datetime(1997, 7, 8, 0, 0), 'window_end': datetime.datetime(1997, 7, 9, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 2493.0, 'window_start': datetime.datetime(1997, 7, 9, 0, 0), 'window_end': datetime.datetime(1997, 7, 10, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 1064.0, 'window_start': datetime.datetime(1997, 7, 23, 0, 0), 'window_end': datetime.datetime(1997, 7, 24, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 464.0, 'window_start': datetime.datetime(1997, 7, 29, 0, 0), 'window_end': datetime.datetime(1997, 7, 30, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 1429.75, 'window_start': datetime.datetime(1997, 8, 7, 0, 0), 'window_end': datetime.datetime(1997, 8, 8, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 918.0, 'window_start': datetime.datetime(1997, 8, 13, 0, 0), 'window_end': datetime.datetime(1997, 8, 14, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 620.0, 'window_start': datetime.datetime(1997, 8, 14, 0, 0), 'window_end': datetime.datetime(1997, 8, 15, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 945.0, 'window_start': datetime.datetime(1997, 8, 21, 0, 0), 'window_end': datetime.datetime(1997, 8, 22, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 1086.0, 'window_start': datetime.datetime(1997, 8, 25, 0, 0), 'window_end': datetime.datetime(1997, 8, 26, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 530.4, 'window_start': datetime.datetime(1997, 9, 1, 0, 0), 'window_end': datetime.datetime(1997, 9, 2, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 1203.5, 'window_start': datetime.datetime(1997, 9, 2, 0, 0), 'window_end': datetime.datetime(1997, 9, 3, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 4668.0, 'window_start': datetime.datetime(1997, 9, 5, 0, 0), 'window_end': datetime.datetime(1997, 9, 6, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 694.75, 'window_start': datetime.datetime(1997, 9, 15, 0, 0), 'window_end': datetime.datetime(1997, 9, 16, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 2301.75, 'window_start': datetime.datetime(1997, 9, 16, 0, 0), 'window_end': datetime.datetime(1997, 9, 17, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 1423.0, 'window_start': datetime.datetime(1997, 9, 19, 0, 0), 'window_end': datetime.datetime(1997, 9, 20, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 1768.0, 'window_start': datetime.datetime(1997, 9, 26, 0, 0), 'window_end': datetime.datetime(1997, 9, 27, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 11042.8, 'window_start': datetime.datetime(1997, 10, 3, 0, 0), 'window_end': datetime.datetime(1997, 10, 4, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 4825.0, 'window_start': datetime.datetime(1997, 10, 6, 0, 0), 'window_end': datetime.datetime(1997, 10, 7, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 114.0, 'window_start': datetime.datetime(1997, 10, 9, 0, 0), 'window_end': datetime.datetime(1997, 10, 10, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 330.0, 'window_start': datetime.datetime(1997, 10, 13, 0, 0), 'window_end': datetime.datetime(1997, 10, 14, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 1331.75, 'window_start': datetime.datetime(1997, 10, 24, 0, 0), 'window_end': datetime.datetime(1997, 10, 25, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 3463.0, 'window_start': datetime.datetime(1997, 10, 27, 0, 0), 'window_end': datetime.datetime(1997, 10, 28, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 972.5, 'window_start': datetime.datetime(1997, 10, 29, 0, 0), 'window_end': datetime.datetime(1997, 10, 30, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 4529.8, 'window_start': datetime.datetime(1997, 11, 18, 0, 0), 'window_end': datetime.datetime(1997, 11, 19, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 1684.0, 'window_start': datetime.datetime(1997, 12, 4, 0, 0), 'window_end': datetime.datetime(1997, 12, 5, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 2310.0, 'window_start': datetime.datetime(1997, 12, 5, 0, 0), 'window_end': datetime.datetime(1997, 12, 6, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 3603.2200000000003, 'window_start': datetime.datetime(1997, 12, 10, 0, 0), 'window_end': datetime.datetime(1997, 12, 11, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 1335.0, 'window_start': datetime.datetime(1997, 12, 16, 0, 0), 'window_end': datetime.datetime(1997, 12, 17, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 770.0, 'window_start': datetime.datetime(1997, 12, 22, 0, 0), 'window_end': datetime.datetime(1997, 12, 23, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 1926.0600000000002, 'window_start': datetime.datetime(1997, 12, 23, 0, 0), 'window_end': datetime.datetime(1997, 12, 24, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 420.0, 'window_start': datetime.datetime(1997, 12, 25, 0, 0), 'window_end': datetime.datetime(1997, 12, 26, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 1585.0, 'window_start': datetime.datetime(1997, 12, 26, 0, 0), 'window_end': datetime.datetime(1997, 12, 27, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 11490.7, 'window_start': datetime.datetime(1998, 1, 6, 0, 0), 'window_end': datetime.datetime(1998, 1, 7, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 1030.76, 'window_start': datetime.datetime(1998, 1, 9, 0, 0), 'window_end': datetime.datetime(1998, 1, 10, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 1858.7, 'window_start': datetime.datetime(1998, 1, 15, 0, 0), 'window_end': datetime.datetime(1998, 1, 16, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 4059.0, 'window_start': datetime.datetime(1998, 1, 21, 0, 0), 'window_end': datetime.datetime(1998, 1, 22, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 1052.1399999999999, 'window_start': datetime.datetime(1998, 1, 23, 0, 0), 'window_end': datetime.datetime(1998, 1, 24, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 625.0, 'window_start': datetime.datetime(1998, 1, 27, 0, 0), 'window_end': datetime.datetime(1998, 1, 28, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 1438.25, 'window_start': datetime.datetime(1998, 1, 29, 0, 0), 'window_end': datetime.datetime(1998, 1, 30, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 581.0, 'window_start': datetime.datetime(1998, 1, 30, 0, 0), 'window_end': datetime.datetime(1998, 1, 31, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 17250.0, 'window_start': datetime.datetime(1998, 2, 2, 0, 0), 'window_end': datetime.datetime(1998, 2, 3, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 1620.0, 'window_start': datetime.datetime(1998, 2, 10, 0, 0), 'window_end': datetime.datetime(1998, 2, 11, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 388.35, 'window_start': datetime.datetime(1998, 2, 17, 0, 0), 'window_end': datetime.datetime(1998, 2, 18, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 5502.11, 'window_start': datetime.datetime(1998, 2, 18, 0, 0), 'window_end': datetime.datetime(1998, 2, 19, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 1174.75, 'window_start': datetime.datetime(1998, 3, 5, 0, 0), 'window_end': datetime.datetime(1998, 3, 6, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 500.0, 'window_start': datetime.datetime(1998, 3, 9, 0, 0), 'window_end': datetime.datetime(1998, 3, 10, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 3642.5, 'window_start': datetime.datetime(1998, 3, 10, 0, 0), 'window_end': datetime.datetime(1998, 3, 11, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 245.0, 'window_start': datetime.datetime(1998, 3, 12, 0, 0), 'window_end': datetime.datetime(1998, 3, 13, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 491.2, 'window_start': datetime.datetime(1998, 3, 16, 0, 0), 'window_end': datetime.datetime(1998, 3, 17, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 677.0, 'window_start': datetime.datetime(1998, 3, 17, 0, 0), 'window_end': datetime.datetime(1998, 3, 18, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 3584.0, 'window_start': datetime.datetime(1998, 3, 19, 0, 0), 'window_end': datetime.datetime(1998, 3, 20, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 910.4, 'window_start': datetime.datetime(1998, 3, 23, 0, 0), 'window_end': datetime.datetime(1998, 3, 24, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 2870.0, 'window_start': datetime.datetime(1998, 4, 1, 0, 0), 'window_end': datetime.datetime(1998, 4, 2, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 560.0, 'window_start': datetime.datetime(1998, 4, 2, 0, 0), 'window_end': datetime.datetime(1998, 4, 3, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 1261.0, 'window_start': datetime.datetime(1998, 4, 3, 0, 0), 'window_end': datetime.datetime(1998, 4, 4, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 3934.0, 'window_start': datetime.datetime(1998, 4, 9, 0, 0), 'window_end': datetime.datetime(1998, 4, 10, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 7685.49, 'window_start': datetime.datetime(1998, 4, 14, 0, 0), 'window_end': datetime.datetime(1998, 4, 15, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 2160.0, 'window_start': datetime.datetime(1998, 4, 16, 0, 0), 'window_end': datetime.datetime(1998, 4, 17, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 1692.0, 'window_start': datetime.datetime(1998, 4, 20, 0, 0), 'window_end': datetime.datetime(1998, 4, 21, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 1564.0, 'window_start': datetime.datetime(1998, 4, 23, 0, 0), 'window_end': datetime.datetime(1998, 4, 24, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 858.0, 'window_start': datetime.datetime(1998, 4, 29, 0, 0), 'window_end': datetime.datetime(1998, 4, 30, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 86.85000000000001, 'window_start': datetime.datetime(1998, 5, 4, 0, 0), 'window_end': datetime.datetime(1998, 5, 5, 0, 0)}\n",
      "{'country': 'Germany', 'totalamount': 1873.5, 'window_start': datetime.datetime(1998, 5, 5, 0, 0), 'window_end': datetime.datetime(1998, 5, 6, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 1813.0, 'window_start': datetime.datetime(1996, 7, 8, 0, 0), 'window_end': datetime.datetime(1996, 7, 9, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 1444.8000000000002, 'window_start': datetime.datetime(1996, 7, 10, 0, 0), 'window_end': datetime.datetime(1996, 7, 11, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 517.8, 'window_start': datetime.datetime(1996, 7, 15, 0, 0), 'window_end': datetime.datetime(1996, 7, 16, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 448.0, 'window_start': datetime.datetime(1996, 7, 19, 0, 0), 'window_end': datetime.datetime(1996, 7, 20, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 924.0, 'window_start': datetime.datetime(1996, 8, 22, 0, 0), 'window_end': datetime.datetime(1996, 8, 23, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 2721.8, 'window_start': datetime.datetime(1996, 8, 27, 0, 0), 'window_end': datetime.datetime(1996, 8, 28, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 1296.0, 'window_start': datetime.datetime(1996, 8, 28, 0, 0), 'window_end': datetime.datetime(1996, 8, 29, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 349.5, 'window_start': datetime.datetime(1996, 9, 6, 0, 0), 'window_end': datetime.datetime(1996, 9, 7, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 928.0, 'window_start': datetime.datetime(1996, 11, 6, 0, 0), 'window_end': datetime.datetime(1996, 11, 7, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 12281.2, 'window_start': datetime.datetime(1996, 12, 4, 0, 0), 'window_end': datetime.datetime(1996, 12, 5, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 959.2, 'window_start': datetime.datetime(1996, 12, 11, 0, 0), 'window_end': datetime.datetime(1996, 12, 12, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 166.0, 'window_start': datetime.datetime(1996, 12, 18, 0, 0), 'window_end': datetime.datetime(1996, 12, 19, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 2018.2, 'window_start': datetime.datetime(1997, 1, 7, 0, 0), 'window_end': datetime.datetime(1997, 1, 8, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 231.4, 'window_start': datetime.datetime(1997, 1, 14, 0, 0), 'window_end': datetime.datetime(1997, 1, 15, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 3170.8, 'window_start': datetime.datetime(1997, 1, 21, 0, 0), 'window_end': datetime.datetime(1997, 1, 22, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 1020.0, 'window_start': datetime.datetime(1997, 1, 23, 0, 0), 'window_end': datetime.datetime(1997, 1, 24, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 914.4, 'window_start': datetime.datetime(1997, 2, 14, 0, 0), 'window_end': datetime.datetime(1997, 2, 15, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 216.0, 'window_start': datetime.datetime(1997, 3, 6, 0, 0), 'window_end': datetime.datetime(1997, 3, 7, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 1472.0, 'window_start': datetime.datetime(1997, 3, 20, 0, 0), 'window_end': datetime.datetime(1997, 3, 21, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 925.1, 'window_start': datetime.datetime(1997, 3, 26, 0, 0), 'window_end': datetime.datetime(1997, 3, 27, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 912.0, 'window_start': datetime.datetime(1997, 4, 2, 0, 0), 'window_end': datetime.datetime(1997, 4, 3, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 200.0, 'window_start': datetime.datetime(1997, 4, 4, 0, 0), 'window_end': datetime.datetime(1997, 4, 5, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 618.0, 'window_start': datetime.datetime(1997, 4, 21, 0, 0), 'window_end': datetime.datetime(1997, 4, 22, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 2162.8, 'window_start': datetime.datetime(1997, 5, 19, 0, 0), 'window_end': datetime.datetime(1997, 5, 20, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 965.0, 'window_start': datetime.datetime(1997, 6, 10, 0, 0), 'window_end': datetime.datetime(1997, 6, 11, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 387.5, 'window_start': datetime.datetime(1997, 6, 26, 0, 0), 'window_end': datetime.datetime(1997, 6, 27, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 142.5, 'window_start': datetime.datetime(1997, 7, 1, 0, 0), 'window_end': datetime.datetime(1997, 7, 2, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 807.38, 'window_start': datetime.datetime(1997, 7, 2, 0, 0), 'window_end': datetime.datetime(1997, 7, 3, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 1413.0, 'window_start': datetime.datetime(1997, 7, 22, 0, 0), 'window_end': datetime.datetime(1997, 7, 23, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 605.0, 'window_start': datetime.datetime(1997, 8, 6, 0, 0), 'window_end': datetime.datetime(1997, 8, 7, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 2896.25, 'window_start': datetime.datetime(1997, 8, 19, 0, 0), 'window_end': datetime.datetime(1997, 8, 20, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 1422.0, 'window_start': datetime.datetime(1997, 8, 25, 0, 0), 'window_end': datetime.datetime(1997, 8, 26, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 1535.0, 'window_start': datetime.datetime(1997, 8, 26, 0, 0), 'window_end': datetime.datetime(1997, 8, 27, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 636.0, 'window_start': datetime.datetime(1997, 8, 27, 0, 0), 'window_end': datetime.datetime(1997, 8, 28, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 382.5, 'window_start': datetime.datetime(1997, 8, 28, 0, 0), 'window_end': datetime.datetime(1997, 8, 29, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 1820.1999999999998, 'window_start': datetime.datetime(1997, 8, 29, 0, 0), 'window_end': datetime.datetime(1997, 8, 30, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 331.78, 'window_start': datetime.datetime(1997, 9, 1, 0, 0), 'window_end': datetime.datetime(1997, 9, 2, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 1291.6, 'window_start': datetime.datetime(1997, 9, 5, 0, 0), 'window_end': datetime.datetime(1997, 9, 6, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 801.1, 'window_start': datetime.datetime(1997, 9, 29, 0, 0), 'window_end': datetime.datetime(1997, 9, 30, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 1150.0, 'window_start': datetime.datetime(1997, 10, 2, 0, 0), 'window_end': datetime.datetime(1997, 10, 3, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 595.5, 'window_start': datetime.datetime(1997, 10, 14, 0, 0), 'window_end': datetime.datetime(1997, 10, 15, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 3424.0, 'window_start': datetime.datetime(1997, 10, 17, 0, 0), 'window_end': datetime.datetime(1997, 10, 18, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 550.0, 'window_start': datetime.datetime(1997, 10, 28, 0, 0), 'window_end': datetime.datetime(1997, 10, 29, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 287.8, 'window_start': datetime.datetime(1997, 10, 31, 0, 0), 'window_end': datetime.datetime(1997, 11, 1, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 1296.75, 'window_start': datetime.datetime(1997, 11, 4, 0, 0), 'window_end': datetime.datetime(1997, 11, 5, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 1498.35, 'window_start': datetime.datetime(1997, 11, 7, 0, 0), 'window_end': datetime.datetime(1997, 11, 8, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 315.0, 'window_start': datetime.datetime(1997, 12, 9, 0, 0), 'window_end': datetime.datetime(1997, 12, 10, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 280.0, 'window_start': datetime.datetime(1997, 12, 15, 0, 0), 'window_end': datetime.datetime(1997, 12, 16, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 1442.5, 'window_start': datetime.datetime(1997, 12, 18, 0, 0), 'window_end': datetime.datetime(1997, 12, 19, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 1913.85, 'window_start': datetime.datetime(1997, 12, 19, 0, 0), 'window_end': datetime.datetime(1997, 12, 20, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 850.0, 'window_start': datetime.datetime(1997, 12, 22, 0, 0), 'window_end': datetime.datetime(1997, 12, 23, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 393.45, 'window_start': datetime.datetime(1997, 12, 24, 0, 0), 'window_end': datetime.datetime(1997, 12, 25, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 1255.8, 'window_start': datetime.datetime(1997, 12, 30, 0, 0), 'window_end': datetime.datetime(1997, 12, 31, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 140.0, 'window_start': datetime.datetime(1998, 1, 1, 0, 0), 'window_end': datetime.datetime(1998, 1, 2, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 648.0, 'window_start': datetime.datetime(1998, 1, 5, 0, 0), 'window_end': datetime.datetime(1998, 1, 6, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 1974.0, 'window_start': datetime.datetime(1998, 1, 13, 0, 0), 'window_end': datetime.datetime(1998, 1, 14, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 1508.12, 'window_start': datetime.datetime(1998, 1, 15, 0, 0), 'window_end': datetime.datetime(1998, 1, 16, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 919.5, 'window_start': datetime.datetime(1998, 1, 19, 0, 0), 'window_end': datetime.datetime(1998, 1, 20, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 2740.0, 'window_start': datetime.datetime(1998, 1, 26, 0, 0), 'window_end': datetime.datetime(1998, 1, 27, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 2004.6, 'window_start': datetime.datetime(1998, 2, 4, 0, 0), 'window_end': datetime.datetime(1998, 2, 5, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 2086.0, 'window_start': datetime.datetime(1998, 2, 9, 0, 0), 'window_end': datetime.datetime(1998, 2, 10, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 3127.5, 'window_start': datetime.datetime(1998, 2, 13, 0, 0), 'window_end': datetime.datetime(1998, 2, 14, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 45.0, 'window_start': datetime.datetime(1998, 2, 20, 0, 0), 'window_end': datetime.datetime(1998, 2, 21, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 1292.05, 'window_start': datetime.datetime(1998, 2, 24, 0, 0), 'window_end': datetime.datetime(1998, 2, 25, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 958.75, 'window_start': datetime.datetime(1998, 2, 26, 0, 0), 'window_end': datetime.datetime(1998, 2, 27, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 537.5, 'window_start': datetime.datetime(1998, 2, 27, 0, 0), 'window_end': datetime.datetime(1998, 2, 28, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 742.5, 'window_start': datetime.datetime(1998, 3, 3, 0, 0), 'window_end': datetime.datetime(1998, 3, 4, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 559.0, 'window_start': datetime.datetime(1998, 3, 4, 0, 0), 'window_end': datetime.datetime(1998, 3, 5, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 700.0, 'window_start': datetime.datetime(1998, 3, 9, 0, 0), 'window_end': datetime.datetime(1998, 3, 10, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 155.0, 'window_start': datetime.datetime(1998, 3, 18, 0, 0), 'window_end': datetime.datetime(1998, 3, 19, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 1122.0, 'window_start': datetime.datetime(1998, 3, 19, 0, 0), 'window_end': datetime.datetime(1998, 3, 20, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 108.0, 'window_start': datetime.datetime(1998, 3, 23, 0, 0), 'window_end': datetime.datetime(1998, 3, 24, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 15810.0, 'window_start': datetime.datetime(1998, 3, 27, 0, 0), 'window_end': datetime.datetime(1998, 3, 28, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 1353.6, 'window_start': datetime.datetime(1998, 3, 31, 0, 0), 'window_end': datetime.datetime(1998, 4, 1, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 1402.0, 'window_start': datetime.datetime(1998, 4, 14, 0, 0), 'window_end': datetime.datetime(1998, 4, 15, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 405.75, 'window_start': datetime.datetime(1998, 4, 22, 0, 0), 'window_end': datetime.datetime(1998, 4, 23, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 342.0, 'window_start': datetime.datetime(1998, 4, 24, 0, 0), 'window_end': datetime.datetime(1998, 4, 25, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 1665.0, 'window_start': datetime.datetime(1998, 4, 27, 0, 0), 'window_end': datetime.datetime(1998, 4, 28, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 1838.0, 'window_start': datetime.datetime(1998, 4, 29, 0, 0), 'window_end': datetime.datetime(1998, 4, 30, 0, 0)}\n",
      "{'country': 'Brazil', 'totalamount': 2384.8, 'window_start': datetime.datetime(1998, 5, 4, 0, 0), 'window_end': datetime.datetime(1998, 5, 5, 0, 0)}\n",
      "{'country': 'Belgium', 'totalamount': 3730.0, 'window_start': datetime.datetime(1996, 7, 9, 0, 0), 'window_end': datetime.datetime(1996, 7, 10, 0, 0)}\n",
      "{'country': 'Belgium', 'totalamount': 2708.7999999999997, 'window_start': datetime.datetime(1996, 9, 10, 0, 0), 'window_end': datetime.datetime(1996, 9, 11, 0, 0)}\n",
      "{'country': 'Belgium', 'totalamount': 3891.0, 'window_start': datetime.datetime(1997, 2, 26, 0, 0), 'window_end': datetime.datetime(1997, 2, 27, 0, 0)}\n",
      "{'country': 'Belgium', 'totalamount': 713.3, 'window_start': datetime.datetime(1997, 3, 4, 0, 0), 'window_end': datetime.datetime(1997, 3, 5, 0, 0)}\n",
      "{'country': 'Belgium', 'totalamount': 1770.8000000000002, 'window_start': datetime.datetime(1997, 3, 14, 0, 0), 'window_end': datetime.datetime(1997, 3, 15, 0, 0)}\n",
      "{'country': 'Belgium', 'totalamount': 946.0, 'window_start': datetime.datetime(1997, 5, 7, 0, 0), 'window_end': datetime.datetime(1997, 5, 8, 0, 0)}\n",
      "{'country': 'Belgium', 'totalamount': 1434.0, 'window_start': datetime.datetime(1997, 8, 28, 0, 0), 'window_end': datetime.datetime(1997, 8, 29, 0, 0)}\n",
      "{'country': 'Belgium', 'totalamount': 3304.0, 'window_start': datetime.datetime(1997, 12, 1, 0, 0), 'window_end': datetime.datetime(1997, 12, 2, 0, 0)}\n",
      "{'country': 'Belgium', 'totalamount': 28.0, 'window_start': datetime.datetime(1997, 12, 5, 0, 0), 'window_end': datetime.datetime(1997, 12, 6, 0, 0)}\n",
      "{'country': 'Belgium', 'totalamount': 4581.0, 'window_start': datetime.datetime(1998, 1, 20, 0, 0), 'window_end': datetime.datetime(1998, 1, 21, 0, 0)}\n",
      "{'country': 'Belgium', 'totalamount': 1112.0, 'window_start': datetime.datetime(1998, 1, 22, 0, 0), 'window_end': datetime.datetime(1998, 1, 23, 0, 0)}\n",
      "{'country': 'Belgium', 'totalamount': 1209.0, 'window_start': datetime.datetime(1998, 2, 12, 0, 0), 'window_end': datetime.datetime(1998, 2, 13, 0, 0)}\n",
      "{'country': 'Belgium', 'totalamount': 2200.0, 'window_start': datetime.datetime(1998, 2, 17, 0, 0), 'window_end': datetime.datetime(1998, 2, 18, 0, 0)}\n",
      "{'country': 'Belgium', 'totalamount': 750.5, 'window_start': datetime.datetime(1998, 2, 19, 0, 0), 'window_end': datetime.datetime(1998, 2, 20, 0, 0)}\n",
      "{'country': 'Belgium', 'totalamount': 2455.0, 'window_start': datetime.datetime(1998, 3, 6, 0, 0), 'window_end': datetime.datetime(1998, 3, 7, 0, 0)}\n",
      "{'country': 'Belgium', 'totalamount': 1500.7, 'window_start': datetime.datetime(1998, 3, 26, 0, 0), 'window_end': datetime.datetime(1998, 3, 27, 0, 0)}\n",
      "{'country': 'Belgium', 'totalamount': 295.38, 'window_start': datetime.datetime(1998, 4, 7, 0, 0), 'window_end': datetime.datetime(1998, 4, 8, 0, 0)}\n",
      "{'country': 'Belgium', 'totalamount': 1754.5, 'window_start': datetime.datetime(1998, 4, 20, 0, 0), 'window_end': datetime.datetime(1998, 4, 21, 0, 0)}\n",
      "{'country': 'Belgium', 'totalamount': 751.0, 'window_start': datetime.datetime(1998, 4, 21, 0, 0), 'window_end': datetime.datetime(1998, 4, 22, 0, 0)}\n",
      "{'country': 'Switzerland', 'totalamount': 625.2, 'window_start': datetime.datetime(1996, 7, 11, 0, 0), 'window_end': datetime.datetime(1996, 7, 12, 0, 0)}\n",
      "{'country': 'Switzerland', 'totalamount': 2490.5, 'window_start': datetime.datetime(1996, 7, 12, 0, 0), 'window_end': datetime.datetime(1996, 7, 13, 0, 0)}\n",
      "{'country': 'Switzerland', 'totalamount': 1174.0, 'window_start': datetime.datetime(1996, 12, 3, 0, 0), 'window_end': datetime.datetime(1996, 12, 4, 0, 0)}\n",
      "{'country': 'Switzerland', 'totalamount': 2208.0, 'window_start': datetime.datetime(1997, 1, 20, 0, 0), 'window_end': datetime.datetime(1997, 1, 21, 0, 0)}\n",
      "{'country': 'Switzerland', 'totalamount': 2356.0, 'window_start': datetime.datetime(1997, 4, 28, 0, 0), 'window_end': datetime.datetime(1997, 4, 29, 0, 0)}\n",
      "{'country': 'Switzerland', 'totalamount': 1823.8, 'window_start': datetime.datetime(1997, 5, 14, 0, 0), 'window_end': datetime.datetime(1997, 5, 15, 0, 0)}\n",
      "{'country': 'Switzerland', 'totalamount': 4666.9400000000005, 'window_start': datetime.datetime(1997, 9, 12, 0, 0), 'window_end': datetime.datetime(1997, 9, 13, 0, 0)}\n",
      "{'country': 'Switzerland', 'totalamount': 1990.0, 'window_start': datetime.datetime(1997, 11, 6, 0, 0), 'window_end': datetime.datetime(1997, 11, 7, 0, 0)}\n",
      "{'country': 'Switzerland', 'totalamount': 2311.7, 'window_start': datetime.datetime(1997, 11, 19, 0, 0), 'window_end': datetime.datetime(1997, 11, 20, 0, 0)}\n",
      "{'country': 'Switzerland', 'totalamount': 1701.46, 'window_start': datetime.datetime(1997, 11, 24, 0, 0), 'window_end': datetime.datetime(1997, 11, 25, 0, 0)}\n",
      "{'country': 'Switzerland', 'totalamount': 1644.6, 'window_start': datetime.datetime(1997, 11, 28, 0, 0), 'window_end': datetime.datetime(1997, 11, 29, 0, 0)}\n",
      "{'country': 'Switzerland', 'totalamount': 837.0, 'window_start': datetime.datetime(1998, 3, 6, 0, 0), 'window_end': datetime.datetime(1998, 3, 7, 0, 0)}\n",
      "{'country': 'Switzerland', 'totalamount': 482.9, 'window_start': datetime.datetime(1998, 3, 16, 0, 0), 'window_end': datetime.datetime(1998, 3, 17, 0, 0)}\n",
      "{'country': 'Switzerland', 'totalamount': 1255.6, 'window_start': datetime.datetime(1998, 3, 20, 0, 0), 'window_end': datetime.datetime(1998, 3, 21, 0, 0)}\n",
      "{'country': 'Switzerland', 'totalamount': 1286.8, 'window_start': datetime.datetime(1998, 4, 16, 0, 0), 'window_end': datetime.datetime(1998, 4, 17, 0, 0)}\n",
      "{'country': 'Switzerland', 'totalamount': 3592.0, 'window_start': datetime.datetime(1998, 4, 17, 0, 0), 'window_end': datetime.datetime(1998, 4, 18, 0, 0)}\n",
      "{'country': 'Switzerland', 'totalamount': 1887.0, 'window_start': datetime.datetime(1998, 4, 22, 0, 0), 'window_end': datetime.datetime(1998, 4, 23, 0, 0)}\n",
      "{'country': 'Switzerland', 'totalamount': 586.0, 'window_start': datetime.datetime(1998, 5, 6, 0, 0), 'window_end': datetime.datetime(1998, 5, 7, 0, 0)}\n",
      "{'country': 'Venezuela', 'totalamount': 1119.9, 'window_start': datetime.datetime(1996, 7, 16, 0, 0), 'window_end': datetime.datetime(1996, 7, 17, 0, 0)}\n",
      "{'country': 'Venezuela', 'totalamount': 1101.2, 'window_start': datetime.datetime(1996, 7, 30, 0, 0), 'window_end': datetime.datetime(1996, 7, 31, 0, 0)}\n",
      "{'country': 'Venezuela', 'totalamount': 1414.8000000000002, 'window_start': datetime.datetime(1996, 8, 16, 0, 0), 'window_end': datetime.datetime(1996, 8, 17, 0, 0)}\n",
      "{'country': 'Venezuela', 'totalamount': 1050.6, 'window_start': datetime.datetime(1996, 9, 3, 0, 0), 'window_end': datetime.datetime(1996, 9, 4, 0, 0)}\n",
      "{'country': 'Venezuela', 'totalamount': 1940.0, 'window_start': datetime.datetime(1996, 10, 16, 0, 0), 'window_end': datetime.datetime(1996, 10, 17, 0, 0)}\n",
      "{'country': 'Venezuela', 'totalamount': 1360.0, 'window_start': datetime.datetime(1996, 11, 19, 0, 0), 'window_end': datetime.datetime(1996, 11, 20, 0, 0)}\n",
      "{'country': 'Venezuela', 'totalamount': 112.0, 'window_start': datetime.datetime(1996, 12, 12, 0, 0), 'window_end': datetime.datetime(1996, 12, 13, 0, 0)}\n",
      "{'country': 'Venezuela', 'totalamount': 2333.2000000000003, 'window_start': datetime.datetime(1996, 12, 26, 0, 0), 'window_end': datetime.datetime(1996, 12, 27, 0, 0)}\n",
      "{'country': 'Venezuela', 'totalamount': 400.0, 'window_start': datetime.datetime(1997, 1, 6, 0, 0), 'window_end': datetime.datetime(1997, 1, 7, 0, 0)}\n",
      "{'country': 'Venezuela', 'totalamount': 2051.6, 'window_start': datetime.datetime(1997, 2, 28, 0, 0), 'window_end': datetime.datetime(1997, 3, 1, 0, 0)}\n",
      "{'country': 'Venezuela', 'totalamount': 182.4, 'window_start': datetime.datetime(1997, 3, 17, 0, 0), 'window_end': datetime.datetime(1997, 3, 18, 0, 0)}\n",
      "{'country': 'Venezuela', 'totalamount': 1760.0, 'window_start': datetime.datetime(1997, 3, 25, 0, 0), 'window_end': datetime.datetime(1997, 3, 26, 0, 0)}\n",
      "{'country': 'Venezuela', 'totalamount': 1272.0, 'window_start': datetime.datetime(1997, 3, 26, 0, 0), 'window_end': datetime.datetime(1997, 3, 27, 0, 0)}\n",
      "{'country': 'Venezuela', 'totalamount': 3163.2, 'window_start': datetime.datetime(1997, 3, 31, 0, 0), 'window_end': datetime.datetime(1997, 4, 1, 0, 0)}\n",
      "{'country': 'Venezuela', 'totalamount': 575.0, 'window_start': datetime.datetime(1997, 4, 7, 0, 0), 'window_end': datetime.datetime(1997, 4, 8, 0, 0)}\n",
      "{'country': 'Venezuela', 'totalamount': 1412.0, 'window_start': datetime.datetime(1997, 4, 8, 0, 0), 'window_end': datetime.datetime(1997, 4, 9, 0, 0)}\n",
      "{'country': 'Venezuela', 'totalamount': 1770.0, 'window_start': datetime.datetime(1997, 5, 21, 0, 0), 'window_end': datetime.datetime(1997, 5, 22, 0, 0)}\n",
      "{'country': 'Venezuela', 'totalamount': 880.5, 'window_start': datetime.datetime(1997, 5, 29, 0, 0), 'window_end': datetime.datetime(1997, 5, 30, 0, 0)}\n",
      "{'country': 'Venezuela', 'totalamount': 2285.0, 'window_start': datetime.datetime(1997, 7, 16, 0, 0), 'window_end': datetime.datetime(1997, 7, 17, 0, 0)}\n",
      "{'country': 'Venezuela', 'totalamount': 358.0, 'window_start': datetime.datetime(1997, 7, 29, 0, 0), 'window_end': datetime.datetime(1997, 7, 30, 0, 0)}\n",
      "{'country': 'Venezuela', 'totalamount': 2720.05, 'window_start': datetime.datetime(1997, 8, 20, 0, 0), 'window_end': datetime.datetime(1997, 8, 21, 0, 0)}\n",
      "{'country': 'Venezuela', 'totalamount': 2054.0, 'window_start': datetime.datetime(1997, 8, 22, 0, 0), 'window_end': datetime.datetime(1997, 8, 23, 0, 0)}\n",
      "{'country': 'Venezuela', 'totalamount': 1073.9, 'window_start': datetime.datetime(1997, 10, 8, 0, 0), 'window_end': datetime.datetime(1997, 10, 9, 0, 0)}\n",
      "{'country': 'Venezuela', 'totalamount': 378.0, 'window_start': datetime.datetime(1997, 10, 15, 0, 0), 'window_end': datetime.datetime(1997, 10, 16, 0, 0)}\n",
      "{'country': 'Venezuela', 'totalamount': 1850.0, 'window_start': datetime.datetime(1997, 11, 4, 0, 0), 'window_end': datetime.datetime(1997, 11, 5, 0, 0)}\n",
      "{'country': 'Venezuela', 'totalamount': 720.0, 'window_start': datetime.datetime(1997, 12, 16, 0, 0), 'window_end': datetime.datetime(1997, 12, 17, 0, 0)}\n",
      "{'country': 'Venezuela', 'totalamount': 387.5, 'window_start': datetime.datetime(1997, 12, 18, 0, 0), 'window_end': datetime.datetime(1997, 12, 19, 0, 0)}\n",
      "{'country': 'Venezuela', 'totalamount': 2878.08, 'window_start': datetime.datetime(1997, 12, 25, 0, 0), 'window_end': datetime.datetime(1997, 12, 26, 0, 0)}\n",
      "{'country': 'Venezuela', 'totalamount': 852.0, 'window_start': datetime.datetime(1998, 1, 2, 0, 0), 'window_end': datetime.datetime(1998, 1, 3, 0, 0)}\n",
      "{'country': 'Venezuela', 'totalamount': 3107.5, 'window_start': datetime.datetime(1998, 1, 9, 0, 0), 'window_end': datetime.datetime(1998, 1, 10, 0, 0)}\n",
      "{'country': 'Venezuela', 'totalamount': 2848.5, 'window_start': datetime.datetime(1998, 1, 19, 0, 0), 'window_end': datetime.datetime(1998, 1, 20, 0, 0)}\n",
      "{'country': 'Venezuela', 'totalamount': 519.0, 'window_start': datetime.datetime(1998, 2, 2, 0, 0), 'window_end': datetime.datetime(1998, 2, 3, 0, 0)}\n",
      "{'country': 'Venezuela', 'totalamount': 144.0, 'window_start': datetime.datetime(1998, 2, 20, 0, 0), 'window_end': datetime.datetime(1998, 2, 21, 0, 0)}\n",
      "{'country': 'Venezuela', 'totalamount': 934.5, 'window_start': datetime.datetime(1998, 2, 23, 0, 0), 'window_end': datetime.datetime(1998, 2, 24, 0, 0)}\n",
      "{'country': 'Venezuela', 'totalamount': 1122.8, 'window_start': datetime.datetime(1998, 3, 2, 0, 0), 'window_end': datetime.datetime(1998, 3, 3, 0, 0)}\n",
      "{'country': 'Venezuela', 'totalamount': 1902.1, 'window_start': datetime.datetime(1998, 3, 17, 0, 0), 'window_end': datetime.datetime(1998, 3, 18, 0, 0)}\n",
      "{'country': 'Venezuela', 'totalamount': 1762.7, 'window_start': datetime.datetime(1998, 3, 18, 0, 0), 'window_end': datetime.datetime(1998, 3, 19, 0, 0)}\n",
      "{'country': 'Venezuela', 'totalamount': 276.6, 'window_start': datetime.datetime(1998, 3, 19, 0, 0), 'window_end': datetime.datetime(1998, 3, 20, 0, 0)}\n",
      "{'country': 'Venezuela', 'totalamount': 912.0, 'window_start': datetime.datetime(1998, 3, 25, 0, 0), 'window_end': datetime.datetime(1998, 3, 26, 0, 0)}\n",
      "{'country': 'Venezuela', 'totalamount': 1980.0, 'window_start': datetime.datetime(1998, 4, 3, 0, 0), 'window_end': datetime.datetime(1998, 4, 4, 0, 0)}\n",
      "{'country': 'Venezuela', 'totalamount': 270.2, 'window_start': datetime.datetime(1998, 4, 10, 0, 0), 'window_end': datetime.datetime(1998, 4, 11, 0, 0)}\n",
      "{'country': 'Venezuela', 'totalamount': 3090.0, 'window_start': datetime.datetime(1998, 4, 21, 0, 0), 'window_end': datetime.datetime(1998, 4, 22, 0, 0)}\n",
      "{'country': 'Venezuela', 'totalamount': 1727.5, 'window_start': datetime.datetime(1998, 4, 28, 0, 0), 'window_end': datetime.datetime(1998, 4, 29, 0, 0)}\n",
      "{'country': 'Venezuela', 'totalamount': 252.56, 'window_start': datetime.datetime(1998, 5, 1, 0, 0), 'window_end': datetime.datetime(1998, 5, 2, 0, 0)}\n",
      "{'country': 'Venezuela', 'totalamount': 510.0, 'window_start': datetime.datetime(1998, 5, 5, 0, 0), 'window_end': datetime.datetime(1998, 5, 6, 0, 0)}\n",
      "{'country': 'Austria', 'totalamount': 2018.6, 'window_start': datetime.datetime(1996, 7, 17, 0, 0), 'window_end': datetime.datetime(1996, 7, 18, 0, 0)}\n",
      "{'country': 'Austria', 'totalamount': 2464.8, 'window_start': datetime.datetime(1996, 7, 23, 0, 0), 'window_end': datetime.datetime(1996, 7, 24, 0, 0)}\n",
      "{'country': 'Austria', 'totalamount': 5677.6, 'window_start': datetime.datetime(1996, 11, 11, 0, 0), 'window_end': datetime.datetime(1996, 11, 12, 0, 0)}\n",
      "{'country': 'Austria', 'totalamount': 10741.6, 'window_start': datetime.datetime(1996, 11, 13, 0, 0), 'window_end': datetime.datetime(1996, 11, 14, 0, 0)}\n",
      "{'country': 'Austria', 'totalamount': 1834.2, 'window_start': datetime.datetime(1996, 11, 29, 0, 0), 'window_end': datetime.datetime(1996, 11, 30, 0, 0)}\n",
      "{'country': 'Austria', 'totalamount': 2900.0, 'window_start': datetime.datetime(1996, 12, 13, 0, 0), 'window_end': datetime.datetime(1996, 12, 14, 0, 0)}\n",
      "{'country': 'Austria', 'totalamount': 2275.2, 'window_start': datetime.datetime(1996, 12, 23, 0, 0), 'window_end': datetime.datetime(1996, 12, 24, 0, 0)}\n",
      "{'country': 'Austria', 'totalamount': 1440.0, 'window_start': datetime.datetime(1996, 12, 24, 0, 0), 'window_end': datetime.datetime(1996, 12, 25, 0, 0)}\n",
      "{'country': 'Austria', 'totalamount': 2713.5, 'window_start': datetime.datetime(1997, 1, 2, 0, 0), 'window_end': datetime.datetime(1997, 1, 3, 0, 0)}\n",
      "{'country': 'Austria', 'totalamount': 1005.9000000000001, 'window_start': datetime.datetime(1997, 1, 3, 0, 0), 'window_end': datetime.datetime(1997, 1, 4, 0, 0)}\n",
      "{'country': 'Austria', 'totalamount': 651.0, 'window_start': datetime.datetime(1997, 1, 27, 0, 0), 'window_end': datetime.datetime(1997, 1, 28, 0, 0)}\n",
      "{'country': 'Austria', 'totalamount': 5796.0, 'window_start': datetime.datetime(1997, 1, 30, 0, 0), 'window_end': datetime.datetime(1997, 1, 31, 0, 0)}\n",
      "{'country': 'Austria', 'totalamount': 1792.0, 'window_start': datetime.datetime(1997, 2, 11, 0, 0), 'window_end': datetime.datetime(1997, 2, 12, 0, 0)}\n",
      "{'country': 'Austria', 'totalamount': 502.20000000000005, 'window_start': datetime.datetime(1997, 3, 28, 0, 0), 'window_end': datetime.datetime(1997, 3, 29, 0, 0)}\n",
      "{'country': 'Austria', 'totalamount': 8623.45, 'window_start': datetime.datetime(1997, 4, 22, 0, 0), 'window_end': datetime.datetime(1997, 4, 23, 0, 0)}\n",
      "{'country': 'Austria', 'totalamount': 4180.0, 'window_start': datetime.datetime(1997, 5, 8, 0, 0), 'window_end': datetime.datetime(1997, 5, 9, 0, 0)}\n",
      "{'country': 'Austria', 'totalamount': 647.75, 'window_start': datetime.datetime(1997, 6, 17, 0, 0), 'window_end': datetime.datetime(1997, 6, 18, 0, 0)}\n",
      "{'country': 'Austria', 'totalamount': 6300.0, 'window_start': datetime.datetime(1997, 7, 10, 0, 0), 'window_end': datetime.datetime(1997, 7, 11, 0, 0)}\n",
      "{'country': 'Austria', 'totalamount': 800.1, 'window_start': datetime.datetime(1997, 7, 11, 0, 0), 'window_end': datetime.datetime(1997, 7, 12, 0, 0)}\n",
      "{'country': 'Austria', 'totalamount': 6483.05, 'window_start': datetime.datetime(1997, 8, 15, 0, 0), 'window_end': datetime.datetime(1997, 8, 16, 0, 0)}\n",
      "{'country': 'Austria', 'totalamount': 1921.0, 'window_start': datetime.datetime(1997, 9, 12, 0, 0), 'window_end': datetime.datetime(1997, 9, 13, 0, 0)}\n",
      "{'country': 'Austria', 'totalamount': 1638.45, 'window_start': datetime.datetime(1997, 9, 30, 0, 0), 'window_end': datetime.datetime(1997, 10, 1, 0, 0)}\n",
      "{'country': 'Austria', 'totalamount': 3600.73, 'window_start': datetime.datetime(1997, 10, 9, 0, 0), 'window_end': datetime.datetime(1997, 10, 10, 0, 0)}\n",
      "{'country': 'Austria', 'totalamount': 1912.85, 'window_start': datetime.datetime(1997, 11, 19, 0, 0), 'window_end': datetime.datetime(1997, 11, 20, 0, 0)}\n",
      "{'country': 'Austria', 'totalamount': 2540.0, 'window_start': datetime.datetime(1997, 12, 3, 0, 0), 'window_end': datetime.datetime(1997, 12, 4, 0, 0)}\n",
      "{'country': 'Austria', 'totalamount': 344.0, 'window_start': datetime.datetime(1997, 12, 10, 0, 0), 'window_end': datetime.datetime(1997, 12, 11, 0, 0)}\n",
      "{'country': 'Austria', 'totalamount': 2216.25, 'window_start': datetime.datetime(1997, 12, 11, 0, 0), 'window_end': datetime.datetime(1997, 12, 12, 0, 0)}\n",
      "{'country': 'Austria', 'totalamount': 6984.5, 'window_start': datetime.datetime(1997, 12, 15, 0, 0), 'window_end': datetime.datetime(1997, 12, 16, 0, 0)}\n",
      "{'country': 'Austria', 'totalamount': 2499.25, 'window_start': datetime.datetime(1997, 12, 24, 0, 0), 'window_end': datetime.datetime(1997, 12, 25, 0, 0)}\n",
      "{'country': 'Austria', 'totalamount': 4705.5, 'window_start': datetime.datetime(1998, 1, 16, 0, 0), 'window_end': datetime.datetime(1998, 1, 17, 0, 0)}\n",
      "{'country': 'Austria', 'totalamount': 735.0, 'window_start': datetime.datetime(1998, 1, 21, 0, 0), 'window_end': datetime.datetime(1998, 1, 22, 0, 0)}\n",
      "{'country': 'Austria', 'totalamount': 3490.0, 'window_start': datetime.datetime(1998, 1, 27, 0, 0), 'window_end': datetime.datetime(1998, 1, 28, 0, 0)}\n",
      "{'country': 'Austria', 'totalamount': 6379.4, 'window_start': datetime.datetime(1998, 2, 18, 0, 0), 'window_end': datetime.datetime(1998, 2, 19, 0, 0)}\n",
      "{'country': 'Austria', 'totalamount': 1408.0, 'window_start': datetime.datetime(1998, 3, 23, 0, 0), 'window_end': datetime.datetime(1998, 3, 24, 0, 0)}\n",
      "{'country': 'Austria', 'totalamount': 4813.5, 'window_start': datetime.datetime(1998, 3, 26, 0, 0), 'window_end': datetime.datetime(1998, 3, 27, 0, 0)}\n",
      "{'country': 'Austria', 'totalamount': 4931.0, 'window_start': datetime.datetime(1998, 4, 1, 0, 0), 'window_end': datetime.datetime(1998, 4, 2, 0, 0)}\n",
      "{'country': 'Austria', 'totalamount': 4903.5, 'window_start': datetime.datetime(1998, 4, 8, 0, 0), 'window_end': datetime.datetime(1998, 4, 9, 0, 0)}\n",
      "{'country': 'Austria', 'totalamount': 6750.0, 'window_start': datetime.datetime(1998, 4, 13, 0, 0), 'window_end': datetime.datetime(1998, 4, 14, 0, 0)}\n",
      "{'country': 'Austria', 'totalamount': 3658.75, 'window_start': datetime.datetime(1998, 4, 27, 0, 0), 'window_end': datetime.datetime(1998, 4, 28, 0, 0)}\n",
      "{'country': 'Austria', 'totalamount': 5218.0, 'window_start': datetime.datetime(1998, 5, 5, 0, 0), 'window_end': datetime.datetime(1998, 5, 6, 0, 0)}\n",
      "{'country': 'Mexico', 'totalamount': 100.8, 'window_start': datetime.datetime(1996, 7, 18, 0, 0), 'window_end': datetime.datetime(1996, 7, 19, 0, 0)}\n",
      "{'country': 'Mexico', 'totalamount': 420.0, 'window_start': datetime.datetime(1996, 8, 8, 0, 0), 'window_end': datetime.datetime(1996, 8, 9, 0, 0)}\n",
      "{'country': 'Mexico', 'totalamount': 848.7, 'window_start': datetime.datetime(1996, 8, 29, 0, 0), 'window_end': datetime.datetime(1996, 8, 30, 0, 0)}\n",
      "{'country': 'Mexico', 'totalamount': 954.4, 'window_start': datetime.datetime(1996, 9, 12, 0, 0), 'window_end': datetime.datetime(1996, 9, 13, 0, 0)}\n",
      "{'country': 'Mexico', 'totalamount': 88.8, 'window_start': datetime.datetime(1996, 9, 18, 0, 0), 'window_end': datetime.datetime(1996, 9, 19, 0, 0)}\n",
      "{'country': 'Mexico', 'totalamount': 1191.1999999999998, 'window_start': datetime.datetime(1996, 10, 2, 0, 0), 'window_end': datetime.datetime(1996, 10, 3, 0, 0)}\n",
      "{'country': 'Mexico', 'totalamount': 112.0, 'window_start': datetime.datetime(1996, 10, 4, 0, 0), 'window_end': datetime.datetime(1996, 10, 5, 0, 0)}\n",
      "{'country': 'Mexico', 'totalamount': 568.8, 'window_start': datetime.datetime(1996, 11, 14, 0, 0), 'window_end': datetime.datetime(1996, 11, 15, 0, 0)}\n",
      "{'country': 'Mexico', 'totalamount': 403.20000000000005, 'window_start': datetime.datetime(1996, 11, 27, 0, 0), 'window_end': datetime.datetime(1996, 11, 28, 0, 0)}\n",
      "{'country': 'Mexico', 'totalamount': 1249.1, 'window_start': datetime.datetime(1997, 3, 13, 0, 0), 'window_end': datetime.datetime(1997, 3, 14, 0, 0)}\n",
      "{'country': 'Mexico', 'totalamount': 816.3, 'window_start': datetime.datetime(1997, 4, 10, 0, 0), 'window_end': datetime.datetime(1997, 4, 11, 0, 0)}\n",
      "{'country': 'Mexico', 'totalamount': 881.25, 'window_start': datetime.datetime(1997, 4, 15, 0, 0), 'window_end': datetime.datetime(1997, 4, 16, 0, 0)}\n",
      "{'country': 'Mexico', 'totalamount': 4150.05, 'window_start': datetime.datetime(1997, 4, 25, 0, 0), 'window_end': datetime.datetime(1997, 4, 26, 0, 0)}\n",
      "{'country': 'Mexico', 'totalamount': 2156.5, 'window_start': datetime.datetime(1997, 5, 13, 0, 0), 'window_end': datetime.datetime(1997, 5, 14, 0, 0)}\n",
      "{'country': 'Mexico', 'totalamount': 2082.0, 'window_start': datetime.datetime(1997, 6, 19, 0, 0), 'window_end': datetime.datetime(1997, 6, 20, 0, 0)}\n",
      "{'country': 'Mexico', 'totalamount': 838.45, 'window_start': datetime.datetime(1997, 6, 23, 0, 0), 'window_end': datetime.datetime(1997, 6, 24, 0, 0)}\n",
      "{'country': 'Mexico', 'totalamount': 479.75, 'window_start': datetime.datetime(1997, 8, 8, 0, 0), 'window_end': datetime.datetime(1997, 8, 9, 0, 0)}\n",
      "{'country': 'Mexico', 'totalamount': 1491.75, 'window_start': datetime.datetime(1997, 9, 22, 0, 0), 'window_end': datetime.datetime(1997, 9, 23, 0, 0)}\n",
      "{'country': 'Mexico', 'totalamount': 375.5, 'window_start': datetime.datetime(1997, 9, 25, 0, 0), 'window_end': datetime.datetime(1997, 9, 26, 0, 0)}\n",
      "{'country': 'Mexico', 'totalamount': 320.0, 'window_start': datetime.datetime(1997, 11, 28, 0, 0), 'window_end': datetime.datetime(1997, 11, 29, 0, 0)}\n",
      "{'country': 'Mexico', 'totalamount': 975.0, 'window_start': datetime.datetime(1998, 1, 20, 0, 0), 'window_end': datetime.datetime(1998, 1, 21, 0, 0)}\n",
      "{'country': 'Mexico', 'totalamount': 660.0, 'window_start': datetime.datetime(1998, 1, 28, 0, 0), 'window_end': datetime.datetime(1998, 1, 29, 0, 0)}\n",
      "{'country': 'Mexico', 'totalamount': 539.5, 'window_start': datetime.datetime(1998, 2, 27, 0, 0), 'window_end': datetime.datetime(1998, 2, 28, 0, 0)}\n",
      "{'country': 'Mexico', 'totalamount': 514.4, 'window_start': datetime.datetime(1998, 3, 4, 0, 0), 'window_end': datetime.datetime(1998, 3, 5, 0, 0)}\n",
      "{'country': 'Mexico', 'totalamount': 1196.0, 'window_start': datetime.datetime(1998, 4, 2, 0, 0), 'window_end': datetime.datetime(1998, 4, 3, 0, 0)}\n",
      "{'country': 'Mexico', 'totalamount': 360.0, 'window_start': datetime.datetime(1998, 5, 4, 0, 0), 'window_end': datetime.datetime(1998, 5, 5, 0, 0)}\n",
      "{'country': 'Mexico', 'totalamount': 300.0, 'window_start': datetime.datetime(1998, 5, 5, 0, 0), 'window_end': datetime.datetime(1998, 5, 6, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 624.8, 'window_start': datetime.datetime(1996, 7, 22, 0, 0), 'window_end': datetime.datetime(1996, 7, 23, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 676.0, 'window_start': datetime.datetime(1996, 7, 31, 0, 0), 'window_end': datetime.datetime(1996, 8, 1, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 48.0, 'window_start': datetime.datetime(1996, 8, 1, 0, 0), 'window_end': datetime.datetime(1996, 8, 2, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 1456.0, 'window_start': datetime.datetime(1996, 8, 2, 0, 0), 'window_end': datetime.datetime(1996, 8, 3, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 1887.6000000000001, 'window_start': datetime.datetime(1996, 8, 30, 0, 0), 'window_end': datetime.datetime(1996, 8, 31, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 4157.0, 'window_start': datetime.datetime(1996, 9, 13, 0, 0), 'window_end': datetime.datetime(1996, 9, 14, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 424.0, 'window_start': datetime.datetime(1996, 9, 17, 0, 0), 'window_end': datetime.datetime(1996, 9, 18, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 336.0, 'window_start': datetime.datetime(1996, 9, 20, 0, 0), 'window_end': datetime.datetime(1996, 9, 21, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 2327.0, 'window_start': datetime.datetime(1996, 9, 25, 0, 0), 'window_end': datetime.datetime(1996, 9, 26, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 2835.0, 'window_start': datetime.datetime(1996, 9, 27, 0, 0), 'window_end': datetime.datetime(1996, 9, 28, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 288.0, 'window_start': datetime.datetime(1996, 9, 30, 0, 0), 'window_end': datetime.datetime(1996, 10, 1, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 6155.9, 'window_start': datetime.datetime(1996, 10, 8, 0, 0), 'window_end': datetime.datetime(1996, 10, 9, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 4819.400000000001, 'window_start': datetime.datetime(1996, 10, 15, 0, 0), 'window_end': datetime.datetime(1996, 10, 16, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 934.5, 'window_start': datetime.datetime(1996, 10, 25, 0, 0), 'window_end': datetime.datetime(1996, 10, 26, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 2856.0, 'window_start': datetime.datetime(1996, 11, 1, 0, 0), 'window_end': datetime.datetime(1996, 11, 2, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 1731.2, 'window_start': datetime.datetime(1996, 11, 5, 0, 0), 'window_end': datetime.datetime(1996, 11, 6, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 141.60000000000002, 'window_start': datetime.datetime(1996, 11, 8, 0, 0), 'window_end': datetime.datetime(1996, 11, 9, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 2527.2, 'window_start': datetime.datetime(1996, 12, 2, 0, 0), 'window_end': datetime.datetime(1996, 12, 3, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 338.0, 'window_start': datetime.datetime(1996, 12, 6, 0, 0), 'window_end': datetime.datetime(1996, 12, 7, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 864.0, 'window_start': datetime.datetime(1996, 12, 17, 0, 0), 'window_end': datetime.datetime(1996, 12, 18, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 3744.6000000000004, 'window_start': datetime.datetime(1996, 12, 25, 0, 0), 'window_end': datetime.datetime(1996, 12, 26, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 2736.0, 'window_start': datetime.datetime(1996, 12, 30, 0, 0), 'window_end': datetime.datetime(1996, 12, 31, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 3868.6, 'window_start': datetime.datetime(1997, 1, 1, 0, 0), 'window_end': datetime.datetime(1997, 1, 2, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 102.4, 'window_start': datetime.datetime(1997, 1, 15, 0, 0), 'window_end': datetime.datetime(1997, 1, 16, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 485.0, 'window_start': datetime.datetime(1997, 1, 31, 0, 0), 'window_end': datetime.datetime(1997, 2, 1, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 7548.1, 'window_start': datetime.datetime(1997, 2, 10, 0, 0), 'window_end': datetime.datetime(1997, 2, 11, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 2096.0, 'window_start': datetime.datetime(1997, 2, 20, 0, 0), 'window_end': datetime.datetime(1997, 2, 21, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 1125.5, 'window_start': datetime.datetime(1997, 3, 10, 0, 0), 'window_end': datetime.datetime(1997, 3, 11, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 10495.6, 'window_start': datetime.datetime(1997, 3, 19, 0, 0), 'window_end': datetime.datetime(1997, 3, 20, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 147.0, 'window_start': datetime.datetime(1997, 3, 21, 0, 0), 'window_end': datetime.datetime(1997, 3, 22, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 704.0, 'window_start': datetime.datetime(1997, 3, 24, 0, 0), 'window_end': datetime.datetime(1997, 3, 25, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 1388.5, 'window_start': datetime.datetime(1997, 4, 11, 0, 0), 'window_end': datetime.datetime(1997, 4, 12, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 4735.4400000000005, 'window_start': datetime.datetime(1997, 4, 18, 0, 0), 'window_end': datetime.datetime(1997, 4, 19, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 396.2, 'window_start': datetime.datetime(1997, 5, 6, 0, 0), 'window_end': datetime.datetime(1997, 5, 7, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 417.2, 'window_start': datetime.datetime(1997, 5, 21, 0, 0), 'window_end': datetime.datetime(1997, 5, 22, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 210.0, 'window_start': datetime.datetime(1997, 5, 22, 0, 0), 'window_end': datetime.datetime(1997, 5, 23, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 3680.5, 'window_start': datetime.datetime(1997, 6, 2, 0, 0), 'window_end': datetime.datetime(1997, 6, 3, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 1299.0, 'window_start': datetime.datetime(1997, 6, 10, 0, 0), 'window_end': datetime.datetime(1997, 6, 11, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 977.5, 'window_start': datetime.datetime(1997, 6, 16, 0, 0), 'window_end': datetime.datetime(1997, 6, 17, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 764.3, 'window_start': datetime.datetime(1997, 6, 19, 0, 0), 'window_end': datetime.datetime(1997, 6, 20, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 569.0, 'window_start': datetime.datetime(1997, 6, 23, 0, 0), 'window_end': datetime.datetime(1997, 6, 24, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 317.75, 'window_start': datetime.datetime(1997, 6, 25, 0, 0), 'window_end': datetime.datetime(1997, 6, 26, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 72.0, 'window_start': datetime.datetime(1997, 7, 4, 0, 0), 'window_end': datetime.datetime(1997, 7, 5, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 565.5, 'window_start': datetime.datetime(1997, 7, 9, 0, 0), 'window_end': datetime.datetime(1997, 7, 10, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 1476.1, 'window_start': datetime.datetime(1997, 7, 11, 0, 0), 'window_end': datetime.datetime(1997, 7, 12, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 2388.5, 'window_start': datetime.datetime(1997, 7, 14, 0, 0), 'window_end': datetime.datetime(1997, 7, 15, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 479.8, 'window_start': datetime.datetime(1997, 7, 16, 0, 0), 'window_end': datetime.datetime(1997, 7, 17, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 1508.0, 'window_start': datetime.datetime(1997, 7, 18, 0, 0), 'window_end': datetime.datetime(1997, 7, 19, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 6475.400000000001, 'window_start': datetime.datetime(1997, 7, 22, 0, 0), 'window_end': datetime.datetime(1997, 7, 23, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 6375.0, 'window_start': datetime.datetime(1997, 7, 28, 0, 0), 'window_end': datetime.datetime(1997, 7, 29, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 6682.0, 'window_start': datetime.datetime(1997, 7, 31, 0, 0), 'window_end': datetime.datetime(1997, 8, 1, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 1393.24, 'window_start': datetime.datetime(1997, 8, 7, 0, 0), 'window_end': datetime.datetime(1997, 8, 8, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 1264.5, 'window_start': datetime.datetime(1997, 8, 11, 0, 0), 'window_end': datetime.datetime(1997, 8, 12, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 5042.95, 'window_start': datetime.datetime(1997, 9, 4, 0, 0), 'window_end': datetime.datetime(1997, 9, 5, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 1701.0, 'window_start': datetime.datetime(1997, 9, 8, 0, 0), 'window_end': datetime.datetime(1997, 9, 9, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 125.0, 'window_start': datetime.datetime(1997, 9, 9, 0, 0), 'window_end': datetime.datetime(1997, 9, 10, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 1295.0, 'window_start': datetime.datetime(1997, 9, 11, 0, 0), 'window_end': datetime.datetime(1997, 9, 12, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 5256.5, 'window_start': datetime.datetime(1997, 9, 23, 0, 0), 'window_end': datetime.datetime(1997, 9, 24, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 1682.5, 'window_start': datetime.datetime(1997, 9, 24, 0, 0), 'window_end': datetime.datetime(1997, 9, 25, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 1327.0, 'window_start': datetime.datetime(1997, 9, 25, 0, 0), 'window_end': datetime.datetime(1997, 9, 26, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 2334.0, 'window_start': datetime.datetime(1997, 10, 6, 0, 0), 'window_end': datetime.datetime(1997, 10, 7, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 996.0, 'window_start': datetime.datetime(1997, 10, 8, 0, 0), 'window_end': datetime.datetime(1997, 10, 9, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 2048.0, 'window_start': datetime.datetime(1997, 10, 10, 0, 0), 'window_end': datetime.datetime(1997, 10, 11, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 1893.0, 'window_start': datetime.datetime(1997, 10, 16, 0, 0), 'window_end': datetime.datetime(1997, 10, 17, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 180.4, 'window_start': datetime.datetime(1997, 10, 17, 0, 0), 'window_end': datetime.datetime(1997, 10, 18, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 4451.7, 'window_start': datetime.datetime(1997, 10, 21, 0, 0), 'window_end': datetime.datetime(1997, 10, 22, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 5768.9, 'window_start': datetime.datetime(1997, 10, 22, 0, 0), 'window_end': datetime.datetime(1997, 10, 23, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 1125.67, 'window_start': datetime.datetime(1997, 10, 27, 0, 0), 'window_end': datetime.datetime(1997, 10, 28, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 1570.0, 'window_start': datetime.datetime(1997, 10, 29, 0, 0), 'window_end': datetime.datetime(1997, 10, 30, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 468.45, 'window_start': datetime.datetime(1997, 10, 30, 0, 0), 'window_end': datetime.datetime(1997, 10, 31, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 596.0, 'window_start': datetime.datetime(1997, 11, 10, 0, 0), 'window_end': datetime.datetime(1997, 11, 11, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 1770.0, 'window_start': datetime.datetime(1997, 11, 13, 0, 0), 'window_end': datetime.datetime(1997, 11, 14, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 2196.0, 'window_start': datetime.datetime(1997, 11, 20, 0, 0), 'window_end': datetime.datetime(1997, 11, 21, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 5569.5, 'window_start': datetime.datetime(1997, 11, 27, 0, 0), 'window_end': datetime.datetime(1997, 11, 28, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 629.5, 'window_start': datetime.datetime(1997, 12, 2, 0, 0), 'window_end': datetime.datetime(1997, 12, 3, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 228.0, 'window_start': datetime.datetime(1997, 12, 12, 0, 0), 'window_end': datetime.datetime(1997, 12, 13, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 2775.0, 'window_start': datetime.datetime(1997, 12, 30, 0, 0), 'window_end': datetime.datetime(1997, 12, 31, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 1660.0, 'window_start': datetime.datetime(1998, 1, 1, 0, 0), 'window_end': datetime.datetime(1998, 1, 2, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 40.0, 'window_start': datetime.datetime(1998, 1, 5, 0, 0), 'window_end': datetime.datetime(1998, 1, 6, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 8891.0, 'window_start': datetime.datetime(1998, 1, 6, 0, 0), 'window_end': datetime.datetime(1998, 1, 7, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 1140.0, 'window_start': datetime.datetime(1998, 1, 7, 0, 0), 'window_end': datetime.datetime(1998, 1, 8, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 915.9, 'window_start': datetime.datetime(1998, 1, 8, 0, 0), 'window_end': datetime.datetime(1998, 1, 9, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 6164.9, 'window_start': datetime.datetime(1998, 1, 22, 0, 0), 'window_end': datetime.datetime(1998, 1, 23, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 2984.0, 'window_start': datetime.datetime(1998, 1, 26, 0, 0), 'window_end': datetime.datetime(1998, 1, 27, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 2275.25, 'window_start': datetime.datetime(1998, 1, 27, 0, 0), 'window_end': datetime.datetime(1998, 1, 28, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 3523.4, 'window_start': datetime.datetime(1998, 1, 30, 0, 0), 'window_end': datetime.datetime(1998, 1, 31, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 98.39999999999999, 'window_start': datetime.datetime(1998, 2, 3, 0, 0), 'window_end': datetime.datetime(1998, 2, 4, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 988.4, 'window_start': datetime.datetime(1998, 2, 11, 0, 0), 'window_end': datetime.datetime(1998, 2, 12, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 1486.6, 'window_start': datetime.datetime(1998, 2, 12, 0, 0), 'window_end': datetime.datetime(1998, 2, 13, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 11380.0, 'window_start': datetime.datetime(1998, 2, 16, 0, 0), 'window_end': datetime.datetime(1998, 2, 17, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 2898.0, 'window_start': datetime.datetime(1998, 2, 18, 0, 0), 'window_end': datetime.datetime(1998, 2, 19, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 1924.25, 'window_start': datetime.datetime(1998, 2, 24, 0, 0), 'window_end': datetime.datetime(1998, 2, 25, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 570.0, 'window_start': datetime.datetime(1998, 3, 9, 0, 0), 'window_end': datetime.datetime(1998, 3, 10, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 4769.0, 'window_start': datetime.datetime(1998, 3, 11, 0, 0), 'window_end': datetime.datetime(1998, 3, 12, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 848.0, 'window_start': datetime.datetime(1998, 3, 20, 0, 0), 'window_end': datetime.datetime(1998, 3, 21, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 439.0, 'window_start': datetime.datetime(1998, 3, 25, 0, 0), 'window_end': datetime.datetime(1998, 3, 26, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 796.5, 'window_start': datetime.datetime(1998, 3, 27, 0, 0), 'window_end': datetime.datetime(1998, 3, 28, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 1809.75, 'window_start': datetime.datetime(1998, 3, 30, 0, 0), 'window_end': datetime.datetime(1998, 3, 31, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 3772.0, 'window_start': datetime.datetime(1998, 3, 31, 0, 0), 'window_end': datetime.datetime(1998, 4, 1, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 69.6, 'window_start': datetime.datetime(1998, 4, 1, 0, 0), 'window_end': datetime.datetime(1998, 4, 2, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 3303.0, 'window_start': datetime.datetime(1998, 4, 6, 0, 0), 'window_end': datetime.datetime(1998, 4, 7, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 391.58000000000004, 'window_start': datetime.datetime(1998, 4, 7, 0, 0), 'window_end': datetime.datetime(1998, 4, 8, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 1575.0, 'window_start': datetime.datetime(1998, 4, 13, 0, 0), 'window_end': datetime.datetime(1998, 4, 14, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 27617.9, 'window_start': datetime.datetime(1998, 4, 17, 0, 0), 'window_end': datetime.datetime(1998, 4, 18, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 554.4, 'window_start': datetime.datetime(1998, 4, 20, 0, 0), 'window_end': datetime.datetime(1998, 4, 21, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 200.0, 'window_start': datetime.datetime(1998, 4, 22, 0, 0), 'window_end': datetime.datetime(1998, 4, 23, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 510.0, 'window_start': datetime.datetime(1998, 4, 30, 0, 0), 'window_end': datetime.datetime(1998, 5, 1, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 5651.05, 'window_start': datetime.datetime(1998, 5, 1, 0, 0), 'window_end': datetime.datetime(1998, 5, 2, 0, 0)}\n",
      "{'country': 'USA', 'totalamount': 1374.6, 'window_start': datetime.datetime(1998, 5, 6, 0, 0), 'window_end': datetime.datetime(1998, 5, 7, 0, 0)}\n",
      "{'country': 'Sweden', 'totalamount': 724.5, 'window_start': datetime.datetime(1996, 7, 24, 0, 0), 'window_end': datetime.datetime(1996, 7, 25, 0, 0)}\n",
      "{'country': 'Sweden', 'totalamount': 1488.8, 'window_start': datetime.datetime(1996, 8, 12, 0, 0), 'window_end': datetime.datetime(1996, 8, 13, 0, 0)}\n",
      "{'country': 'Sweden', 'totalamount': 613.2, 'window_start': datetime.datetime(1996, 8, 14, 0, 0), 'window_end': datetime.datetime(1996, 8, 15, 0, 0)}\n",
      "{'country': 'Sweden', 'totalamount': 2262.5, 'window_start': datetime.datetime(1996, 10, 11, 0, 0), 'window_end': datetime.datetime(1996, 10, 12, 0, 0)}\n",
      "{'country': 'Sweden', 'totalamount': 103.19999999999999, 'window_start': datetime.datetime(1996, 12, 10, 0, 0), 'window_end': datetime.datetime(1996, 12, 11, 0, 0)}\n",
      "{'country': 'Sweden', 'totalamount': 2222.3999999999996, 'window_start': datetime.datetime(1996, 12, 16, 0, 0), 'window_end': datetime.datetime(1996, 12, 17, 0, 0)}\n",
      "{'country': 'Sweden', 'totalamount': 360.0, 'window_start': datetime.datetime(1997, 2, 3, 0, 0), 'window_end': datetime.datetime(1997, 2, 4, 0, 0)}\n",
      "{'country': 'Sweden', 'totalamount': 1031.7, 'window_start': datetime.datetime(1997, 2, 12, 0, 0), 'window_end': datetime.datetime(1997, 2, 13, 0, 0)}\n",
      "{'country': 'Sweden', 'totalamount': 174.9, 'window_start': datetime.datetime(1997, 2, 13, 0, 0), 'window_end': datetime.datetime(1997, 2, 14, 0, 0)}\n",
      "{'country': 'Sweden', 'totalamount': 234.8, 'window_start': datetime.datetime(1997, 2, 28, 0, 0), 'window_end': datetime.datetime(1997, 3, 1, 0, 0)}\n",
      "{'country': 'Sweden', 'totalamount': 3192.65, 'window_start': datetime.datetime(1997, 5, 1, 0, 0), 'window_end': datetime.datetime(1997, 5, 2, 0, 0)}\n",
      "{'country': 'Sweden', 'totalamount': 2295.2, 'window_start': datetime.datetime(1997, 5, 12, 0, 0), 'window_end': datetime.datetime(1997, 5, 13, 0, 0)}\n",
      "{'country': 'Sweden', 'totalamount': 2844.5, 'window_start': datetime.datetime(1997, 6, 6, 0, 0), 'window_end': datetime.datetime(1997, 6, 7, 0, 0)}\n",
      "{'country': 'Sweden', 'totalamount': 1565.6499999999999, 'window_start': datetime.datetime(1997, 6, 18, 0, 0), 'window_end': datetime.datetime(1997, 6, 19, 0, 0)}\n",
      "{'country': 'Sweden', 'totalamount': 1503.6, 'window_start': datetime.datetime(1997, 8, 11, 0, 0), 'window_end': datetime.datetime(1997, 8, 12, 0, 0)}\n",
      "{'country': 'Sweden', 'totalamount': 668.7, 'window_start': datetime.datetime(1997, 9, 2, 0, 0), 'window_end': datetime.datetime(1997, 9, 3, 0, 0)}\n",
      "{'country': 'Sweden', 'totalamount': 4210.5, 'window_start': datetime.datetime(1997, 9, 17, 0, 0), 'window_end': datetime.datetime(1997, 9, 18, 0, 0)}\n",
      "{'country': 'Sweden', 'totalamount': 630.0, 'window_start': datetime.datetime(1997, 10, 1, 0, 0), 'window_end': datetime.datetime(1997, 10, 2, 0, 0)}\n",
      "{'country': 'Sweden', 'totalamount': 2545.0, 'window_start': datetime.datetime(1997, 10, 14, 0, 0), 'window_end': datetime.datetime(1997, 10, 15, 0, 0)}\n",
      "{'country': 'Sweden', 'totalamount': 1459.0, 'window_start': datetime.datetime(1997, 11, 7, 0, 0), 'window_end': datetime.datetime(1997, 11, 8, 0, 0)}\n",
      "{'country': 'Sweden', 'totalamount': 4337.0, 'window_start': datetime.datetime(1997, 12, 2, 0, 0), 'window_end': datetime.datetime(1997, 12, 3, 0, 0)}\n",
      "{'country': 'Sweden', 'totalamount': 875.0, 'window_start': datetime.datetime(1997, 12, 11, 0, 0), 'window_end': datetime.datetime(1997, 12, 12, 0, 0)}\n",
      "{'country': 'Sweden', 'totalamount': 96.5, 'window_start': datetime.datetime(1997, 12, 16, 0, 0), 'window_end': datetime.datetime(1997, 12, 17, 0, 0)}\n",
      "{'country': 'Sweden', 'totalamount': 250.8, 'window_start': datetime.datetime(1998, 1, 9, 0, 0), 'window_end': datetime.datetime(1998, 1, 10, 0, 0)}\n",
      "{'country': 'Sweden', 'totalamount': 1254.0, 'window_start': datetime.datetime(1998, 1, 16, 0, 0), 'window_end': datetime.datetime(1998, 1, 17, 0, 0)}\n",
      "{'country': 'Sweden', 'totalamount': 2630.95, 'window_start': datetime.datetime(1998, 1, 28, 0, 0), 'window_end': datetime.datetime(1998, 1, 29, 0, 0)}\n",
      "{'country': 'Sweden', 'totalamount': 1461.6, 'window_start': datetime.datetime(1998, 2, 3, 0, 0), 'window_end': datetime.datetime(1998, 2, 4, 0, 0)}\n",
      "{'country': 'Sweden', 'totalamount': 729.5, 'window_start': datetime.datetime(1998, 2, 6, 0, 0), 'window_end': datetime.datetime(1998, 2, 7, 0, 0)}\n",
      "{'country': 'Sweden', 'totalamount': 1875.0, 'window_start': datetime.datetime(1998, 2, 10, 0, 0), 'window_end': datetime.datetime(1998, 2, 11, 0, 0)}\n",
      "{'country': 'Sweden', 'totalamount': 1015.8, 'window_start': datetime.datetime(1998, 2, 23, 0, 0), 'window_end': datetime.datetime(1998, 2, 24, 0, 0)}\n",
      "{'country': 'Sweden', 'totalamount': 2034.5, 'window_start': datetime.datetime(1998, 3, 4, 0, 0), 'window_end': datetime.datetime(1998, 3, 5, 0, 0)}\n",
      "{'country': 'Sweden', 'totalamount': 93.0, 'window_start': datetime.datetime(1998, 3, 17, 0, 0), 'window_end': datetime.datetime(1998, 3, 18, 0, 0)}\n",
      "{'country': 'Sweden', 'totalamount': 2233.0, 'window_start': datetime.datetime(1998, 3, 26, 0, 0), 'window_end': datetime.datetime(1998, 3, 27, 0, 0)}\n",
      "{'country': 'Sweden', 'totalamount': 310.0, 'window_start': datetime.datetime(1998, 3, 27, 0, 0), 'window_end': datetime.datetime(1998, 3, 28, 0, 0)}\n",
      "{'country': 'Sweden', 'totalamount': 6527.25, 'window_start': datetime.datetime(1998, 4, 1, 0, 0), 'window_end': datetime.datetime(1998, 4, 2, 0, 0)}\n",
      "{'country': 'Sweden', 'totalamount': 2769.0, 'window_start': datetime.datetime(1998, 4, 6, 0, 0), 'window_end': datetime.datetime(1998, 4, 7, 0, 0)}\n",
      "{'country': 'Sweden', 'totalamount': 900.0, 'window_start': datetime.datetime(1998, 4, 27, 0, 0), 'window_end': datetime.datetime(1998, 4, 28, 0, 0)}\n",
      "{'country': 'Finland', 'totalamount': 364.79999999999995, 'window_start': datetime.datetime(1996, 7, 26, 0, 0), 'window_end': datetime.datetime(1996, 7, 27, 0, 0)}\n",
      "{'country': 'Finland', 'totalamount': 1376.0, 'window_start': datetime.datetime(1996, 8, 1, 0, 0), 'window_end': datetime.datetime(1996, 8, 2, 0, 0)}\n",
      "{'country': 'Finland', 'totalamount': 516.0, 'window_start': datetime.datetime(1996, 10, 3, 0, 0), 'window_end': datetime.datetime(1996, 10, 4, 0, 0)}\n",
      "{'country': 'Finland', 'totalamount': 954.0, 'window_start': datetime.datetime(1996, 10, 18, 0, 0), 'window_end': datetime.datetime(1996, 10, 19, 0, 0)}\n",
      "{'country': 'Finland', 'totalamount': 372.0, 'window_start': datetime.datetime(1997, 1, 13, 0, 0), 'window_end': datetime.datetime(1997, 1, 14, 0, 0)}\n",
      "{'country': 'Finland', 'totalamount': 720.0, 'window_start': datetime.datetime(1997, 1, 16, 0, 0), 'window_end': datetime.datetime(1997, 1, 17, 0, 0)}\n",
      "{'country': 'Finland', 'totalamount': 393.0, 'window_start': datetime.datetime(1997, 2, 5, 0, 0), 'window_end': datetime.datetime(1997, 2, 6, 0, 0)}\n",
      "{'country': 'Finland', 'totalamount': 2684.0, 'window_start': datetime.datetime(1997, 2, 24, 0, 0), 'window_end': datetime.datetime(1997, 2, 25, 0, 0)}\n",
      "{'country': 'Finland', 'totalamount': 1344.0, 'window_start': datetime.datetime(1997, 5, 5, 0, 0), 'window_end': datetime.datetime(1997, 5, 6, 0, 0)}\n",
      "{'country': 'Finland', 'totalamount': 1546.3, 'window_start': datetime.datetime(1997, 5, 30, 0, 0), 'window_end': datetime.datetime(1997, 5, 31, 0, 0)}\n",
      "{'country': 'Finland', 'totalamount': 2413.9, 'window_start': datetime.datetime(1997, 6, 30, 0, 0), 'window_end': datetime.datetime(1997, 7, 1, 0, 0)}\n",
      "{'country': 'Finland', 'totalamount': 120.0, 'window_start': datetime.datetime(1997, 7, 30, 0, 0), 'window_end': datetime.datetime(1997, 7, 31, 0, 0)}\n",
      "{'country': 'Finland', 'totalamount': 629.5, 'window_start': datetime.datetime(1997, 8, 19, 0, 0), 'window_end': datetime.datetime(1997, 8, 20, 0, 0)}\n",
      "{'country': 'Finland', 'totalamount': 412.35, 'window_start': datetime.datetime(1997, 9, 18, 0, 0), 'window_end': datetime.datetime(1997, 9, 19, 0, 0)}\n",
      "{'country': 'Finland', 'totalamount': 642.0, 'window_start': datetime.datetime(1997, 10, 7, 0, 0), 'window_end': datetime.datetime(1997, 10, 8, 0, 0)}\n",
      "{'country': 'Finland', 'totalamount': 1871.25, 'window_start': datetime.datetime(1997, 11, 21, 0, 0), 'window_end': datetime.datetime(1997, 11, 22, 0, 0)}\n",
      "{'country': 'Finland', 'totalamount': 1132.35, 'window_start': datetime.datetime(1997, 12, 17, 0, 0), 'window_end': datetime.datetime(1997, 12, 18, 0, 0)}\n",
      "{'country': 'Finland', 'totalamount': 336.8, 'window_start': datetime.datetime(1998, 2, 6, 0, 0), 'window_end': datetime.datetime(1998, 2, 7, 0, 0)}\n",
      "{'country': 'Finland', 'totalamount': 611.3, 'window_start': datetime.datetime(1998, 2, 10, 0, 0), 'window_end': datetime.datetime(1998, 2, 11, 0, 0)}\n",
      "{'country': 'Finland', 'totalamount': 452.9, 'window_start': datetime.datetime(1998, 2, 26, 0, 0), 'window_end': datetime.datetime(1998, 2, 27, 0, 0)}\n",
      "{'country': 'Finland', 'totalamount': 586.0, 'window_start': datetime.datetime(1998, 4, 7, 0, 0), 'window_end': datetime.datetime(1998, 4, 8, 0, 0)}\n",
      "{'country': 'Finland', 'totalamount': 300.0, 'window_start': datetime.datetime(1998, 4, 15, 0, 0), 'window_end': datetime.datetime(1998, 4, 16, 0, 0)}\n",
      "{'country': 'Italy', 'totalamount': 307.2, 'window_start': datetime.datetime(1996, 8, 7, 0, 0), 'window_end': datetime.datetime(1996, 8, 8, 0, 0)}\n",
      "{'country': 'Italy', 'totalamount': 89.0, 'window_start': datetime.datetime(1996, 8, 23, 0, 0), 'window_end': datetime.datetime(1996, 8, 24, 0, 0)}\n",
      "{'country': 'Italy', 'totalamount': 608.0, 'window_start': datetime.datetime(1996, 9, 9, 0, 0), 'window_end': datetime.datetime(1996, 9, 10, 0, 0)}\n",
      "{'country': 'Italy', 'totalamount': 1675.0, 'window_start': datetime.datetime(1997, 1, 3, 0, 0), 'window_end': datetime.datetime(1997, 1, 4, 0, 0)}\n",
      "{'country': 'Italy', 'totalamount': 49.8, 'window_start': datetime.datetime(1997, 1, 22, 0, 0), 'window_end': datetime.datetime(1997, 1, 23, 0, 0)}\n",
      "{'country': 'Italy', 'totalamount': 192.0, 'window_start': datetime.datetime(1997, 1, 28, 0, 0), 'window_end': datetime.datetime(1997, 1, 29, 0, 0)}\n",
      "{'country': 'Italy', 'totalamount': 537.5999999999999, 'window_start': datetime.datetime(1997, 2, 12, 0, 0), 'window_end': datetime.datetime(1997, 2, 13, 0, 0)}\n",
      "{'country': 'Italy', 'totalamount': 235.2, 'window_start': datetime.datetime(1997, 3, 6, 0, 0), 'window_end': datetime.datetime(1997, 3, 7, 0, 0)}\n",
      "{'country': 'Italy', 'totalamount': 543.0, 'window_start': datetime.datetime(1997, 6, 9, 0, 0), 'window_end': datetime.datetime(1997, 6, 10, 0, 0)}\n",
      "{'country': 'Italy', 'totalamount': 28.0, 'window_start': datetime.datetime(1997, 7, 2, 0, 0), 'window_end': datetime.datetime(1997, 7, 3, 0, 0)}\n",
      "{'country': 'Italy', 'totalamount': 1380.25, 'window_start': datetime.datetime(1997, 8, 18, 0, 0), 'window_end': datetime.datetime(1997, 8, 19, 0, 0)}\n",
      "{'country': 'Italy', 'totalamount': 193.0, 'window_start': datetime.datetime(1997, 9, 3, 0, 0), 'window_end': datetime.datetime(1997, 9, 4, 0, 0)}\n",
      "{'country': 'Italy', 'totalamount': 93.5, 'window_start': datetime.datetime(1997, 10, 20, 0, 0), 'window_end': datetime.datetime(1997, 10, 21, 0, 0)}\n",
      "{'country': 'Italy', 'totalamount': 1710.0, 'window_start': datetime.datetime(1997, 11, 3, 0, 0), 'window_end': datetime.datetime(1997, 11, 4, 0, 0)}\n",
      "{'country': 'Italy', 'totalamount': 143.2, 'window_start': datetime.datetime(1997, 11, 25, 0, 0), 'window_end': datetime.datetime(1997, 11, 26, 0, 0)}\n",
      "{'country': 'Italy', 'totalamount': 1650.0, 'window_start': datetime.datetime(1997, 12, 18, 0, 0), 'window_end': datetime.datetime(1997, 12, 19, 0, 0)}\n",
      "{'country': 'Italy', 'totalamount': 18.4, 'window_start': datetime.datetime(1997, 12, 31, 0, 0), 'window_end': datetime.datetime(1998, 1, 1, 0, 0)}\n",
      "{'country': 'Italy', 'totalamount': 1852.0, 'window_start': datetime.datetime(1998, 1, 2, 0, 0), 'window_end': datetime.datetime(1998, 1, 3, 0, 0)}\n",
      "{'country': 'Italy', 'totalamount': 833.0, 'window_start': datetime.datetime(1998, 1, 7, 0, 0), 'window_end': datetime.datetime(1998, 1, 8, 0, 0)}\n",
      "{'country': 'Italy', 'totalamount': 698.0, 'window_start': datetime.datetime(1998, 2, 26, 0, 0), 'window_end': datetime.datetime(1998, 2, 27, 0, 0)}\n",
      "{'country': 'Italy', 'totalamount': 750.0, 'window_start': datetime.datetime(1998, 3, 10, 0, 0), 'window_end': datetime.datetime(1998, 3, 11, 0, 0)}\n",
      "{'country': 'Italy', 'totalamount': 560.0, 'window_start': datetime.datetime(1998, 3, 11, 0, 0), 'window_end': datetime.datetime(1998, 3, 12, 0, 0)}\n",
      "{'country': 'Italy', 'totalamount': 110.0, 'window_start': datetime.datetime(1998, 3, 16, 0, 0), 'window_end': datetime.datetime(1998, 3, 17, 0, 0)}\n",
      "{'country': 'Italy', 'totalamount': 645.0, 'window_start': datetime.datetime(1998, 4, 9, 0, 0), 'window_end': datetime.datetime(1998, 4, 10, 0, 0)}\n",
      "{'country': 'Italy', 'totalamount': 1030.0, 'window_start': datetime.datetime(1998, 4, 15, 0, 0), 'window_end': datetime.datetime(1998, 4, 16, 0, 0)}\n",
      "{'country': 'Italy', 'totalamount': 774.0, 'window_start': datetime.datetime(1998, 4, 30, 0, 0), 'window_end': datetime.datetime(1998, 5, 1, 0, 0)}\n",
      "{'country': 'Spain', 'totalamount': 86.5, 'window_start': datetime.datetime(1996, 8, 14, 0, 0), 'window_end': datetime.datetime(1996, 8, 15, 0, 0)}\n",
      "{'country': 'Spain', 'totalamount': 155.39999999999998, 'window_start': datetime.datetime(1996, 8, 15, 0, 0), 'window_end': datetime.datetime(1996, 8, 16, 0, 0)}\n",
      "{'country': 'Spain', 'totalamount': 1242.0, 'window_start': datetime.datetime(1996, 9, 11, 0, 0), 'window_end': datetime.datetime(1996, 9, 12, 0, 0)}\n",
      "{'country': 'Spain', 'totalamount': 498.5, 'window_start': datetime.datetime(1996, 9, 16, 0, 0), 'window_end': datetime.datetime(1996, 9, 17, 0, 0)}\n",
      "{'country': 'Spain', 'totalamount': 982.0, 'window_start': datetime.datetime(1996, 10, 10, 0, 0), 'window_end': datetime.datetime(1996, 10, 11, 0, 0)}\n",
      "{'country': 'Spain', 'totalamount': 136.0, 'window_start': datetime.datetime(1996, 11, 28, 0, 0), 'window_end': datetime.datetime(1996, 11, 29, 0, 0)}\n",
      "{'country': 'Spain', 'totalamount': 338.20000000000005, 'window_start': datetime.datetime(1997, 1, 27, 0, 0), 'window_end': datetime.datetime(1997, 1, 28, 0, 0)}\n",
      "{'country': 'Spain', 'totalamount': 749.0, 'window_start': datetime.datetime(1997, 5, 28, 0, 0), 'window_end': datetime.datetime(1997, 5, 29, 0, 0)}\n",
      "{'country': 'Spain', 'totalamount': 155.0, 'window_start': datetime.datetime(1997, 6, 13, 0, 0), 'window_end': datetime.datetime(1997, 6, 14, 0, 0)}\n",
      "{'country': 'Spain', 'totalamount': 2775.05, 'window_start': datetime.datetime(1997, 8, 12, 0, 0), 'window_end': datetime.datetime(1997, 8, 13, 0, 0)}\n",
      "{'country': 'Spain', 'totalamount': 4035.8, 'window_start': datetime.datetime(1997, 12, 29, 0, 0), 'window_end': datetime.datetime(1997, 12, 30, 0, 0)}\n",
      "{'country': 'Spain', 'totalamount': 2166.8, 'window_start': datetime.datetime(1998, 2, 5, 0, 0), 'window_end': datetime.datetime(1998, 2, 6, 0, 0)}\n",
      "{'country': 'Spain', 'totalamount': 310.0, 'window_start': datetime.datetime(1998, 2, 6, 0, 0), 'window_end': datetime.datetime(1998, 2, 7, 0, 0)}\n",
      "{'country': 'Spain', 'totalamount': 70.0, 'window_start': datetime.datetime(1998, 2, 13, 0, 0), 'window_end': datetime.datetime(1998, 2, 14, 0, 0)}\n",
      "{'country': 'Spain', 'totalamount': 605.0, 'window_start': datetime.datetime(1998, 2, 16, 0, 0), 'window_end': datetime.datetime(1998, 2, 17, 0, 0)}\n",
      "{'country': 'Spain', 'totalamount': 858.0, 'window_start': datetime.datetime(1998, 2, 26, 0, 0), 'window_end': datetime.datetime(1998, 2, 27, 0, 0)}\n",
      "{'country': 'Spain', 'totalamount': 365.89, 'window_start': datetime.datetime(1998, 3, 2, 0, 0), 'window_end': datetime.datetime(1998, 3, 3, 0, 0)}\n",
      "{'country': 'Spain', 'totalamount': 137.5, 'window_start': datetime.datetime(1998, 3, 5, 0, 0), 'window_end': datetime.datetime(1998, 3, 6, 0, 0)}\n",
      "{'country': 'Spain', 'totalamount': 2362.25, 'window_start': datetime.datetime(1998, 3, 13, 0, 0), 'window_end': datetime.datetime(1998, 3, 14, 0, 0)}\n",
      "{'country': 'Spain', 'totalamount': 280.0, 'window_start': datetime.datetime(1998, 3, 24, 0, 0), 'window_end': datetime.datetime(1998, 3, 25, 0, 0)}\n",
      "{'country': 'Spain', 'totalamount': 702.0, 'window_start': datetime.datetime(1998, 4, 8, 0, 0), 'window_end': datetime.datetime(1998, 4, 9, 0, 0)}\n",
      "{'country': 'Spain', 'totalamount': 361.0, 'window_start': datetime.datetime(1998, 4, 9, 0, 0), 'window_end': datetime.datetime(1998, 4, 10, 0, 0)}\n",
      "{'country': 'Spain', 'totalamount': 60.0, 'window_start': datetime.datetime(1998, 4, 21, 0, 0), 'window_end': datetime.datetime(1998, 4, 22, 0, 0)}\n",
      "{'country': 'UK', 'totalamount': 479.4, 'window_start': datetime.datetime(1996, 8, 26, 0, 0), 'window_end': datetime.datetime(1996, 8, 27, 0, 0)}\n",
      "{'country': 'UK', 'totalamount': 516.8, 'window_start': datetime.datetime(1996, 9, 26, 0, 0), 'window_end': datetime.datetime(1996, 9, 27, 0, 0)}\n",
      "{'country': 'UK', 'totalamount': 240.4, 'window_start': datetime.datetime(1996, 10, 1, 0, 0), 'window_end': datetime.datetime(1996, 10, 2, 0, 0)}\n",
      "{'country': 'UK', 'totalamount': 144.0, 'window_start': datetime.datetime(1996, 10, 3, 0, 0), 'window_end': datetime.datetime(1996, 10, 4, 0, 0)}\n",
      "{'country': 'UK', 'totalamount': 480.0, 'window_start': datetime.datetime(1996, 11, 15, 0, 0), 'window_end': datetime.datetime(1996, 11, 16, 0, 0)}\n",
      "{'country': 'UK', 'totalamount': 3654.4, 'window_start': datetime.datetime(1996, 11, 21, 0, 0), 'window_end': datetime.datetime(1996, 11, 22, 0, 0)}\n",
      "{'country': 'UK', 'totalamount': 950.0, 'window_start': datetime.datetime(1996, 11, 26, 0, 0), 'window_end': datetime.datetime(1996, 11, 27, 0, 0)}\n",
      "{'country': 'UK', 'totalamount': 1016.0, 'window_start': datetime.datetime(1996, 12, 9, 0, 0), 'window_end': datetime.datetime(1996, 12, 10, 0, 0)}\n",
      "{'country': 'UK', 'totalamount': 899.0, 'window_start': datetime.datetime(1996, 12, 16, 0, 0), 'window_end': datetime.datetime(1996, 12, 17, 0, 0)}\n",
      "{'country': 'UK', 'totalamount': 1274.0, 'window_start': datetime.datetime(1996, 12, 19, 0, 0), 'window_end': datetime.datetime(1996, 12, 20, 0, 0)}\n",
      "{'country': 'UK', 'totalamount': 3063.0, 'window_start': datetime.datetime(1997, 1, 1, 0, 0), 'window_end': datetime.datetime(1997, 1, 2, 0, 0)}\n",
      "{'country': 'UK', 'totalamount': 631.6, 'window_start': datetime.datetime(1997, 2, 4, 0, 0), 'window_end': datetime.datetime(1997, 2, 5, 0, 0)}\n",
      "{'country': 'UK', 'totalamount': 453.0, 'window_start': datetime.datetime(1997, 2, 21, 0, 0), 'window_end': datetime.datetime(1997, 2, 22, 0, 0)}\n",
      "{'country': 'UK', 'totalamount': 156.00000000000003, 'window_start': datetime.datetime(1997, 3, 3, 0, 0), 'window_end': datetime.datetime(1997, 3, 4, 0, 0)}\n",
      "{'country': 'UK', 'totalamount': 1328.0, 'window_start': datetime.datetime(1997, 3, 11, 0, 0), 'window_end': datetime.datetime(1997, 3, 12, 0, 0)}\n",
      "{'country': 'UK', 'totalamount': 1051.1999999999998, 'window_start': datetime.datetime(1997, 3, 12, 0, 0), 'window_end': datetime.datetime(1997, 3, 13, 0, 0)}\n",
      "{'country': 'UK', 'totalamount': 230.39999999999998, 'window_start': datetime.datetime(1997, 3, 13, 0, 0), 'window_end': datetime.datetime(1997, 3, 14, 0, 0)}\n",
      "{'country': 'UK', 'totalamount': 386.2, 'window_start': datetime.datetime(1997, 3, 24, 0, 0), 'window_end': datetime.datetime(1997, 3, 25, 0, 0)}\n",
      "{'country': 'UK', 'totalamount': 352.0, 'window_start': datetime.datetime(1997, 4, 24, 0, 0), 'window_end': datetime.datetime(1997, 4, 25, 0, 0)}\n",
      "{'country': 'UK', 'totalamount': 2715.9, 'window_start': datetime.datetime(1997, 5, 1, 0, 0), 'window_end': datetime.datetime(1997, 5, 2, 0, 0)}\n",
      "{'country': 'UK', 'totalamount': 796.35, 'window_start': datetime.datetime(1997, 5, 9, 0, 0), 'window_end': datetime.datetime(1997, 5, 10, 0, 0)}\n",
      "{'country': 'UK', 'totalamount': 139.8, 'window_start': datetime.datetime(1997, 5, 15, 0, 0), 'window_end': datetime.datetime(1997, 5, 16, 0, 0)}\n",
      "{'country': 'UK', 'totalamount': 355.5, 'window_start': datetime.datetime(1997, 5, 16, 0, 0), 'window_end': datetime.datetime(1997, 5, 17, 0, 0)}\n",
      "{'country': 'UK', 'totalamount': 1908.0, 'window_start': datetime.datetime(1997, 5, 23, 0, 0), 'window_end': datetime.datetime(1997, 5, 24, 0, 0)}\n",
      "{'country': 'UK', 'totalamount': 2142.9, 'window_start': datetime.datetime(1997, 6, 4, 0, 0), 'window_end': datetime.datetime(1997, 6, 5, 0, 0)}\n",
      "{'country': 'UK', 'totalamount': 477.0, 'window_start': datetime.datetime(1997, 6, 24, 0, 0), 'window_end': datetime.datetime(1997, 6, 25, 0, 0)}\n",
      "{'country': 'UK', 'totalamount': 493.0, 'window_start': datetime.datetime(1997, 7, 15, 0, 0), 'window_end': datetime.datetime(1997, 7, 16, 0, 0)}\n",
      "{'country': 'UK', 'totalamount': 758.5, 'window_start': datetime.datetime(1997, 8, 5, 0, 0), 'window_end': datetime.datetime(1997, 8, 6, 0, 0)}\n",
      "{'country': 'UK', 'totalamount': 45.0, 'window_start': datetime.datetime(1997, 9, 18, 0, 0), 'window_end': datetime.datetime(1997, 9, 19, 0, 0)}\n",
      "{'country': 'UK', 'totalamount': 1704.0, 'window_start': datetime.datetime(1997, 10, 16, 0, 0), 'window_end': datetime.datetime(1997, 10, 17, 0, 0)}\n",
      "{'country': 'UK', 'totalamount': 655.0, 'window_start': datetime.datetime(1997, 11, 3, 0, 0), 'window_end': datetime.datetime(1997, 11, 4, 0, 0)}\n",
      "{'country': 'UK', 'totalamount': 285.0, 'window_start': datetime.datetime(1997, 11, 14, 0, 0), 'window_end': datetime.datetime(1997, 11, 15, 0, 0)}\n",
      "{'country': 'UK', 'totalamount': 336.0, 'window_start': datetime.datetime(1997, 11, 17, 0, 0), 'window_end': datetime.datetime(1997, 11, 18, 0, 0)}\n",
      "{'country': 'UK', 'totalamount': 1080.0, 'window_start': datetime.datetime(1997, 11, 20, 0, 0), 'window_end': datetime.datetime(1997, 11, 21, 0, 0)}\n",
      "{'country': 'UK', 'totalamount': 252.0, 'window_start': datetime.datetime(1997, 11, 24, 0, 0), 'window_end': datetime.datetime(1997, 11, 25, 0, 0)}\n",
      "{'country': 'UK', 'totalamount': 1477.0, 'window_start': datetime.datetime(1997, 12, 8, 0, 0), 'window_end': datetime.datetime(1997, 12, 9, 0, 0)}\n",
      "{'country': 'UK', 'totalamount': 191.1, 'window_start': datetime.datetime(1997, 12, 24, 0, 0), 'window_end': datetime.datetime(1997, 12, 25, 0, 0)}\n",
      "{'country': 'UK', 'totalamount': 2078.75, 'window_start': datetime.datetime(1997, 12, 26, 0, 0), 'window_end': datetime.datetime(1997, 12, 27, 0, 0)}\n",
      "{'country': 'UK', 'totalamount': 2290.4, 'window_start': datetime.datetime(1997, 12, 30, 0, 0), 'window_end': datetime.datetime(1997, 12, 31, 0, 0)}\n",
      "{'country': 'UK', 'totalamount': 1764.0, 'window_start': datetime.datetime(1998, 1, 13, 0, 0), 'window_end': datetime.datetime(1998, 1, 14, 0, 0)}\n",
      "{'country': 'UK', 'totalamount': 931.5, 'window_start': datetime.datetime(1998, 1, 23, 0, 0), 'window_end': datetime.datetime(1998, 1, 24, 0, 0)}\n",
      "{'country': 'UK', 'totalamount': 282.0, 'window_start': datetime.datetime(1998, 2, 2, 0, 0), 'window_end': datetime.datetime(1998, 2, 3, 0, 0)}\n",
      "{'country': 'UK', 'totalamount': 1630.0, 'window_start': datetime.datetime(1998, 2, 4, 0, 0), 'window_end': datetime.datetime(1998, 2, 5, 0, 0)}\n",
      "{'country': 'UK', 'totalamount': 390.0, 'window_start': datetime.datetime(1998, 3, 3, 0, 0), 'window_end': datetime.datetime(1998, 3, 4, 0, 0)}\n",
      "{'country': 'UK', 'totalamount': 920.6, 'window_start': datetime.datetime(1998, 3, 6, 0, 0), 'window_end': datetime.datetime(1998, 3, 7, 0, 0)}\n",
      "{'country': 'UK', 'totalamount': 711.0, 'window_start': datetime.datetime(1998, 3, 11, 0, 0), 'window_end': datetime.datetime(1998, 3, 12, 0, 0)}\n",
      "{'country': 'UK', 'totalamount': 220.0, 'window_start': datetime.datetime(1998, 3, 13, 0, 0), 'window_end': datetime.datetime(1998, 3, 14, 0, 0)}\n",
      "{'country': 'UK', 'totalamount': 4675.0, 'window_start': datetime.datetime(1998, 3, 16, 0, 0), 'window_end': datetime.datetime(1998, 3, 17, 0, 0)}\n",
      "{'country': 'UK', 'totalamount': 2772.0, 'window_start': datetime.datetime(1998, 3, 31, 0, 0), 'window_end': datetime.datetime(1998, 4, 1, 0, 0)}\n",
      "{'country': 'UK', 'totalamount': 491.5, 'window_start': datetime.datetime(1998, 4, 10, 0, 0), 'window_end': datetime.datetime(1998, 4, 11, 0, 0)}\n",
      "{'country': 'UK', 'totalamount': 1500.0, 'window_start': datetime.datetime(1998, 4, 14, 0, 0), 'window_end': datetime.datetime(1998, 4, 15, 0, 0)}\n",
      "{'country': 'UK', 'totalamount': 1966.81, 'window_start': datetime.datetime(1998, 4, 15, 0, 0), 'window_end': datetime.datetime(1998, 4, 16, 0, 0)}\n",
      "{'country': 'UK', 'totalamount': 1090.5, 'window_start': datetime.datetime(1998, 4, 24, 0, 0), 'window_end': datetime.datetime(1998, 4, 25, 0, 0)}\n",
      "{'country': 'UK', 'totalamount': 3740.0, 'window_start': datetime.datetime(1998, 4, 28, 0, 0), 'window_end': datetime.datetime(1998, 4, 29, 0, 0)}\n",
      "{'country': 'UK', 'totalamount': 45.0, 'window_start': datetime.datetime(1998, 4, 29, 0, 0), 'window_end': datetime.datetime(1998, 4, 30, 0, 0)}\n",
      "{'country': 'Ireland', 'totalamount': 3127.0, 'window_start': datetime.datetime(1996, 9, 5, 0, 0), 'window_end': datetime.datetime(1996, 9, 6, 0, 0)}\n",
      "{'country': 'Ireland', 'totalamount': 1762.0, 'window_start': datetime.datetime(1996, 9, 19, 0, 0), 'window_end': datetime.datetime(1996, 9, 20, 0, 0)}\n",
      "{'country': 'Ireland', 'totalamount': 2545.2, 'window_start': datetime.datetime(1996, 10, 22, 0, 0), 'window_end': datetime.datetime(1996, 10, 23, 0, 0)}\n",
      "{'country': 'Ireland', 'totalamount': 1708.0, 'window_start': datetime.datetime(1996, 12, 5, 0, 0), 'window_end': datetime.datetime(1996, 12, 6, 0, 0)}\n",
      "{'country': 'Ireland', 'totalamount': 1419.8, 'window_start': datetime.datetime(1996, 12, 12, 0, 0), 'window_end': datetime.datetime(1996, 12, 13, 0, 0)}\n",
      "{'country': 'Ireland', 'totalamount': 1748.5, 'window_start': datetime.datetime(1997, 1, 29, 0, 0), 'window_end': datetime.datetime(1997, 1, 30, 0, 0)}\n",
      "{'country': 'Ireland', 'totalamount': 2048.5, 'window_start': datetime.datetime(1997, 4, 11, 0, 0), 'window_end': datetime.datetime(1997, 4, 12, 0, 0)}\n",
      "{'country': 'Ireland', 'totalamount': 2614.5, 'window_start': datetime.datetime(1997, 4, 24, 0, 0), 'window_end': datetime.datetime(1997, 4, 25, 0, 0)}\n",
      "{'country': 'Ireland', 'totalamount': 3109.0, 'window_start': datetime.datetime(1997, 6, 12, 0, 0), 'window_end': datetime.datetime(1997, 6, 13, 0, 0)}\n",
      "{'country': 'Ireland', 'totalamount': 1928.0, 'window_start': datetime.datetime(1997, 8, 27, 0, 0), 'window_end': datetime.datetime(1997, 8, 28, 0, 0)}\n",
      "{'country': 'Ireland', 'totalamount': 703.25, 'window_start': datetime.datetime(1997, 9, 9, 0, 0), 'window_end': datetime.datetime(1997, 9, 10, 0, 0)}\n",
      "{'country': 'Ireland', 'totalamount': 6201.9, 'window_start': datetime.datetime(1997, 9, 30, 0, 0), 'window_end': datetime.datetime(1997, 10, 1, 0, 0)}\n",
      "{'country': 'Ireland', 'totalamount': 3370.0, 'window_start': datetime.datetime(1997, 10, 13, 0, 0), 'window_end': datetime.datetime(1997, 10, 14, 0, 0)}\n",
      "{'country': 'Ireland', 'totalamount': 1238.4, 'window_start': datetime.datetime(1997, 10, 21, 0, 0), 'window_end': datetime.datetime(1997, 10, 22, 0, 0)}\n",
      "{'country': 'Ireland', 'totalamount': 997.0, 'window_start': datetime.datetime(1997, 11, 11, 0, 0), 'window_end': datetime.datetime(1997, 11, 12, 0, 0)}\n",
      "{'country': 'Ireland', 'totalamount': 10835.240000000002, 'window_start': datetime.datetime(1998, 2, 19, 0, 0), 'window_end': datetime.datetime(1998, 2, 20, 0, 0)}\n",
      "{'country': 'Ireland', 'totalamount': 8267.400000000001, 'window_start': datetime.datetime(1998, 2, 26, 0, 0), 'window_end': datetime.datetime(1998, 2, 27, 0, 0)}\n",
      "{'country': 'Ireland', 'totalamount': 2248.2, 'window_start': datetime.datetime(1998, 3, 30, 0, 0), 'window_end': datetime.datetime(1998, 3, 31, 0, 0)}\n",
      "{'country': 'Ireland', 'totalamount': 1445.5, 'window_start': datetime.datetime(1998, 4, 30, 0, 0), 'window_end': datetime.datetime(1998, 5, 1, 0, 0)}\n",
      "{'country': 'Portugal', 'totalamount': 1168.0, 'window_start': datetime.datetime(1996, 10, 14, 0, 0), 'window_end': datetime.datetime(1996, 10, 15, 0, 0)}\n",
      "{'country': 'Portugal', 'totalamount': 316.8, 'window_start': datetime.datetime(1996, 10, 23, 0, 0), 'window_end': datetime.datetime(1996, 10, 24, 0, 0)}\n",
      "{'country': 'Portugal', 'totalamount': 154.0, 'window_start': datetime.datetime(1996, 11, 12, 0, 0), 'window_end': datetime.datetime(1996, 11, 13, 0, 0)}\n",
      "{'country': 'Portugal', 'totalamount': 843.1999999999999, 'window_start': datetime.datetime(1996, 12, 27, 0, 0), 'window_end': datetime.datetime(1996, 12, 28, 0, 0)}\n",
      "{'country': 'Portugal', 'totalamount': 851.1999999999999, 'window_start': datetime.datetime(1997, 2, 3, 0, 0), 'window_end': datetime.datetime(1997, 2, 4, 0, 0)}\n",
      "{'country': 'Portugal', 'totalamount': 1848.0, 'window_start': datetime.datetime(1997, 3, 4, 0, 0), 'window_end': datetime.datetime(1997, 3, 5, 0, 0)}\n",
      "{'country': 'Portugal', 'totalamount': 672.0, 'window_start': datetime.datetime(1997, 3, 17, 0, 0), 'window_end': datetime.datetime(1997, 3, 18, 0, 0)}\n",
      "{'country': 'Portugal', 'totalamount': 305.3, 'window_start': datetime.datetime(1997, 3, 31, 0, 0), 'window_end': datetime.datetime(1997, 4, 1, 0, 0)}\n",
      "{'country': 'Portugal', 'totalamount': 1836.0, 'window_start': datetime.datetime(1997, 5, 28, 0, 0), 'window_end': datetime.datetime(1997, 5, 29, 0, 0)}\n",
      "{'country': 'Portugal', 'totalamount': 256.5, 'window_start': datetime.datetime(1997, 7, 18, 0, 0), 'window_end': datetime.datetime(1997, 7, 19, 0, 0)}\n",
      "{'country': 'Portugal', 'totalamount': 1515.75, 'window_start': datetime.datetime(1997, 9, 10, 0, 0), 'window_end': datetime.datetime(1997, 9, 11, 0, 0)}\n",
      "{'country': 'Portugal', 'totalamount': 68.0, 'window_start': datetime.datetime(1998, 3, 19, 0, 0), 'window_end': datetime.datetime(1998, 3, 20, 0, 0)}\n",
      "{'country': 'Portugal', 'totalamount': 2633.9, 'window_start': datetime.datetime(1998, 4, 8, 0, 0), 'window_end': datetime.datetime(1998, 4, 9, 0, 0)}\n",
      "{'country': 'Canada', 'totalamount': 2233.6, 'window_start': datetime.datetime(1996, 10, 17, 0, 0), 'window_end': datetime.datetime(1996, 10, 18, 0, 0)}\n",
      "{'country': 'Canada', 'totalamount': 3463.2, 'window_start': datetime.datetime(1996, 10, 28, 0, 0), 'window_end': datetime.datetime(1996, 10, 29, 0, 0)}\n",
      "{'country': 'Canada', 'totalamount': 420.0, 'window_start': datetime.datetime(1996, 12, 9, 0, 0), 'window_end': datetime.datetime(1996, 12, 10, 0, 0)}\n",
      "{'country': 'Canada', 'totalamount': 1832.8, 'window_start': datetime.datetime(1996, 12, 20, 0, 0), 'window_end': datetime.datetime(1996, 12, 21, 0, 0)}\n",
      "{'country': 'Canada', 'totalamount': 2010.5, 'window_start': datetime.datetime(1997, 1, 10, 0, 0), 'window_end': datetime.datetime(1997, 1, 11, 0, 0)}\n",
      "{'country': 'Canada', 'totalamount': 11493.2, 'window_start': datetime.datetime(1997, 1, 23, 0, 0), 'window_end': datetime.datetime(1997, 1, 24, 0, 0)}\n",
      "{'country': 'Canada', 'totalamount': 2523.0, 'window_start': datetime.datetime(1997, 1, 30, 0, 0), 'window_end': datetime.datetime(1997, 1, 31, 0, 0)}\n",
      "{'country': 'Canada', 'totalamount': 1078.0, 'window_start': datetime.datetime(1997, 2, 7, 0, 0), 'window_end': datetime.datetime(1997, 2, 8, 0, 0)}\n",
      "{'country': 'Canada', 'totalamount': 896.0, 'window_start': datetime.datetime(1997, 4, 1, 0, 0), 'window_end': datetime.datetime(1997, 4, 2, 0, 0)}\n",
      "{'country': 'Canada', 'totalamount': 278.0, 'window_start': datetime.datetime(1997, 4, 3, 0, 0), 'window_end': datetime.datetime(1997, 4, 4, 0, 0)}\n",
      "{'country': 'Canada', 'totalamount': 147.89999999999998, 'window_start': datetime.datetime(1997, 4, 14, 0, 0), 'window_end': datetime.datetime(1997, 4, 15, 0, 0)}\n",
      "{'country': 'Canada', 'totalamount': 711.0, 'window_start': datetime.datetime(1997, 6, 11, 0, 0), 'window_end': datetime.datetime(1997, 6, 12, 0, 0)}\n",
      "{'country': 'Canada', 'totalamount': 2595.0, 'window_start': datetime.datetime(1997, 6, 17, 0, 0), 'window_end': datetime.datetime(1997, 6, 18, 0, 0)}\n",
      "{'country': 'Canada', 'totalamount': 1140.0, 'window_start': datetime.datetime(1997, 7, 7, 0, 0), 'window_end': datetime.datetime(1997, 7, 8, 0, 0)}\n",
      "{'country': 'Canada', 'totalamount': 4326.0, 'window_start': datetime.datetime(1997, 7, 21, 0, 0), 'window_end': datetime.datetime(1997, 7, 22, 0, 0)}\n",
      "{'country': 'Canada', 'totalamount': 2697.5, 'window_start': datetime.datetime(1997, 8, 1, 0, 0), 'window_end': datetime.datetime(1997, 8, 2, 0, 0)}\n",
      "{'country': 'Canada', 'totalamount': 1260.0, 'window_start': datetime.datetime(1997, 8, 4, 0, 0), 'window_end': datetime.datetime(1997, 8, 5, 0, 0)}\n",
      "{'country': 'Canada', 'totalamount': 57.5, 'window_start': datetime.datetime(1997, 8, 5, 0, 0), 'window_end': datetime.datetime(1997, 8, 6, 0, 0)}\n",
      "{'country': 'Canada', 'totalamount': 638.5, 'window_start': datetime.datetime(1997, 10, 30, 0, 0), 'window_end': datetime.datetime(1997, 10, 31, 0, 0)}\n",
      "{'country': 'Canada', 'totalamount': 3118.0, 'window_start': datetime.datetime(1997, 11, 14, 0, 0), 'window_end': datetime.datetime(1997, 11, 15, 0, 0)}\n",
      "{'country': 'Canada', 'totalamount': 187.0, 'window_start': datetime.datetime(1998, 1, 1, 0, 0), 'window_end': datetime.datetime(1998, 1, 2, 0, 0)}\n",
      "{'country': 'Canada', 'totalamount': 1930.0, 'window_start': datetime.datetime(1998, 3, 2, 0, 0), 'window_end': datetime.datetime(1998, 3, 3, 0, 0)}\n",
      "{'country': 'Canada', 'totalamount': 1139.1, 'window_start': datetime.datetime(1998, 3, 12, 0, 0), 'window_end': datetime.datetime(1998, 3, 13, 0, 0)}\n",
      "{'country': 'Canada', 'totalamount': 4422.0, 'window_start': datetime.datetime(1998, 3, 13, 0, 0), 'window_end': datetime.datetime(1998, 3, 14, 0, 0)}\n",
      "{'country': 'Canada', 'totalamount': 717.5, 'window_start': datetime.datetime(1998, 3, 25, 0, 0), 'window_end': datetime.datetime(1998, 3, 26, 0, 0)}\n",
      "{'country': 'Canada', 'totalamount': 1014.0, 'window_start': datetime.datetime(1998, 3, 27, 0, 0), 'window_end': datetime.datetime(1998, 3, 28, 0, 0)}\n",
      "{'country': 'Canada', 'totalamount': 1170.3, 'window_start': datetime.datetime(1998, 4, 16, 0, 0), 'window_end': datetime.datetime(1998, 4, 17, 0, 0)}\n",
      "{'country': 'Canada', 'totalamount': 1309.5, 'window_start': datetime.datetime(1998, 4, 23, 0, 0), 'window_end': datetime.datetime(1998, 4, 24, 0, 0)}\n",
      "{'country': 'Canada', 'totalamount': 525.0, 'window_start': datetime.datetime(1998, 4, 24, 0, 0), 'window_end': datetime.datetime(1998, 4, 25, 0, 0)}\n",
      "{'country': 'Denmark', 'totalamount': 412.0, 'window_start': datetime.datetime(1996, 10, 29, 0, 0), 'window_end': datetime.datetime(1996, 10, 30, 0, 0)}\n",
      "{'country': 'Denmark', 'totalamount': 834.1999999999999, 'window_start': datetime.datetime(1996, 11, 28, 0, 0), 'window_end': datetime.datetime(1996, 11, 29, 0, 0)}\n",
      "{'country': 'Denmark', 'totalamount': 1765.6, 'window_start': datetime.datetime(1996, 12, 31, 0, 0), 'window_end': datetime.datetime(1997, 1, 1, 0, 0)}\n",
      "{'country': 'Denmark', 'totalamount': 11283.2, 'window_start': datetime.datetime(1997, 1, 16, 0, 0), 'window_end': datetime.datetime(1997, 1, 17, 0, 0)}\n",
      "{'country': 'Denmark', 'totalamount': 2719.0, 'window_start': datetime.datetime(1997, 3, 5, 0, 0), 'window_end': datetime.datetime(1997, 3, 6, 0, 0)}\n",
      "{'country': 'Denmark', 'totalamount': 835.1999999999999, 'window_start': datetime.datetime(1997, 6, 3, 0, 0), 'window_end': datetime.datetime(1997, 6, 4, 0, 0)}\n",
      "{'country': 'Denmark', 'totalamount': 812.5, 'window_start': datetime.datetime(1997, 7, 7, 0, 0), 'window_end': datetime.datetime(1997, 7, 8, 0, 0)}\n",
      "{'country': 'Denmark', 'totalamount': 65.0, 'window_start': datetime.datetime(1997, 7, 17, 0, 0), 'window_end': datetime.datetime(1997, 7, 18, 0, 0)}\n",
      "{'country': 'Denmark', 'totalamount': 870.0, 'window_start': datetime.datetime(1997, 8, 22, 0, 0), 'window_end': datetime.datetime(1997, 8, 23, 0, 0)}\n",
      "{'country': 'Denmark', 'totalamount': 570.0, 'window_start': datetime.datetime(1997, 9, 15, 0, 0), 'window_end': datetime.datetime(1997, 9, 16, 0, 0)}\n",
      "{'country': 'Denmark', 'totalamount': 3490.0, 'window_start': datetime.datetime(1997, 10, 1, 0, 0), 'window_end': datetime.datetime(1997, 10, 2, 0, 0)}\n",
      "{'country': 'Denmark', 'totalamount': 919.9999999999999, 'window_start': datetime.datetime(1997, 11, 17, 0, 0), 'window_end': datetime.datetime(1997, 11, 18, 0, 0)}\n",
      "{'country': 'Denmark', 'totalamount': 1704.0, 'window_start': datetime.datetime(1997, 12, 8, 0, 0), 'window_end': datetime.datetime(1997, 12, 9, 0, 0)}\n",
      "{'country': 'Denmark', 'totalamount': 3923.75, 'window_start': datetime.datetime(1997, 12, 29, 0, 0), 'window_end': datetime.datetime(1997, 12, 30, 0, 0)}\n",
      "{'country': 'Denmark', 'totalamount': 1936.0, 'window_start': datetime.datetime(1998, 3, 3, 0, 0), 'window_end': datetime.datetime(1998, 3, 4, 0, 0)}\n",
      "{'country': 'Denmark', 'totalamount': 1407.5, 'window_start': datetime.datetime(1998, 3, 12, 0, 0), 'window_end': datetime.datetime(1998, 3, 13, 0, 0)}\n",
      "{'country': 'Denmark', 'totalamount': 990.0, 'window_start': datetime.datetime(1998, 4, 2, 0, 0), 'window_end': datetime.datetime(1998, 4, 3, 0, 0)}\n",
      "{'country': 'Denmark', 'totalamount': 244.29999999999998, 'window_start': datetime.datetime(1998, 5, 6, 0, 0), 'window_end': datetime.datetime(1998, 5, 7, 0, 0)}\n",
      "{'country': 'Poland', 'totalamount': 459.0, 'window_start': datetime.datetime(1996, 12, 5, 0, 0), 'window_end': datetime.datetime(1996, 12, 6, 0, 0)}\n",
      "{'country': 'Poland', 'totalamount': 808.0, 'window_start': datetime.datetime(1997, 7, 25, 0, 0), 'window_end': datetime.datetime(1997, 7, 26, 0, 0)}\n",
      "{'country': 'Poland', 'totalamount': 399.85, 'window_start': datetime.datetime(1997, 12, 23, 0, 0), 'window_end': datetime.datetime(1997, 12, 24, 0, 0)}\n",
      "{'country': 'Poland', 'totalamount': 160.0, 'window_start': datetime.datetime(1998, 2, 4, 0, 0), 'window_end': datetime.datetime(1998, 2, 5, 0, 0)}\n",
      "{'country': 'Poland', 'totalamount': 427.5, 'window_start': datetime.datetime(1998, 2, 25, 0, 0), 'window_end': datetime.datetime(1998, 2, 26, 0, 0)}\n",
      "{'country': 'Poland', 'totalamount': 686.0, 'window_start': datetime.datetime(1998, 4, 3, 0, 0), 'window_end': datetime.datetime(1998, 4, 4, 0, 0)}\n",
      "{'country': 'Poland', 'totalamount': 591.5999999999999, 'window_start': datetime.datetime(1998, 4, 23, 0, 0), 'window_end': datetime.datetime(1998, 4, 24, 0, 0)}\n",
      "{'country': 'Norway', 'totalamount': 1058.4, 'window_start': datetime.datetime(1996, 12, 18, 0, 0), 'window_end': datetime.datetime(1996, 12, 19, 0, 0)}\n",
      "{'country': 'Norway', 'totalamount': 200.0, 'window_start': datetime.datetime(1997, 4, 29, 0, 0), 'window_end': datetime.datetime(1997, 4, 30, 0, 0)}\n",
      "{'country': 'Norway', 'totalamount': 500.0, 'window_start': datetime.datetime(1997, 8, 20, 0, 0), 'window_end': datetime.datetime(1997, 8, 21, 0, 0)}\n",
      "{'country': 'Norway', 'totalamount': 2684.4, 'window_start': datetime.datetime(1998, 1, 14, 0, 0), 'window_end': datetime.datetime(1998, 1, 15, 0, 0)}\n",
      "{'country': 'Norway', 'totalamount': 670.0, 'window_start': datetime.datetime(1998, 2, 26, 0, 0), 'window_end': datetime.datetime(1998, 2, 27, 0, 0)}\n",
      "{'country': 'Norway', 'totalamount': 622.35, 'window_start': datetime.datetime(1998, 4, 10, 0, 0), 'window_end': datetime.datetime(1998, 4, 11, 0, 0)}\n",
      "{'country': 'Argentina', 'totalamount': 319.20000000000005, 'window_start': datetime.datetime(1997, 1, 9, 0, 0), 'window_end': datetime.datetime(1997, 1, 10, 0, 0)}\n",
      "{'country': 'Argentina', 'totalamount': 443.4, 'window_start': datetime.datetime(1997, 2, 17, 0, 0), 'window_end': datetime.datetime(1997, 2, 18, 0, 0)}\n",
      "{'country': 'Argentina', 'totalamount': 225.5, 'window_start': datetime.datetime(1997, 4, 29, 0, 0), 'window_end': datetime.datetime(1997, 4, 30, 0, 0)}\n",
      "{'country': 'Argentina', 'totalamount': 110.0, 'window_start': datetime.datetime(1997, 5, 8, 0, 0), 'window_end': datetime.datetime(1997, 5, 9, 0, 0)}\n",
      "{'country': 'Argentina', 'totalamount': 706.0, 'window_start': datetime.datetime(1997, 10, 24, 0, 0), 'window_end': datetime.datetime(1997, 10, 25, 0, 0)}\n",
      "{'country': 'Argentina', 'totalamount': 12.5, 'window_start': datetime.datetime(1997, 12, 17, 0, 0), 'window_end': datetime.datetime(1997, 12, 18, 0, 0)}\n",
      "{'country': 'Argentina', 'totalamount': 477.0, 'window_start': datetime.datetime(1998, 1, 7, 0, 0), 'window_end': datetime.datetime(1998, 1, 8, 0, 0)}\n",
      "{'country': 'Argentina', 'totalamount': 932.0, 'window_start': datetime.datetime(1998, 1, 13, 0, 0), 'window_end': datetime.datetime(1998, 1, 14, 0, 0)}\n",
      "{'country': 'Argentina', 'totalamount': 150.0, 'window_start': datetime.datetime(1998, 2, 11, 0, 0), 'window_end': datetime.datetime(1998, 2, 12, 0, 0)}\n",
      "{'country': 'Argentina', 'totalamount': 30.0, 'window_start': datetime.datetime(1998, 2, 20, 0, 0), 'window_end': datetime.datetime(1998, 2, 21, 0, 0)}\n",
      "{'country': 'Argentina', 'totalamount': 686.7, 'window_start': datetime.datetime(1998, 2, 27, 0, 0), 'window_end': datetime.datetime(1998, 2, 28, 0, 0)}\n",
      "{'country': 'Argentina', 'totalamount': 644.8, 'window_start': datetime.datetime(1998, 3, 10, 0, 0), 'window_end': datetime.datetime(1998, 3, 11, 0, 0)}\n",
      "{'country': 'Argentina', 'totalamount': 781.0, 'window_start': datetime.datetime(1998, 3, 18, 0, 0), 'window_end': datetime.datetime(1998, 3, 19, 0, 0)}\n",
      "{'country': 'Argentina', 'totalamount': 2220.0, 'window_start': datetime.datetime(1998, 3, 30, 0, 0), 'window_end': datetime.datetime(1998, 3, 31, 0, 0)}\n",
      "{'country': 'Argentina', 'totalamount': 76.0, 'window_start': datetime.datetime(1998, 4, 13, 0, 0), 'window_end': datetime.datetime(1998, 4, 14, 0, 0)}\n",
      "{'country': 'Argentina', 'totalamount': 305.0, 'window_start': datetime.datetime(1998, 4, 28, 0, 0), 'window_end': datetime.datetime(1998, 4, 29, 0, 0)}\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam import pvalue\n",
    "from apache_beam.io import ReadFromText, WriteToText\n",
    "from datetime import datetime\n",
    "import time\n",
    "import typing\n",
    "from apache_beam import coders\n",
    "from apache_beam.transforms.sql import SqlTransform\n",
    "from apache_beam import window\n",
    "\n",
    "class GetTimestampFn(beam.DoFn):\n",
    "    def process(self, element, window=beam.DoFn.WindowParam):\n",
    "        #print(element, type(element), dir(element))\n",
    "        # window_start = window.start.to_utc_datetime().strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
    "        # window_end = window.end.to_utc_datetime().strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
    "        window_start = window.start.to_utc_datetime()\n",
    "        window_end = window.end.to_utc_datetime()\n",
    "        output = { **(element._asdict()), 'window_start': window_start, 'window_end': window_end}\n",
    "        yield output\n",
    "\n",
    "class LeftJoin(beam.PTransform):\n",
    "    '''\n",
    "    This PTransform will take a dictionary to the left of the | which will be the collection of the two\n",
    "    PCollections you want to join together. Both must be a dictionary. You will then pass in the name of each\n",
    "    PCollection and the key to join them on.\n",
    "    It will automatically reshape the two dicts into tuples of (key, dict) where it removes the key from each dict\n",
    "    It then CoGroups them and reshapes the tuple into a dict ready for insertion to a BQ table\n",
    "    '''\n",
    "    def __init__(self, parent_pipeline_name, parent_key, child_pipeline_name, child_key):\n",
    "        self.parent_pipeline_name = parent_pipeline_name\n",
    "        self.parent_key = parent_key\n",
    "        self.child_pipeline_name = child_pipeline_name\n",
    "        self.child_key = child_key\n",
    "\n",
    "    def expand(self, pcols):\n",
    "        def reshapeToKV(item, key):\n",
    "            # pipeline object should be a dictionary\n",
    "            item1 = item.copy()\n",
    "            del item1[key]\n",
    "            return (item[key], item1)\n",
    "\n",
    "        def reshapeCoGroupToFlatDict(item):\n",
    "            parent = {self.parent_key : item[0]}\n",
    "            parent.update(item[1][self.parent_pipeline_name][0])\n",
    "            ret = []\n",
    "            for row1 in item[1][self.child_pipeline_name]:\n",
    "                row = parent.copy()\n",
    "                row.update(row1)\n",
    "                ret.append(row)\n",
    "            return ret\n",
    "\n",
    "        return (\n",
    "                {\n",
    "                self.parent_pipeline_name : pcols[self.parent_pipeline_name] | f'Convert {self.parent_pipeline_name} to KV' \n",
    "                    >> beam.Map(reshapeToKV, self.parent_key)\n",
    "                ,self.child_pipeline_name : pcols[self.child_pipeline_name] | f'Convert {self.child_pipeline_name} to KV'\n",
    "                    >> beam.Map(reshapeToKV, self.child_key)\n",
    "                } | f'CoGroupByKey {self.child_pipeline_name} into {self.parent_pipeline_name}'\n",
    "                    >> beam.CoGroupByKey()\n",
    "                  | f'Reshape to dictionary'\n",
    "                    >> beam.FlatMap(reshapeCoGroupToFlatDict)\n",
    "        )\n",
    "\n",
    "ordersfilename = 'datasets/northwind/AVRO/orders/orders.avro'\n",
    "orderdetailsfilename = 'datasets/northwind/AVRO/orderdetails/orderdetails.avro'\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "    orders = (p | 'Read Orders' >> beam.io.ReadFromAvro(ordersfilename)\n",
    "             )\n",
    "    orderdetails = (p | 'Read OrderDetails' >> beam.io.ReadFromAvro(orderdetailsfilename)\n",
    "                   )\n",
    "    ordersjoin = ( {'orders': orders, 'orderdetails': orderdetails} \n",
    "                    | 'Join' >> LeftJoin('orders', 'orderid', 'orderdetails', 'orderid')\n",
    "                    | 'Select' >> beam.Map(lambda x : dict( customerid = x['customerid']\n",
    "                                                               , orderdate = datetime.strptime(x['orderdate'], '%Y-%m-%d').date()\n",
    "                                                               , country = x['shipcountry']\n",
    "                                                               , amount = x['unitprice'] * x['quantity']))\n",
    "                 )\n",
    "    \n",
    "    \n",
    "    groupby = (ordersjoin\n",
    "               | 'Timestamp' >> beam.Map(lambda x : beam.window.TimestampedValue(x, time.mktime(x['orderdate'].timetuple())))\n",
    "               | 'Window' >> beam.WindowInto(beam.window.FixedWindows(60 * 60 * 24))\n",
    "               | 'Group' >> beam.GroupBy(country = lambda x: x['country']).aggregate_field(lambda x: x['amount'], sum, 'totalamount')\n",
    "               | 'AddWindowTimestamp' >> (beam.ParDo(GetTimestampFn()))\n",
    "              )\n",
    "\n",
    "    groupby | beam.Map(print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "740287b5-2615-43df-90b7-166b976954fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "org.apache.beam.vendor.guava.v26_0_jre.com.google.common.util.concurrent.UncheckedExecutionException: org.apache.beam.vendor.guava.v26_0_jre.com.google.common.util.concurrent.UncheckedExecutionException: java.lang.IllegalArgumentException: Failed to decode Schema due to an error decoding Field proto:\n\nname: \"orderdate\"\ntype {\n  nullable: true\n  logical_type {\n    urn: \"beam:logical:pythonsdk_any:v1\"\n  }\n}\n\n\tat org.apache.beam.vendor.guava.v26_0_jre.com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2050)\n\tat org.apache.beam.vendor.guava.v26_0_jre.com.google.common.cache.LocalCache.get(LocalCache.java:3952)\n\tat org.apache.beam.vendor.guava.v26_0_jre.com.google.common.cache.LocalCache.getOrLoad(LocalCache.java:3974)\n\tat org.apache.beam.vendor.guava.v26_0_jre.com.google.common.cache.LocalCache$LocalLoadingCache.get(LocalCache.java:4958)\n\tat org.apache.beam.runners.core.construction.RehydratedComponents.getPCollection(RehydratedComponents.java:139)\n\tat org.apache.beam.sdk.expansion.service.ExpansionService.lambda$expand$0(ExpansionService.java:497)\n\tat java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321)\n\tat java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169)\n\tat java.util.Collections$UnmodifiableMap$UnmodifiableEntrySet.lambda$entryConsumer$0(Collections.java:1575)\n\tat java.util.Iterator.forEachRemaining(Iterator.java:116)\n\tat java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)\n\tat java.util.Collections$UnmodifiableMap$UnmodifiableEntrySet$UnmodifiableEntrySetSpliterator.forEachRemaining(Collections.java:1600)\n\tat java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481)\n\tat java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471)\n\tat java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708)\n\tat java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)\n\tat java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499)\n\tat org.apache.beam.sdk.expansion.service.ExpansionService.expand(ExpansionService.java:492)\n\tat org.apache.beam.sdk.expansion.service.ExpansionService.expand(ExpansionService.java:606)\n\tat org.apache.beam.model.expansion.v1.ExpansionServiceGrpc$MethodHandlers.invoke(ExpansionServiceGrpc.java:305)\n\tat org.apache.beam.vendor.grpc.v1p48p1.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:182)\n\tat org.apache.beam.vendor.grpc.v1p48p1.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:354)\n\tat org.apache.beam.vendor.grpc.v1p48p1.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:866)\n\tat org.apache.beam.vendor.grpc.v1p48p1.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)\n\tat org.apache.beam.vendor.grpc.v1p48p1.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: org.apache.beam.vendor.guava.v26_0_jre.com.google.common.util.concurrent.UncheckedExecutionException: java.lang.IllegalArgumentException: Failed to decode Schema due to an error decoding Field proto:\n\nname: \"orderdate\"\ntype {\n  nullable: true\n  logical_type {\n    urn: \"beam:logical:pythonsdk_any:v1\"\n  }\n}\n\n\tat org.apache.beam.vendor.guava.v26_0_jre.com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2050)\n\tat org.apache.beam.vendor.guava.v26_0_jre.com.google.common.cache.LocalCache.get(LocalCache.java:3952)\n\tat org.apache.beam.vendor.guava.v26_0_jre.com.google.common.cache.LocalCache.getOrLoad(LocalCache.java:3974)\n\tat org.apache.beam.vendor.guava.v26_0_jre.com.google.common.cache.LocalCache$LocalLoadingCache.get(LocalCache.java:4958)\n\tat org.apache.beam.runners.core.construction.RehydratedComponents.getCoder(RehydratedComponents.java:168)\n\tat org.apache.beam.runners.core.construction.PCollectionTranslation.fromProto(PCollectionTranslation.java:51)\n\tat org.apache.beam.runners.core.construction.RehydratedComponents$3.load(RehydratedComponents.java:108)\n\tat org.apache.beam.runners.core.construction.RehydratedComponents$3.load(RehydratedComponents.java:98)\n\tat org.apache.beam.vendor.guava.v26_0_jre.com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3528)\n\tat org.apache.beam.vendor.guava.v26_0_jre.com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2277)\n\tat org.apache.beam.vendor.guava.v26_0_jre.com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2154)\n\tat org.apache.beam.vendor.guava.v26_0_jre.com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2044)\n\t... 27 more\nCaused by: java.lang.IllegalArgumentException: Failed to decode Schema due to an error decoding Field proto:\n\nname: \"orderdate\"\ntype {\n  nullable: true\n  logical_type {\n    urn: \"beam:logical:pythonsdk_any:v1\"\n  }\n}\n\n\tat org.apache.beam.sdk.schemas.SchemaTranslation.schemaFromProto(SchemaTranslation.java:271)\n\tat org.apache.beam.runners.core.construction.CoderTranslators$8.fromComponents(CoderTranslators.java:171)\n\tat org.apache.beam.runners.core.construction.CoderTranslators$8.fromComponents(CoderTranslators.java:153)\n\tat org.apache.beam.runners.core.construction.CoderTranslation.fromKnownCoder(CoderTranslation.java:170)\n\tat org.apache.beam.runners.core.construction.CoderTranslation.fromProto(CoderTranslation.java:145)\n\tat org.apache.beam.runners.core.construction.RehydratedComponents$2.load(RehydratedComponents.java:87)\n\tat org.apache.beam.runners.core.construction.RehydratedComponents$2.load(RehydratedComponents.java:82)\n\tat org.apache.beam.vendor.guava.v26_0_jre.com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3528)\n\tat org.apache.beam.vendor.guava.v26_0_jre.com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2277)\n\tat org.apache.beam.vendor.guava.v26_0_jre.com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2154)\n\tat org.apache.beam.vendor.guava.v26_0_jre.com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2044)\n\t... 38 more\nCaused by: java.lang.IllegalArgumentException: Unexpected type_info: TYPEINFO_NOT_SET\n\tat org.apache.beam.sdk.schemas.SchemaTranslation.fieldTypeFromProtoWithoutNullable(SchemaTranslation.java:462)\n\tat org.apache.beam.sdk.schemas.SchemaTranslation.fieldTypeFromProto(SchemaTranslation.java:306)\n\tat org.apache.beam.sdk.schemas.SchemaTranslation.fieldTypeFromProtoWithoutNullable(SchemaTranslation.java:459)\n\tat org.apache.beam.sdk.schemas.SchemaTranslation.fieldTypeFromProto(SchemaTranslation.java:306)\n\tat org.apache.beam.sdk.schemas.SchemaTranslation.fieldFromProto(SchemaTranslation.java:299)\n\tat org.apache.beam.sdk.schemas.SchemaTranslation.schemaFromProto(SchemaTranslation.java:269)\n\t... 48 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 93\u001b[0m\n\u001b[1;32m     79\u001b[0m orders \u001b[38;5;241m=\u001b[39m (p \u001b[38;5;241m|\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRead Orders\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m>>\u001b[39m beam\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mReadFromAvro(ordersfilename)\n\u001b[1;32m     80\u001b[0m             \u001b[38;5;241m|\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mParse Date\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m>>\u001b[39m beam\u001b[38;5;241m.\u001b[39mMap(\u001b[38;5;28;01mlambda\u001b[39;00m x : \u001b[38;5;28mdict\u001b[39m(orderid \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124morderid\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     81\u001b[0m                                                        , country \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshipcountry\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     84\u001b[0m              \u001b[38;5;241m|\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOrder to Class\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m>>\u001b[39m beam\u001b[38;5;241m.\u001b[39mMap(\u001b[38;5;28;01mlambda\u001b[39;00m x : Order(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mx))\u001b[38;5;241m.\u001b[39mwith_output_types(Order) \n\u001b[1;32m     85\u001b[0m          )\n\u001b[1;32m     86\u001b[0m orderdetails \u001b[38;5;241m=\u001b[39m (p \u001b[38;5;241m|\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRead OrderDetails\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m>>\u001b[39m beam\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mReadFromAvro(orderdetailsfilename)\n\u001b[1;32m     87\u001b[0m                   \u001b[38;5;241m|\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mParse Amount\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m>>\u001b[39m beam\u001b[38;5;241m.\u001b[39mMap(\u001b[38;5;28;01mlambda\u001b[39;00m x : \u001b[38;5;28mdict\u001b[39m(orderid \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124morderid\u001b[39m\u001b[38;5;124m'\u001b[39m]                        \n\u001b[1;32m     88\u001b[0m                                                            , amount \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munitprice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquantity\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     91\u001b[0m              \u001b[38;5;241m|\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOrderDetail to Class\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m>>\u001b[39m beam\u001b[38;5;241m.\u001b[39mMap(\u001b[38;5;28;01mlambda\u001b[39;00m x : OrderDetail(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mx))\u001b[38;5;241m.\u001b[39mwith_output_types(OrderDetail) \n\u001b[1;32m     92\u001b[0m                )\n\u001b[0;32m---> 93\u001b[0m ordersjoin \u001b[38;5;241m=\u001b[39m ( \u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43morders\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43morders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43morderdetails\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43morderdetails\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m|\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSQL\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>>\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mSqlTransform\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'''\u001b[39;49m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;43m                SELECT country\u001b[39;49m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;43m                    , sum(amount) as total_amount\u001b[39;49m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;124;43m                FROM orders as o\u001b[39;49m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;124;43m                JOIN orderdetails as od on o.orderid = od.orderid\u001b[39;49m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;124;43m                GROUP BY country\u001b[39;49m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;124;43m                \u001b[39;49m\u001b[38;5;124;43m'''\u001b[39;49m\n\u001b[1;32m    101\u001b[0m \u001b[43m             \u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    102\u001b[0m \u001b[38;5;66;03m# ordersjoin = ( {'orders': orders, 'orderdetails': orderdetails} \u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m#                 | 'SQL' >> SqlTransform('''\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;66;03m#                 SELECT country, TUMBLE_START(orderdate, 60*60*24) as start_date\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;66;03m#                 '''\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;66;03m#              ))\u001b[39;00m\n\u001b[1;32m    113\u001b[0m ordersjoin \u001b[38;5;241m|\u001b[39m beam\u001b[38;5;241m.\u001b[39mMap(\u001b[38;5;28mprint\u001b[39m)\n",
      "File \u001b[0;32m/jupyter/.kernels/apache-beam-2.46.0/lib/python3.8/site-packages/apache_beam/transforms/ptransform.py:1095\u001b[0m, in \u001b[0;36m_NamedPTransform.__ror__\u001b[0;34m(self, pvalueish, _unused)\u001b[0m\n\u001b[1;32m   1094\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__ror__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pvalueish, _unused\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m-> 1095\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__ror__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpvalueish\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/jupyter/.kernels/apache-beam-2.46.0/lib/python3.8/site-packages/apache_beam/transforms/ptransform.py:617\u001b[0m, in \u001b[0;36mPTransform.__ror__\u001b[0;34m(self, left, label)\u001b[0m\n\u001b[1;32m    615\u001b[0m pvalueish \u001b[38;5;241m=\u001b[39m _SetInputPValues()\u001b[38;5;241m.\u001b[39mvisit(pvalueish, replacements)\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpipeline \u001b[38;5;241m=\u001b[39m p\n\u001b[0;32m--> 617\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpvalueish\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deferred:\n\u001b[1;32m    619\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/jupyter/.kernels/apache-beam-2.46.0/lib/python3.8/site-packages/apache_beam/pipeline.py:666\u001b[0m, in \u001b[0;36mPipeline.apply\u001b[0;34m(self, transform, pvalueish, label)\u001b[0m\n\u001b[1;32m    664\u001b[0m old_label, transform\u001b[38;5;241m.\u001b[39mlabel \u001b[38;5;241m=\u001b[39m transform\u001b[38;5;241m.\u001b[39mlabel, label\n\u001b[1;32m    665\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 666\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpvalueish\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    668\u001b[0m   transform\u001b[38;5;241m.\u001b[39mlabel \u001b[38;5;241m=\u001b[39m old_label\n",
      "File \u001b[0;32m/jupyter/.kernels/apache-beam-2.46.0/lib/python3.8/site-packages/apache_beam/pipeline.py:712\u001b[0m, in \u001b[0;36mPipeline.apply\u001b[0;34m(self, transform, pvalueish, label)\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m type_options\u001b[38;5;241m.\u001b[39mpipeline_type_check:\n\u001b[1;32m    710\u001b[0m   transform\u001b[38;5;241m.\u001b[39mtype_check_inputs(pvalueish)\n\u001b[0;32m--> 712\u001b[0m pvalueish_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpvalueish\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m type_options \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m type_options\u001b[38;5;241m.\u001b[39mpipeline_type_check:\n\u001b[1;32m    715\u001b[0m   transform\u001b[38;5;241m.\u001b[39mtype_check_outputs(pvalueish_result)\n",
      "File \u001b[0;32m/jupyter/.kernels/apache-beam-2.46.0/lib/python3.8/site-packages/apache_beam/runners/runner.py:185\u001b[0m, in \u001b[0;36mPipelineRunner.apply\u001b[0;34m(self, transform, input, options)\u001b[0m\n\u001b[1;32m    183\u001b[0m   m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapply_\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    184\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m m:\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExecution of [\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m] not implemented in runner \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (transform, \u001b[38;5;28mself\u001b[39m))\n",
      "File \u001b[0;32m/jupyter/.kernels/apache-beam-2.46.0/lib/python3.8/site-packages/apache_beam/runners/runner.py:215\u001b[0m, in \u001b[0;36mPipelineRunner.apply_PTransform\u001b[0;34m(self, transform, input, options)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_PTransform\u001b[39m(\u001b[38;5;28mself\u001b[39m, transform, \u001b[38;5;28minput\u001b[39m, options):\n\u001b[1;32m    214\u001b[0m   \u001b[38;5;66;03m# The base case of apply is to call the transform's expand.\u001b[39;00m\n\u001b[0;32m--> 215\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtransform\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/jupyter/.kernels/apache-beam-2.46.0/lib/python3.8/site-packages/apache_beam/transforms/external.py:605\u001b[0m, in \u001b[0;36mExternalTransform.expand\u001b[0;34m(self, pvalueish)\u001b[0m\n\u001b[1;32m    603\u001b[0m response \u001b[38;5;241m=\u001b[39m service\u001b[38;5;241m.\u001b[39mExpand(request)\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39merror:\n\u001b[0;32m--> 605\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(response\u001b[38;5;241m.\u001b[39merror)\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expanded_components \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mcomponents\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(env\u001b[38;5;241m.\u001b[39mdependencies\n\u001b[1;32m    608\u001b[0m        \u001b[38;5;28;01mfor\u001b[39;00m env \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expanded_components\u001b[38;5;241m.\u001b[39menvironments\u001b[38;5;241m.\u001b[39mvalues()):\n",
      "\u001b[0;31mRuntimeError\u001b[0m: org.apache.beam.vendor.guava.v26_0_jre.com.google.common.util.concurrent.UncheckedExecutionException: org.apache.beam.vendor.guava.v26_0_jre.com.google.common.util.concurrent.UncheckedExecutionException: java.lang.IllegalArgumentException: Failed to decode Schema due to an error decoding Field proto:\n\nname: \"orderdate\"\ntype {\n  nullable: true\n  logical_type {\n    urn: \"beam:logical:pythonsdk_any:v1\"\n  }\n}\n\n\tat org.apache.beam.vendor.guava.v26_0_jre.com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2050)\n\tat org.apache.beam.vendor.guava.v26_0_jre.com.google.common.cache.LocalCache.get(LocalCache.java:3952)\n\tat org.apache.beam.vendor.guava.v26_0_jre.com.google.common.cache.LocalCache.getOrLoad(LocalCache.java:3974)\n\tat org.apache.beam.vendor.guava.v26_0_jre.com.google.common.cache.LocalCache$LocalLoadingCache.get(LocalCache.java:4958)\n\tat org.apache.beam.runners.core.construction.RehydratedComponents.getPCollection(RehydratedComponents.java:139)\n\tat org.apache.beam.sdk.expansion.service.ExpansionService.lambda$expand$0(ExpansionService.java:497)\n\tat java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321)\n\tat java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169)\n\tat java.util.Collections$UnmodifiableMap$UnmodifiableEntrySet.lambda$entryConsumer$0(Collections.java:1575)\n\tat java.util.Iterator.forEachRemaining(Iterator.java:116)\n\tat java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)\n\tat java.util.Collections$UnmodifiableMap$UnmodifiableEntrySet$UnmodifiableEntrySetSpliterator.forEachRemaining(Collections.java:1600)\n\tat java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481)\n\tat java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471)\n\tat java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708)\n\tat java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)\n\tat java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499)\n\tat org.apache.beam.sdk.expansion.service.ExpansionService.expand(ExpansionService.java:492)\n\tat org.apache.beam.sdk.expansion.service.ExpansionService.expand(ExpansionService.java:606)\n\tat org.apache.beam.model.expansion.v1.ExpansionServiceGrpc$MethodHandlers.invoke(ExpansionServiceGrpc.java:305)\n\tat org.apache.beam.vendor.grpc.v1p48p1.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:182)\n\tat org.apache.beam.vendor.grpc.v1p48p1.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:354)\n\tat org.apache.beam.vendor.grpc.v1p48p1.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:866)\n\tat org.apache.beam.vendor.grpc.v1p48p1.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)\n\tat org.apache.beam.vendor.grpc.v1p48p1.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: org.apache.beam.vendor.guava.v26_0_jre.com.google.common.util.concurrent.UncheckedExecutionException: java.lang.IllegalArgumentException: Failed to decode Schema due to an error decoding Field proto:\n\nname: \"orderdate\"\ntype {\n  nullable: true\n  logical_type {\n    urn: \"beam:logical:pythonsdk_any:v1\"\n  }\n}\n\n\tat org.apache.beam.vendor.guava.v26_0_jre.com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2050)\n\tat org.apache.beam.vendor.guava.v26_0_jre.com.google.common.cache.LocalCache.get(LocalCache.java:3952)\n\tat org.apache.beam.vendor.guava.v26_0_jre.com.google.common.cache.LocalCache.getOrLoad(LocalCache.java:3974)\n\tat org.apache.beam.vendor.guava.v26_0_jre.com.google.common.cache.LocalCache$LocalLoadingCache.get(LocalCache.java:4958)\n\tat org.apache.beam.runners.core.construction.RehydratedComponents.getCoder(RehydratedComponents.java:168)\n\tat org.apache.beam.runners.core.construction.PCollectionTranslation.fromProto(PCollectionTranslation.java:51)\n\tat org.apache.beam.runners.core.construction.RehydratedComponents$3.load(RehydratedComponents.java:108)\n\tat org.apache.beam.runners.core.construction.RehydratedComponents$3.load(RehydratedComponents.java:98)\n\tat org.apache.beam.vendor.guava.v26_0_jre.com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3528)\n\tat org.apache.beam.vendor.guava.v26_0_jre.com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2277)\n\tat org.apache.beam.vendor.guava.v26_0_jre.com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2154)\n\tat org.apache.beam.vendor.guava.v26_0_jre.com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2044)\n\t... 27 more\nCaused by: java.lang.IllegalArgumentException: Failed to decode Schema due to an error decoding Field proto:\n\nname: \"orderdate\"\ntype {\n  nullable: true\n  logical_type {\n    urn: \"beam:logical:pythonsdk_any:v1\"\n  }\n}\n\n\tat org.apache.beam.sdk.schemas.SchemaTranslation.schemaFromProto(SchemaTranslation.java:271)\n\tat org.apache.beam.runners.core.construction.CoderTranslators$8.fromComponents(CoderTranslators.java:171)\n\tat org.apache.beam.runners.core.construction.CoderTranslators$8.fromComponents(CoderTranslators.java:153)\n\tat org.apache.beam.runners.core.construction.CoderTranslation.fromKnownCoder(CoderTranslation.java:170)\n\tat org.apache.beam.runners.core.construction.CoderTranslation.fromProto(CoderTranslation.java:145)\n\tat org.apache.beam.runners.core.construction.RehydratedComponents$2.load(RehydratedComponents.java:87)\n\tat org.apache.beam.runners.core.construction.RehydratedComponents$2.load(RehydratedComponents.java:82)\n\tat org.apache.beam.vendor.guava.v26_0_jre.com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3528)\n\tat org.apache.beam.vendor.guava.v26_0_jre.com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2277)\n\tat org.apache.beam.vendor.guava.v26_0_jre.com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2154)\n\tat org.apache.beam.vendor.guava.v26_0_jre.com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2044)\n\t... 38 more\nCaused by: java.lang.IllegalArgumentException: Unexpected type_info: TYPEINFO_NOT_SET\n\tat org.apache.beam.sdk.schemas.SchemaTranslation.fieldTypeFromProtoWithoutNullable(SchemaTranslation.java:462)\n\tat org.apache.beam.sdk.schemas.SchemaTranslation.fieldTypeFromProto(SchemaTranslation.java:306)\n\tat org.apache.beam.sdk.schemas.SchemaTranslation.fieldTypeFromProtoWithoutNullable(SchemaTranslation.java:459)\n\tat org.apache.beam.sdk.schemas.SchemaTranslation.fieldTypeFromProto(SchemaTranslation.java:306)\n\tat org.apache.beam.sdk.schemas.SchemaTranslation.fieldFromProto(SchemaTranslation.java:299)\n\tat org.apache.beam.sdk.schemas.SchemaTranslation.schemaFromProto(SchemaTranslation.java:269)\n\t... 48 more\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam import pvalue\n",
    "from apache_beam.io import ReadFromText, WriteToText\n",
    "from datetime import datetime\n",
    "import time\n",
    "import typing\n",
    "from apache_beam import coders\n",
    "from apache_beam.transforms.sql import SqlTransform\n",
    "from apache_beam import window\n",
    "\n",
    "class Order(typing.NamedTuple):\n",
    "    orderid: int\n",
    "    orderdate: datetime.date\n",
    "    country: str\n",
    "beam.coders.registry.register_coder(Order, coders.RowCoder)\n",
    "\n",
    "class OrderDetail(typing.NamedTuple):\n",
    "    orderid: int\n",
    "    amount: float\n",
    "beam.coders.registry.register_coder(OrderDetail, coders.RowCoder)\n",
    "\n",
    "class GetTimestampFn(beam.DoFn):\n",
    "    def process(self, element, window=beam.DoFn.WindowParam):\n",
    "        #print(element, type(element), dir(element))\n",
    "        # window_start = window.start.to_utc_datetime().strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
    "        # window_end = window.end.to_utc_datetime().strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
    "        window_start = window.start.to_utc_datetime()\n",
    "        window_end = window.end.to_utc_datetime()\n",
    "        output = { **(element._asdict()), 'window_start': window_start, 'window_end': window_end}\n",
    "        yield output\n",
    "\n",
    "class LeftJoin(beam.PTransform):\n",
    "    '''\n",
    "    This PTransform will take a dictionary to the left of the | which will be the collection of the two\n",
    "    PCollections you want to join together. Both must be a dictionary. You will then pass in the name of each\n",
    "    PCollection and the key to join them on.\n",
    "    It will automatically reshape the two dicts into tuples of (key, dict) where it removes the key from each dict\n",
    "    It then CoGroups them and reshapes the tuple into a dict ready for insertion to a BQ table\n",
    "    '''\n",
    "    def __init__(self, parent_pipeline_name, parent_key, child_pipeline_name, child_key):\n",
    "        self.parent_pipeline_name = parent_pipeline_name\n",
    "        self.parent_key = parent_key\n",
    "        self.child_pipeline_name = child_pipeline_name\n",
    "        self.child_key = child_key\n",
    "\n",
    "    def expand(self, pcols):\n",
    "        def reshapeToKV(item, key):\n",
    "            # pipeline object should be a dictionary\n",
    "            item1 = item.copy()\n",
    "            del item1[key]\n",
    "            return (item[key], item1)\n",
    "\n",
    "        def reshapeCoGroupToFlatDict(item):\n",
    "            parent = {self.parent_key : item[0]}\n",
    "            parent.update(item[1][self.parent_pipeline_name][0])\n",
    "            ret = []\n",
    "            for row1 in item[1][self.child_pipeline_name]:\n",
    "                row = parent.copy()\n",
    "                row.update(row1)\n",
    "                ret.append(row)\n",
    "            return ret\n",
    "\n",
    "        return (\n",
    "                {\n",
    "                self.parent_pipeline_name : pcols[self.parent_pipeline_name] | f'Convert {self.parent_pipeline_name} to KV' \n",
    "                    >> beam.Map(reshapeToKV, self.parent_key)\n",
    "                ,self.child_pipeline_name : pcols[self.child_pipeline_name] | f'Convert {self.child_pipeline_name} to KV'\n",
    "                    >> beam.Map(reshapeToKV, self.child_key)\n",
    "                } | f'CoGroupByKey {self.child_pipeline_name} into {self.parent_pipeline_name}'\n",
    "                    >> beam.CoGroupByKey()\n",
    "                  | f'Reshape to dictionary'\n",
    "                    >> beam.FlatMap(reshapeCoGroupToFlatDict)\n",
    "        )\n",
    "\n",
    "ordersfilename = 'datasets/northwind/AVRO/orders/orders.avro'\n",
    "orderdetailsfilename = 'datasets/northwind/AVRO/orderdetails/orderdetails.avro'\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "    orders = (p | 'Read Orders' >> beam.io.ReadFromAvro(ordersfilename)\n",
    "                | 'Parse Date' >> beam.Map(lambda x : dict(orderid = x['orderid']\n",
    "                                                           , country = x['shipcountry']\n",
    "                                                           , orderdate = datetime.strptime(x['orderdate'], '%Y-%m-%d').date()))\n",
    "#                | 'Order to Row' >> beam.Map(lambda x : beam.Row(**x))\n",
    "                 | 'Order to Class' >> beam.Map(lambda x : Order(**x)).with_output_types(Order) \n",
    "             )\n",
    "    orderdetails = (p | 'Read OrderDetails' >> beam.io.ReadFromAvro(orderdetailsfilename)\n",
    "                      | 'Parse Amount' >> beam.Map(lambda x : dict(orderid = x['orderid']                        \n",
    "                                                               , amount = x['unitprice'] * x['quantity']))\n",
    "                                                               \n",
    "#                      | 'OrderDetail to Row' >> beam.Map(lambda x : beam.Row(**x))\n",
    "                 | 'OrderDetail to Class' >> beam.Map(lambda x : OrderDetail(**x)).with_output_types(OrderDetail) \n",
    "                   )\n",
    "    ordersjoin = ( {'orders': orders, 'orderdetails': orderdetails} \n",
    "                    | 'SQL' >> SqlTransform('''\n",
    "                    SELECT country\n",
    "                        , sum(amount) as total_amount\n",
    "                    FROM orders as o\n",
    "                    JOIN orderdetails as od on o.orderid = od.orderid\n",
    "                    GROUP BY country\n",
    "                    '''\n",
    "                 ))\n",
    "    # ordersjoin = ( {'orders': orders, 'orderdetails': orderdetails} \n",
    "    #                 | 'SQL' >> SqlTransform('''\n",
    "    #                 SELECT country, TUMBLE_START(orderdate, 60*60*24) as start_date\n",
    "    #                     , sum(amount) as total_amount\n",
    "    #                 FROM orders as o\n",
    "    #                 JOIN orderdetails as od on o.orderid = od.orderid\n",
    "    #                 GROUP BY COUNTRY, TUMBLE(orderdate, 60*60*24)\n",
    "    #                 '''\n",
    "    #              ))\n",
    "    \n",
    "    \n",
    "    ordersjoin | beam.Map(print)\n",
    "#     groupby = (ordersjoin\n",
    "#                | 'Timestamp' >> beam.Map(lambda x : beam.window.TimestampedValue(x, time.mktime(x['orderdate'].timetuple())))\n",
    "#                | 'Window' >> beam.WindowInto(beam.window.FixedWindows(60 * 60 * 24))\n",
    "#                | 'Group' >> beam.GroupBy(country = lambda x: x['country']).aggregate_field(lambda x: x['amount'], sum, 'totalamount')\n",
    "#                | 'AddWindowTimestamp' >> (beam.ParDo(GetTimestampFn()))\n",
    "#               )\n",
    "\n",
    "#     groupby | beam.Map(print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738ed601-0fc5-48ea-bcd2-79980e0a889c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c9be7e3-8313-44d5-a323-e361227209ab",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923315b5-84f3-43af-9c68-effabfbf7c56",
   "metadata": {},
   "source": [
    "#     orders = (p | 'Read Orders' >> beam.io.ReadFromAvro(ordersfilename)\n",
    "# #                | 'Orders To Row' >> beam.Map(lambda x : beam.Row(**x))\n",
    "# #                | 'Parse' >> beam.ParDo(OrdersParseRow())\n",
    "#              )\n",
    "# #    orders | 'Print Orders' >> beam.Map(print)\n",
    "\n",
    "#     orderdetails = (p | 'Read OrderDetails' >> beam.io.ReadFromAvro(orderdetailsfilename)\n",
    "# #                | 'OrderDetailsTo Row' >> beam.Map(lambda x : beam.Row(**x))\n",
    "#             )\n",
    "# #    orderdetails | 'Print OrderDetailss' >> beam.Map(print)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "01. Apache Beam 2.46.0 for Python 3",
   "language": "python",
   "name": "01-apache-beam-2.46.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
